<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Qian-Wu Liao" />


<title>Preprocessing: Untargeted Metabolomics and Lipidomics of Method Development cohort</title>

<script src="site_libs/header-attrs-2.23/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-6.4.0/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.0/css/v4-shims.min.css" rel="stylesheet" />

<link rel="icon" href="https://github.com/workflowr/workflowr-assets/raw/main/img/reproducible.png">
<!-- Add a small amount of space between sections. -->
<style type="text/css">
div.section {
  padding-top: 12px;
}
</style>



<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">SMART-CARE: Lung Cancer</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/LiaoQianWu/SMART-CARE_LungCancer">
    <span class="fab fa-github"></span>
     
    Source code
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Preprocessing: Untargeted Metabolomics and
Lipidomics of Method Development cohort</h1>
<h4 class="author">Qian-Wu Liao</h4>

</div>


<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-report" data-toggle="collapse" data-target="#workflowr-report">
<span class="glyphicon glyphicon-list" aria-hidden="true"></span>
workflowr <span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span>
</button>
</p>
<div id="workflowr-report" class="collapse">
<ul class="nav nav-tabs">
<li class="active">
<a data-toggle="tab" href="#summary">Summary</a>
</li>
<li>
<a data-toggle="tab" href="#checks"> Checks <span
class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> </a>
</li>
<li>
<a data-toggle="tab" href="#versions">Past versions</a>
</li>
</ul>
<div class="tab-content">
<div id="summary" class="tab-pane fade in active">
<p>
<strong>Last updated:</strong> 2023-12-06
</p>
<p>
<strong>Checks:</strong> <span
class="glyphicon glyphicon-ok text-success" aria-hidden="true"></span> 6
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> 1
</p>
<p>
<strong>Knit directory:</strong> <code>SMART-CARE_LungCancer/</code>
<span class="glyphicon glyphicon-question-sign" aria-hidden="true"
title="This is the local directory in which the code in this file was executed.">
</span>
</p>
<p>
This reproducible <a href="https://rmarkdown.rstudio.com">R Markdown</a>
analysis was created with <a
  href="https://github.com/workflowr/workflowr">workflowr</a> (version
1.7.0). The <em>Checks</em> tab describes the reproducibility checks
that were applied when the results were created. The <em>Past
versions</em> tab lists the development history.
</p>
<hr>
</div>
<div id="checks" class="tab-pane fade">
<div id="workflowr-checks" class="panel-group">
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRMarkdownfilestronguptodate">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>R Markdown file:</strong> up-to-date
</a>
</p>
</div>
<div id="strongRMarkdownfilestronguptodate"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great! Since the R Markdown file has been committed to the Git
repository, you know the exact version of the code that produced these
results.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongEnvironmentstrongempty">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Environment:</strong> empty </a>
</p>
</div>
<div id="strongEnvironmentstrongempty" class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! The global environment was empty. Objects defined in the
global environment can affect the analysis in your R Markdown file in
unknown ways. For reproduciblity it’s best to always run the code in an
empty environment.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSeedstrongcodesetseed20230425code">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Seed:</strong>
<code>set.seed(20230425)</code> </a>
</p>
</div>
<div id="strongSeedstrongcodesetseed20230425code"
class="panel-collapse collapse">
<div class="panel-body">
<p>The command <code>set.seed(20230425)</code> was run prior to running
the code in the R Markdown file. Setting a seed ensures that any results
that rely on randomness, e.g. subsampling or permutations, are
reproducible.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongSessioninformationstrongrecorded">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Session information:</strong>
recorded </a>
</p>
</div>
<div id="strongSessioninformationstrongrecorded"
class="panel-collapse collapse">
<div class="panel-body">
<p>Great job! Recording the operating system, R version, and package
versions is critical for reproducibility.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongCachestrongnone">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Cache:</strong> none </a>
</p>
</div>
<div id="strongCachestrongnone" class="panel-collapse collapse">
<div class="panel-body">
<p>Nice! There were no cached chunks for this analysis, so you can be
confident that you successfully produced the results during this
run.</p>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongFilepathsstrongabsolute">
<span class="glyphicon glyphicon-exclamation-sign text-danger"
aria-hidden="true"></span> <strong>File paths:</strong> absolute </a>
</p>
</div>
<div id="strongFilepathsstrongabsolute" class="panel-collapse collapse">
<div class="panel-body">
<p>
Using absolute paths to the files within your workflowr project makes it
difficult for you and others to run your code on a different machine.
Change the absolute path(s) below to the suggested relative path(s) to
make your code more reproducible.
</p>
<table class="table table-condensed table-hover">
<thead>
<tr>
<th style="text-align:left;">
absolute
</th>
<th style="text-align:left;">
relative
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
/Users/qianwu/Desktop/SMART-CARE_LungCancer
</td>
<td style="text-align:left;">
.
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
<p class="panel-title">
<a data-toggle="collapse" data-parent="#workflowr-checks" href="#strongRepositoryversionstrongahrefhttpsgithubcomLiaoQianWuSMARTCARELungCancertree7f8311b18786948e24e79c7cdbe7bc7780db99c6targetblank7f8311ba">
<span class="glyphicon glyphicon-ok text-success"
aria-hidden="true"></span> <strong>Repository version:</strong>
<a href="https://github.com/LiaoQianWu/SMART-CARE_LungCancer/tree/7f8311b18786948e24e79c7cdbe7bc7780db99c6" target="_blank">7f8311b</a>
</a>
</p>
</div>
<div
id="strongRepositoryversionstrongahrefhttpsgithubcomLiaoQianWuSMARTCARELungCancertree7f8311b18786948e24e79c7cdbe7bc7780db99c6targetblank7f8311ba"
class="panel-collapse collapse">
<div class="panel-body">
<p>
Great! You are using Git for version control. Tracking code development
and connecting the code version to the results is critical for
reproducibility.
</p>
<p>
The results in this page were generated with repository version
<a href="https://github.com/LiaoQianWu/SMART-CARE_LungCancer/tree/7f8311b18786948e24e79c7cdbe7bc7780db99c6" target="_blank">7f8311b</a>.
See the <em>Past versions</em> tab to see a history of the changes made
to the R Markdown and HTML files.
</p>
<p>
Note that you need to be careful to ensure that all relevant files for
the analysis have been committed to Git prior to generating the results
(you can use <code>wflow_publish</code> or
<code>wflow_git_commit</code>). workflowr only checks the R Markdown
file, but you know if there are other scripts or data files that it
depends on. Below is the status of the Git repository when the results
were generated:
</p>
<pre><code>
Ignored files:
    Ignored:    .DS_Store
    Ignored:    .RData
    Ignored:    .Rhistory
    Ignored:    analysis/.DS_Store
    Ignored:    code/.DS_Store
    Ignored:    data/.DS_Store
    Ignored:    output/.DS_Store

Untracked files:
    Untracked:  analysis/feature_selection.Rmd
    Untracked:  code/archive/
    Untracked:  code/dataset_list.R
    Untracked:  code/workflowr_commands.R
    Untracked:  data/Discovery/
    Untracked:  data/MethodDev/
    Untracked:  data/aliquot_metadata.xlsx
    Untracked:  data/patient_metadata.xlsx
    Untracked:  data/sample_metadata.xlsx
    Untracked:  output/MethodDev/
    Untracked:  output/SC_meeting/

</code></pre>
<p>
Note that any generated files, e.g. HTML, png, CSS, etc., are not
included in this status report because it is ok for generated content to
have uncommitted changes.
</p>
</div>
</div>
</div>
</div>
<hr>
</div>
<div id="versions" class="tab-pane fade">

<p>
These are the previous versions of the repository in which changes were
made to the R Markdown
(<code>analysis/MethodDev_01_preprocessing_untargeted.Rmd</code>) and
HTML (<code>docs/MethodDev_01_preprocessing_untargeted.html</code>)
files. If you’ve configured a remote Git repository (see
<code>?wflow_git_remote</code>), click on the hyperlinks in the table
below to view the files as they were in that past version.
</p>
<div class="table-responsive">
<table class="table table-condensed table-hover">
<thead>
<tr>
<th>
File
</th>
<th>
Version
</th>
<th>
Author
</th>
<th>
Date
</th>
<th>
Message
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/LiaoQianWu/SMART-CARE_LungCancer/blob/e9ae79526a098e2bdd9b4446f1489f6d5dc45642/analysis/MethodDev_01_preprocessing_untargeted.Rmd" target="_blank">e9ae795</a>
</td>
<td>
LiaoQianWu
</td>
<td>
2023-12-05
</td>
<td>
Update metadata
</td>
</tr>
<tr>
<td>
Rmd
</td>
<td>
<a href="https://github.com/LiaoQianWu/SMART-CARE_LungCancer/blob/bba10115517c46c67704f4f5a2d707d3172ef1a5/analysis/MethodDev_01_preprocessing_untargeted.Rmd" target="_blank">bba1011</a>
</td>
<td>
LiaoQianWu
</td>
<td>
2023-11-17
</td>
<td>
Rearrange file locations and redo preprocessing of all method
development datasets
</td>
</tr>
</tbody>
</table>
</div>
<hr>
</div>
</div>
</div>
<p><font size='4'> Description: Preprocess Plasma and Tissue Untargeted
Metabolomics and Lipidomics generated by Qiuqin Zhou and Kelechi Amatobi
from AG Hopf. This script includes (1) performing varied data
normalization techniques (log2-transformation, VSN, and median
normalization) on data and comparing them in terms of whether all
samples are brought to same scale and similarity of triplicate measures
of each sample, (2) conducting batch correction if needed, and (3)
merging triplicates into individual measures and storing all information
in SummarizedExperiment objects for further analyses. Among varied
normalization methods, vsn normalized data was selected. Note that,
since features have not been annotated yet by comparing against
databases, we defined them by m/z and retention time.<br />
</p>
<p>Update: Remove those features whose Retention Times are shorter than
0.3 min and longer than 8.5 min for Metabolomics and 9 min for
Lipidomics.<br />
</p>
<p>Update2: Remove those features quantified in less than 2/3 of samples
in all sample groups of interest after data fusion. </font></p>
<p>Load libraries</p>
<pre class="r"><code>library(&#39;readxl&#39;)
library(&#39;vsn&#39;)
library(&#39;limma&#39;)
library(&#39;sva&#39;)
library(&#39;DEP&#39;)
library(&#39;SummarizedExperiment&#39;)
library(&#39;tidyverse&#39;)
# Load user-defined functions
source(&#39;./code/misc.R&#39;)

# Set plot theme
th &lt;- theme_bw(base_size = 15) +
  theme(axis.title = element_text(face = &#39;bold&#39;),
        axis.text = element_text(face = &#39;bold&#39;),
        axis.ticks = element_line(linewidth = 0.8),
        legend.text = element_text(size = 15))</code></pre>
<pre class="r"><code># Load sample metadata
smpMetadat &lt;- readxl::read_excel(&#39;./data/sample_metadata.xlsx&#39;)
colnames(smpMetadat) &lt;- smpMetadat[3,, drop = F]
smpMetadat &lt;- dplyr::slice(smpMetadat, -c(1:3)) %&gt;%
  dplyr::select(c(Code, Parents, Visit, `Material submitted`, `Date and time of collection or surgery`,
                  `SMART-CARE cohort identifier`)) %&gt;%
  dplyr::rename(Sample = Code, Patient = Parents, TimePoint = Visit, SmpType = `Material submitted`,
                Date = `Date and time of collection or surgery`, Cohort = `SMART-CARE cohort identifier`) %&gt;%
  dplyr::mutate(Sample = stringr::str_remove_all(Sample, &#39;^SC_T_S_|^SC_DIS_S_|^SC_S_|_P&#39;),
                Patient = stringr::str_remove(Patient, &#39;^/THRX_SPACE/THRX_DB/&#39;),
                TimePoint = dplyr::case_when(TimePoint == &#39;PRETHERAPEUTIC&#39; ~ &#39;Baseline&#39;,
                                             TimePoint == &#39;FOLLOW-UP&#39; ~ &#39;Follow-up&#39;,
                                             TimePoint == &#39;RECURRENCE&#39; ~ &#39;Recurrence&#39;),
                SmpType = dplyr::case_when(SmpType == &#39;EDTA_PLASMA&#39; ~ &#39;Plasma&#39;,
                                           SmpType == &#39;FRESH_FROZEN_TISSUE&#39; ~ &#39;Tissue&#39;),
                Condition = dplyr::case_when(grepl(&#39;_TU|TG&#39;, Sample) ~ &#39;Tumor&#39;,
                                             grepl(&#39;_NG&#39;, Sample) ~ &#39;Normal&#39;,
                                             !grepl(&#39;_TU|_NG&#39;, Sample) ~ TimePoint),
                Date = stringr::str_extract(Date, &#39;^\\d+-\\d+-\\d+&#39;),
                Cohort = dplyr::case_when(Cohort == &#39;DISCOVERY_COHORT&#39; ~ &#39;Discovery&#39;,
                                          Cohort == &#39;METHOD_DEVELOPMENT_COHORT&#39; ~ &#39;MethodDev&#39;),
                Date = as.Date(Date, format = &#39;%Y-%m-%d&#39;))

# Load patient metadata
patientMetadat &lt;- readxl::read_excel(&#39;./data/patient_metadata.xlsx&#39;)
colnames(patientMetadat) &lt;- patientMetadat[3,, drop = F]
patientMetadat &lt;- dplyr::slice(patientMetadat, -c(1:3)) %&gt;%
  dplyr::select(c(Code, Gender, `Age at diagnosis`, `Pathological stage`, `Smoking status`,
                  `Adjuvant chemotherapy`,)) %&gt;%
  dplyr::rename(Patient = Code, Age = `Age at diagnosis`, Stage = `Pathological stage`,
                Smoking = `Smoking status`, Adjuvant = `Adjuvant chemotherapy`) %&gt;%
  dplyr::mutate(Gender = dplyr::case_when(Gender == &#39;MALE&#39; ~ &#39;Male&#39;,
                                          Gender == &#39;FEMALE&#39; ~ &#39;Female&#39;),
                Smoking = dplyr::case_when(Smoking == &#39;SMOKER&#39; ~ &#39;Smoker&#39;,
                                           Smoking == &#39;EX-SMOKER&#39; ~ &#39;Ex-smoker&#39;,
                                           Smoking == &#39;NON-SMOKER&#39; ~ &#39;Non-smoker&#39;),
                Adjuvant = dplyr::case_when(Adjuvant == &#39;true&#39; ~ &#39;True&#39;,
                                            Adjuvant == &#39;false&#39; ~ &#39;False&#39;),
                Age = as.numeric(Age))
# Include patient recurrence information in patient metadata
recurPats &lt;- dplyr::filter(smpMetadat, TimePoint == &#39;Recurrence&#39;) %&gt;%
  dplyr::pull(Patient)
patientMetadat &lt;- dplyr::mutate(patientMetadat, Recurrence = dplyr::case_when(Patient %in% recurPats ~ &#39;Yes&#39;,
                                                                              !Patient %in% recurPats ~ &#39;No&#39;))

# Load aliquot metadata
aliquotMetadat &lt;- readxl::read_excel(&#39;./data/aliquot_metadata.xlsx&#39;)
colnames(aliquotMetadat) &lt;- aliquotMetadat[3,, drop = F]
aliquotMetadat &lt;- dplyr::slice(aliquotMetadat, -c(1:3)) %&gt;%
  dplyr::select(Code, Parents, `Tumor Cell Content (%)`, `Cohort Identifier`, `Submission to`,
                `Delivered?`) %&gt;%
  dplyr::rename(Aliquot = Code, Sample = Parents, TumorPurity = `Tumor Cell Content (%)`,
                Cohort = `Cohort Identifier`, To = `Submission to`, Delivered = `Delivered?`) %&gt;%
  dplyr::mutate(Sample = stringr::str_remove_all(Sample, &#39;^/THRX_SPACE/THRX_DB/SC_T_S_|_P&#39;),
                Sample = stringr::str_remove(Sample, &#39;^/THRX_SPACE/THRX_DB/SC_DIS_S_&#39;),
                Sample = stringr::str_remove(Sample, &#39;^/THRX_SPACE/THRX_DB/SC_S_&#39;),
                Sample = stringr::str_remove(Sample, &#39;^/THRX_SPACE/THRX_DB/SC_DIS_&#39;),
                Cohort = dplyr::case_when(Cohort == &#39;method establishment&#39; ~ &#39;MethodDev&#39;,
                                          Cohort == &#39;DISCOVERY_COHORT&#39; ~ &#39;Discovery&#39;),
                TumorPurity = as.numeric(TumorPurity)) %&gt;%
  dplyr::filter(To %in% c(&#39;HOPF&#39;))
# Prepare aliquot metadata containing tumor purity information
tumorPurityInfo &lt;- dplyr::select(aliquotMetadat, Aliquot, Sample, TumorPurity)

# Combine all needed metadata
summMetadat &lt;- dplyr::left_join(tumorPurityInfo, smpMetadat, by = &#39;Sample&#39;) %&gt;%
  dplyr::left_join(patientMetadat, by = &#39;Patient&#39;)

# List sample annotations to keep in SE objects
smpAnno &lt;- c(&#39;Patient&#39;, &#39;SmpType&#39;, &#39;TimePoint&#39;, &#39;Date&#39;, &#39;Cohort&#39;, &#39;Condition&#39;,
             &#39;Recurrence&#39;, &#39;Gender&#39;, &#39;Age&#39;, &#39;Smoking&#39;, &#39;Stage&#39;, &#39;Adjuvant&#39;)</code></pre>
<div id="plasma-metabolomics" class="section level1">
<h1>Plasma Metabolomics</h1>
<pre class="r"><code># Load dataset
metaPlasmaTab &lt;- readxl::read_excel(&#39;./data/MethodDev/AG_Hopf/PLASMA_METABOLOMICS_20221108.Feature list.xlsx&#39;)
# Take care of sample and feature identifications
# Put new suffixes to column names to indicate technical triplicates
colNam &lt;- colnames(metaPlasmaTab) %&gt;%
  stringr::str_remove(&#39;\\.\\.\\..*$&#39;)
colNam[1] &lt;- &#39;m/z_RT&#39;
smpNam &lt;- colNam[2:length(colNam)]
colNam[2:length(colNam)] &lt;- paste0(smpNam, &#39;_&#39;, rep(c(1,2,3), length(smpNam)/3))
colnames(metaPlasmaTab) &lt;- colNam

# Remove those features whose retention times are smaller than 0.3 and greater than 8.5 min
RT &lt;- stringr::str_extract(metaPlasmaTab$`m/z_RT`, &#39;/.*&#39;) %&gt;%
  stringr::str_remove(&#39;/&#39;) %&gt;%
  as.numeric()
metaPlasmaTab &lt;- metaPlasmaTab[RT &gt;= 0.3 &amp; RT &lt;= 8.5,]
# Remove those features whose intensities are smaller than 300?
# MZ &lt;- stringr::str_extract(metaPlasmaTab$`m/z_RT`, &#39;.*/&#39;) %&gt;%
#   stringr::str_remove(&#39;/&#39;) %&gt;%
#   as.numeric()
# sum(MZ &lt; 300) #458

# Create feature IDs for m/z_RT to simplify downstream operations
metaPlasmaTab$Feature_ID &lt;- paste0(&#39;Feature&#39;, seq(nrow(metaPlasmaTab)))</code></pre>
<p>Display data dimensions (120 triplicate samples and 974 features)</p>
<pre class="r"><code>dim(dplyr::select(metaPlasmaTab, -c(`m/z_RT`, Feature_ID)))</code></pre>
<pre><code>[1] 974 120</code></pre>
<p>List duplicated features that have same m/z and retention time</p>
<pre class="r"><code># Check duplicated m/z_RT (features) to see if further actions are needed
cat(&#39;The following features have duplication:\n&#39;,
    paste(metaPlasmaTab$`m/z_RT`[duplicated(metaPlasmaTab$`m/z_RT`)],
          collapse = &#39;  &#39;))</code></pre>
<pre><code>The following features have duplication:
 362.92618/0.79  182.06326/6.18</code></pre>
<p>Display distribution of original data</p>
<pre class="r"><code># Convert messy wide data to tidy long table
metaPlasmaTab &lt;- tidyr::pivot_longer(metaPlasmaTab, cols = -c(&#39;m/z_RT&#39;, &#39;Feature_ID&#39;),
                                     names_to = &#39;Sample_ID&#39;, values_to = &#39;Abundance&#39;) %&gt;%
  # Convert zero values to NA since zeros are not real zeros, but undetected,
  # might be extremely small or normal values and perform log2-transformation on
  # feature abundance
  dplyr::mutate(Abundance = replace(Abundance, Abundance == 0, NA),
                Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;SC_T_A_.*_2_&#39;),
                log2Abundance = log2(Abundance)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display original data distribution
ggplot(metaPlasmaTab, aes(x=Sample_ID, y=Abundance)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = &#39;Sample&#39;, title = &#39;Original data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-4-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Display distribution of log2-transformed data</p>
<pre class="r"><code># Display log2-transformed data distribution
ggplot(metaPlasmaTab, aes(x=Sample_ID, y=log2Abundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Log2(Abundance)&#39;, title = &#39;Log2-transformed data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-5-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Percentage of missing values in data</p>
<pre class="r"><code># Display percentage of missing values
abun &lt;- metaPlasmaTab$Abundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), &#39;% observations are missing.&#39;))</code></pre>
<pre><code>0.23% observations are missing.</code></pre>
<p><br/> - Is data on the same scale (mean and median)?<br />
- Does data have stable variance?<br />
- Use glog2-transformation if there are lots of zeros.</p>
<div id="normalization" class="section level2">
<h2>Normalization</h2>
<div id="vsn" class="section level3">
<h3>VSN</h3>
<p>Display distribution of vsn normalized data</p>
<pre class="r"><code># Convert long table to wide data
abunMat &lt;- dplyr::select(metaPlasmaTab, Feature_ID, Sample_ID, Abundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;Abundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  as.matrix()

# Perform VSN
fit &lt;- vsnMatrix(abunMat) # fit contains fitted calibration and transformation parameters
abunVsnMat &lt;- predict(fit, abunMat) %&gt;% # predict applies fit to data
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;)
metaPlasmaVsnTab &lt;- tidyr::pivot_longer(abunVsnMat,
                                        cols = -&#39;Feature_ID&#39;,
                                        names_to = &#39;Sample_ID&#39;,
                                        values_to = &#39;vsnAbundance&#39;) %&gt;%
  dplyr::mutate(Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;SC_T_A_.*_2_&#39;)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display VSN normalized data
ggplot(metaPlasmaVsnTab, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Vsn normalized data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-8-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="median-normalization" class="section level3">
<h3>Median normalization</h3>
<p>Display distribution of median normalized data</p>
<pre class="r"><code># Perform median normalization (median scaling and log2-transformation)
# Similar procedure as that of VSN where affine transformation is conducted followed
# by glog2-transformation. Yet, notice that median transformation may produce negative
# values that are problematic to log2-transformation
metaPlasmaMediTab &lt;- limma::normalizeBetweenArrays(abunMat, method = &#39;scale&#39;) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;) %&gt;%
  tidyr::pivot_longer(cols = -&#39;Feature_ID&#39;,
                      names_to = &#39;Sample_ID&#39;,
                      values_to = &#39;mediAbundance&#39;) %&gt;%
  dplyr::mutate(mediAbundance = log2(mediAbundance),
                Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;SC_T_A_.*_2_&#39;)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display median normalized data
ggplot(metaPlasmaMediTab, aes(x=Sample_ID, y=mediAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Median normalized data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-9-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># - Check how median scaling works in limma?</code></pre>
</div>
</div>
<div id="histogram-for-standard-deviations" class="section level2">
<h2>Histogram for standard deviations</h2>
<p>Compute standard deviation of each feature among triplicate measures.
Dashed line indicates mean standard deviation.</p>
<pre class="r"><code># Calculate standard deviations of each feature among triplicates
# Log2-transformation
log2Std &lt;- dplyr::group_by(metaPlasmaTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(log2Abundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;Log2&#39;) %&gt;%
  dplyr::select(Method, Std)
# VSN
vsnStd &lt;- dplyr::group_by(metaPlasmaVsnTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;VSN&#39;) %&gt;%
  dplyr::select(Method, Std)
# Median normalization
mediStd &lt;- dplyr::group_by(metaPlasmaMediTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(mediAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;Median norm&#39;) %&gt;%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab &lt;- rbind(log2Std, vsnStd, mediStd)
stdMean &lt;- dplyr::group_by(stdTab, Method) %&gt;%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2, position = &#39;identity&#39;) +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype=&quot;dashed&quot;, linewidth = 0.7, show.legend = F) +
  labs(x = &#39;Standard Deviation&#39;, y = &#39;Count&#39;,
       title = &#39;Standard deviation of each feature among triplicates&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-10-1.png" width="960" style="display: block; margin: auto;" />
<br/> - Is the standard deviation near zero among triplicates?</p>
</div>
<div id="pca" class="section level2">
<h2>PCA</h2>
<p>Assess similarity among triplicate measures normalized by different
methods for quality control</p>
<div id="log2-transformation" class="section level3">
<h3>Log2-transformation</h3>
<pre class="r"><code># Perform PCA to assess similarity among triplicates
# Log2-transformation
# Remove rows (features) that have any NA values
naFeats &lt;- unique(metaPlasmaTab$Feature_ID[is.na(metaPlasmaTab$Abundance)])
abunLog2MatSub &lt;- dplyr::select(metaPlasmaTab,
                                Feature_ID, Sample_ID, log2Abundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;log2Abundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

# Extract Sample condition annotations
condition &lt;- dplyr::select(metaPlasmaTab,
                           Sample_ID, Patient, Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample_ID))

pcLog2Res &lt;- prcomp(t(abunLog2MatSub), center = T, scale. = F)
pcLog2Tab &lt;- pcLog2Res$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, &#39;_2_.&#39;),
                Batch = rep(c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;), nrow(.)/3))

ggplot(pcLog2Tab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Log2-transformed data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-11-1.png" width="960" style="display: block; margin: auto;" />
<br/> - What is the meaning of separation?<br />
- What is the pattern of separation?</p>
</div>
<div id="vsn-1" class="section level3">
<h3>VSN</h3>
<pre class="r"><code># VSN
abunVsnMatSub &lt;- dplyr::select(metaPlasmaVsnTab,
                               Feature_ID, Sample_ID, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcVsnRes &lt;- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab &lt;- pcVsnRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, &#39;_2_.&#39;),
                Batch = rep(c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;), nrow(.)/3)) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-12-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Condition, group=Sample)) +
#   geom_point() +
#   geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
#   labs(title = &#39;Vsn normalized data&#39;)</code></pre>
</div>
<div id="median-normalization-1" class="section level3">
<h3>Median normalization</h3>
<pre class="r"><code># Median normalization
abunMediMatSub &lt;- dplyr::select(metaPlasmaMediTab,
                                Feature_ID, Sample_ID, mediAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;mediAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcMediRes &lt;- prcomp(t(abunMediMatSub), center = T, scale. = F)
pcMediTab &lt;- pcMediRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, &#39;_2_.&#39;),
                Batch = rep(c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;), nrow(.)/3))

ggplot(pcMediTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Median normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-13-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="scatterplots-between-triplicates" class="section level2">
<h2>Scatterplots between triplicates</h2>
<p>Check correlations between triplicate measures processed using
different data normalization methods due to batch effects. Red diagonal
shows perfect positive correlation, which is for inspecting data
distribution.</p>
<div id="log2-transformation-1" class="section level3">
<h3>Log2-transformation</h3>
<p>Batch1 vs Batch2</p>
<pre class="r"><code># Make scatterplots to see relationships between triplicates
# Log2-transformation
# Retrieve data according to Batch (different triplicates)
log2B1 &lt;- dplyr::filter(metaPlasmaTab, Batch == &#39;1&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, log2Abundance) %&gt;%
  dplyr::rename(Batch1 = log2Abundance)
log2B2 &lt;- dplyr::filter(metaPlasmaTab, Batch == &#39;2&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, log2Abundance) %&gt;%
  dplyr::rename(Batch2 = log2Abundance)
log2B3 &lt;- dplyr::filter(metaPlasmaTab, Batch == &#39;3&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, log2Abundance) %&gt;%
  dplyr::rename(Batch3 = log2Abundance)

# Batch 1 and 2
log2ScatTabB12 &lt;- dplyr::left_join(log2B1, log2B2, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(log2ScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Log2-transformed data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-14-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Batch2 vs Batch3</p>
<pre class="r"><code># Batch 2 and 3
log2ScatTabB23 &lt;- dplyr::left_join(log2B2, log2B3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(log2ScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Log2-transformed data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-15-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Batch1 vs Batch3</p>
<pre class="r"><code># Batch 1 and 3
log2ScatTabB13 &lt;- dplyr::left_join(log2B1, log2B3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(log2ScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Log2-transformed data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-16-1.png" width="960" style="display: block; margin: auto;" />
<br/> - Is there data shifting (linear relationship)?</p>
</div>
<div id="vsn-2" class="section level3">
<h3>VSN</h3>
<p>Batch1 vs Batch2</p>
<pre class="r"><code># VSN
vsnB1 &lt;- dplyr::filter(metaPlasmaVsnTab, Batch == &#39;1&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch1 = vsnAbundance)
vsnB2 &lt;- dplyr::filter(metaPlasmaVsnTab, Batch == &#39;2&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch2 = vsnAbundance)
vsnB3 &lt;- dplyr::filter(metaPlasmaVsnTab, Batch == &#39;3&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch3 = vsnAbundance)

# Batch 1 and 2
vsnScatTabB12 &lt;- dplyr::left_join(vsnB1, vsnB2, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-17-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Batch2 vs Batch3</p>
<pre class="r"><code># Batch 2 and 3
vsnScatTabB23 &lt;- dplyr::left_join(vsnB2, vsnB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-18-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Batch1 vs Batch3</p>
<pre class="r"><code># Batch 1 and 3
vsnScatTabB13 &lt;- dplyr::left_join(vsnB1, vsnB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-19-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="median-normalization-2" class="section level3">
<h3>Median normalization</h3>
<p>Batch1 vs Batch2</p>
<pre class="r"><code># Median Normalization
mediB1 &lt;- dplyr::filter(metaPlasmaMediTab, Batch == &#39;1&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, mediAbundance) %&gt;%
  dplyr::rename(Batch1 = mediAbundance)
mediB2 &lt;- dplyr::filter(metaPlasmaMediTab, Batch == &#39;2&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, mediAbundance) %&gt;%
  dplyr::rename(Batch2 = mediAbundance)
mediB3 &lt;- dplyr::filter(metaPlasmaMediTab, Batch == &#39;3&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, mediAbundance) %&gt;%
  dplyr::rename(Batch3 = mediAbundance)

# Batch 1 and 2
mediScatTabB12 &lt;- dplyr::left_join(mediB1, mediB2, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(mediScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Median normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-20-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Batch2 vs Batch3</p>
<pre class="r"><code># Batch 2 and 3
mediScatTabB23 &lt;- dplyr::left_join(mediB2, mediB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(mediScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Median normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-21-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Batch1 vs Batch3</p>
<pre class="r"><code># Batch 1 and 3
mediScatTabB13 &lt;- dplyr::left_join(mediB1, mediB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(mediScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Median normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-22-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="batch-correction" class="section level2">
<h2>Batch correction</h2>
<p>To be consistent, vsn normalized data is selected because VSN works
well in all Untargeted omics datasets in terms of bringing samples to
same scale and containing more features that have zero or low variance
among triplicate samples. <br/> <br/></p>
<p>Display distribution of vsn normalized data after batch
correction</p>
<pre class="r"><code># Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunVsnMat &lt;- dplyr::select(metaPlasmaVsnTab,
                            Feature_ID, Sample_ID, vsnAbundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  as.matrix()
# Define sample batches
batch &lt;- rep(c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;), ncol(abunVsnMat)/3)
# Define design matrix to keep particular effects, e.g., treatments
condition &lt;- dplyr::select(metaPlasmaVsnTab, Sample_ID, Sample, Batch, Patient,
                           Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample_ID))
designMat &lt;- model.matrix(~condition$Condition)

# Perform batch correction (limma)
metaPlasmaVsnTabBC &lt;- limma::removeBatchEffect(abunVsnMat,
                                               batch = batch,
                                               design = designMat) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;) %&gt;%
  tidyr::pivot_longer(cols = -&#39;Feature_ID&#39;,
                      names_to = &#39;Sample_ID&#39;,
                      values_to = &#39;vsnAbundance&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

# Display batch corrected VSN normalized data to check if there is any negative
# values
ggplot(metaPlasmaVsnTabBC, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Vsn normalized data (after batch correction)&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-23-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Compute standard deviation of each feature among triplicate
samples</p>
<pre class="r"><code># Calculate standard deviations of each feature among triplicates
# Batch corrected VSN
vsnStdBC &lt;- dplyr::group_by(metaPlasmaVsnTabBC, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;BC_VSN&#39;) %&gt;%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab &lt;- rbind(vsnStd, vsnStdBC)
stdMean &lt;- dplyr::group_by(stdTab, Method) %&gt;%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2, position = &#39;identity&#39;) +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype=&quot;dashed&quot;, linewidth = 0.7, show.legend = F) +
  labs(x = &#39;Standard Deviation&#39;, y = &#39;Count&#39;,
       title = &#39;Standard deviation of each feature among triplicates&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-24-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>PCA</p>
<pre class="r"><code># Perform PCA
# Remove rows (features) that have any NA values
naFeats &lt;- unique(metaPlasmaVsnTabBC$Feature_ID[
  is.na(metaPlasmaVsnTabBC$vsnAbundance)])
abunVsnMatSubBC &lt;- dplyr::select(metaPlasmaVsnTabBC,
                                 Feature_ID, Sample_ID, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcVsnResBC &lt;- prcomp(t(abunVsnMatSubBC), center = T, scale. = F)
pcVsnTabBC &lt;- pcVsnResBC$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcVsnTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data (after batch correction)&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-25-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Showcase changes in data points of PC1 top features with highest
loadings. Large dot indicates mean.</p>
<pre class="r"><code># Take a look at PC1 top features with highest weights in samples before and
# after batch correction
# Retrieve PC1 top features with highest weights
topFeatPC1 &lt;- names(sort(pcVsnRes$rotation[, 1], decreasing = T)[1:20])

# Vsn normalized data before batch correction
# Filter data
metaPlasmaVsnTabSub &lt;- filter(metaPlasmaVsnTab,
                              Feature_ID %in% topFeatPC1)
# Compute mean of each batch per group
abunVsnSubMean &lt;- group_by(metaPlasmaVsnTabSub, Feature_ID, Batch) %&gt;%
  summarise(Mean = mean(vsnAbundance, na.rm = T))

ggplot(metaPlasmaVsnTabSub, aes(x=Feature_ID, y=vsnAbundance, col=Batch)) +
  geom_point() +
  geom_point(data = abunVsnSubMean, aes(x=Feature_ID, y=Mean, col=Batch),
             size = 4, alpha = 0.7, show.legend = F) +
  labs(x = &#39;Feature ID&#39;, y = &#39;Normalized abundance&#39;,
       title = &#39;Before batch correction&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-26-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># After batch correction
metaPlasmaVsnTabBCSub &lt;- filter(metaPlasmaVsnTabBC,
                                Feature_ID %in% topFeatPC1)
abunVsnSubMeanBC &lt;- group_by(metaPlasmaVsnTabBCSub, Feature_ID, Batch) %&gt;%
  summarise(Mean = mean(vsnAbundance, na.rm = T))

ggplot(metaPlasmaVsnTabBCSub, aes(x=Feature_ID, y=vsnAbundance, col=Batch)) +
  geom_point() +
  geom_point(data = abunVsnSubMeanBC, aes(x=Feature_ID, y=Mean, col=Batch),
             size = 4, alpha = 0.7, show.legend = F) +
  labs(x = &#39;Feature ID&#39;, y = &#39;Normalized abundance&#39;,
       title = &#39;After batch correction&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-26-2.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="data-fusion" class="section level2">
<h2>Data fusion</h2>
<p>Mean of triplicates is taken. <br/> <br/></p>
<p>Display distribution of merged data</p>
<pre class="r"><code># Merge triplicates (take mean)
merge_metaPlasmaVsnTab &lt;- dplyr::group_by(metaPlasmaVsnTabBC, Feature_ID, Sample) %&gt;%
  dplyr::summarise(vsnAbundance = mean(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Sample&#39;)

# Incorporate m/z_RT information
MZRT &lt;- dplyr::select(metaPlasmaTab, `m/z_RT`, Feature_ID) %&gt;%
  dplyr::filter(!duplicated(Feature_ID))
merge_metaPlasmaVsnTab &lt;- dplyr::left_join(merge_metaPlasmaVsnTab, MZRT,
                                           by = &#39;Feature_ID&#39;)

ggplot(merge_metaPlasmaVsnTab, aes(x=Sample, y=vsnAbundance)) +
  geom_boxplot() +
  labs(y = &#39;Normalized abundance&#39;, title = &#39;Vsn normalized data&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-28-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Percentage of missing values</p>
<pre class="r"><code># Display percentage of missing values
abun &lt;- merge_metaPlasmaVsnTab$vsnAbundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), &#39;% observations are missing.&#39;))</code></pre>
<pre><code>0.07% observations are missing.</code></pre>
<p><strong>Remove features quantified in less than 2/3 of samples in all
four sample groups</strong> <strong>of interest (Baseline/Follow-up
Recurrence/Non-recurrence)</strong><br />
Missing data is more likely to happen in features with small abundances
due to detection limit. Image comparison between two sample groups,
certain metabolites are highly missing in one group and present in the
other</p>
<pre class="r"><code># Prepare sample time point information for feature filtering
merge_metaPlasmaVsnTab &lt;- dplyr::mutate(merge_metaPlasmaVsnTab,
                                        TimePoint = dplyr::case_when(
                                          Condition == &#39;Baseline&#39; ~ &#39;Baseline&#39;,
                                          Condition != &#39;Baseline&#39; ~ &#39;2 years later&#39;))

# Remove features quantified in less than 2/3 of samples in all sample groups of interest
# Grouping like this since Baseline and Follow-up samples will be analyzed separately
rmFeats &lt;- dplyr::group_by(merge_metaPlasmaVsnTab, Feature_ID, TimePoint, Recurrence) %&gt;%
  # Compute proportion of observed data points of each group
  dplyr::summarise(frac_nonNA = round(sum(!is.na(vsnAbundance)) / length(vsnAbundance), 2)) %&gt;%
  dplyr::ungroup() %&gt;%
  # Keep features observed in less than 2/3 of samples of groups
  dplyr::filter(frac_nonNA &lt; 0.67) %&gt;%
  dplyr::group_by(Feature_ID) %&gt;%
  dplyr::summarise(Count = length(Feature_ID)) %&gt;%
  # Keep features observed in less than 2/3 of samples of all groups
  dplyr::filter(Count == 4) %&gt;%
  dplyr::pull(Feature_ID)
merge_metaPlasmaVsnTab &lt;- dplyr::filter(merge_metaPlasmaVsnTab, !Feature_ID %in% rmFeats)

# Convert tidy long table to SummarizedExperiment object and save it for further analysis
metaPlasmaVsn &lt;- df2SummExp(merge_metaPlasmaVsnTab, row_id = &#39;Feature_ID&#39;, col_id = &#39;Sample&#39;,
                            values = &#39;vsnAbundance&#39;, row_anno = &#39;m/z_RT&#39;, col_anno = smpAnno)
# Save vsn normalized data
saveRDS(metaPlasmaVsn, &#39;./data/MethodDev/AG_Hopf/metaPlasmaVsn.rds&#39;)</code></pre>
<p>Display dimensions of filtered dataset</p>
<pre class="r"><code>dim(metaPlasmaVsn)</code></pre>
<pre><code>[1] 957  40</code></pre>
<p>Show feature mean-variance relationship of vsn normalized data</p>
<pre class="r"><code>vsn::meanSdPlot(as.matrix(assay(metaPlasmaVsn)), ranks = T, plot = F, bins = 30)$gg +
  labs(x = &#39;Rank of mean&#39;, y = &#39;SD&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-32-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>PCA</p>
<pre class="r"><code># Perform PCA
# Remove rows (features) that have any NA values
naFeats &lt;- unique(merge_metaPlasmaVsnTab$Feature_ID[
  is.na(merge_metaPlasmaVsnTab$vsnAbundance)])
abunVsnMatSub &lt;- dplyr::select(merge_metaPlasmaVsnTab,
                               Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

# Extract sample condition annotations
condition &lt;- dplyr::select(merge_metaPlasmaVsnTab,
                           Sample, Patient, Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample)) %&gt;%
  dplyr::mutate(Time_point = dplyr::case_when(
    Condition == &#39;Baseline&#39; ~ &#39;0&#39;,
    Condition != &#39;Baseline&#39; ~ &#39;2&#39;
  ))

pcVsnRes &lt;- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab &lt;- pcVsnRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample&#39;)

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Time_point, shape=Condition,
                     group=Patient)) +
  geom_point(size = 3) +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data&#39;) +
  scale_color_discrete(name = &#39;Time point&#39;,
                       labels = c(&#39;Baseline&#39;, &#39;2 years later&#39;)) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-33-1.png" width="960" style="display: block; margin: auto;" />
<br/> -&gt; PCA mainly captures source of variation in time points when
samples were taken. <br/> <br/></p>
<p>Variance explained by each PC</p>
<pre class="r"><code># Display proportion of total variance captured by all PCs explained by each PC
varExplained &lt;- pcVsnRes$sdev^2 / sum(pcVsnRes$sdev^2)
PC &lt;- paste0(&#39;PC&#39;, seq(length(varExplained)))
varTab &lt;- data.frame(PC = factor(PC, levels = PC),
                     Var_explained = varExplained)

ggplot(varTab, aes(x=PC, y=Var_explained*100)) +
  geom_col() +
  labs(x = &#39;&#39;, y = &#39;Variance explained (%)&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-34-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Store median normalized data for computing log(FC) later
# Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunMediMat &lt;- dplyr::select(metaPlasmaMediTab,
                             Feature_ID, Sample_ID, mediAbundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;mediAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  as.matrix()
# Define sample batches
batch &lt;- rep(c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;), ncol(abunMediMat)/3)
# Define design matrix to keep particular effects, e.g., treatments
condition &lt;- dplyr::select(metaPlasmaMediTab, Sample_ID, Sample, Batch, Patient,
                           Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample_ID))
designMat &lt;- model.matrix(~condition$Condition)

# Perform batch correction (limma)
metaPlasmaMediTabBC &lt;- limma::removeBatchEffect(abunMediMat,
                                                batch = batch,
                                                design = designMat) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;) %&gt;%
  tidyr::pivot_longer(cols = -&#39;Feature_ID&#39;,
                      names_to = &#39;Sample_ID&#39;,
                      values_to = &#39;mediAbundance&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

# Display batch corrected median normalized data to check if there is any negative
# values
# ggplot(metaPlasmaMediTabBC, aes(x=Sample_ID, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
#        title = &#39;Median normalized data (after batch correction)&#39;) +
#   th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# Perform PCA
# Remove rows (features) that have any NA values
abunMediMatBC &lt;- dplyr::select(metaPlasmaMediTabBC,
                               Feature_ID, Sample_ID, mediAbundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;mediAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcMediResBC &lt;- doPCA(abunMediMatBC)
pcMediTabBC &lt;- pcMediResBC$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

# ggplot(pcMediTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
#   geom_point() +
#   geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
#   labs(title = &#39;Median normalized data (after batch correction)&#39;) +
#   th

# Merge triplicates (take mean)
merge_metaPlasmaMediTab &lt;- dplyr::group_by(metaPlasmaMediTabBC, Feature_ID, Sample) %&gt;%
  dplyr::summarise(mediAbundance = mean(mediAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::filter(!Feature_ID %in% rmFeats) %&gt;%
  dplyr::left_join(summMetadat, &#39;Sample&#39;)

# Incorporate m/z_RT information
MZRT &lt;- dplyr::select(metaPlasmaTab, `m/z_RT`, Feature_ID) %&gt;%
  dplyr::filter(!duplicated(Feature_ID))
merge_metaPlasmaMediTab &lt;- dplyr::left_join(merge_metaPlasmaMediTab, MZRT,
                                            by = &#39;Feature_ID&#39;)

# ggplot(merge_metaPlasmaMediTab, aes(x=Sample, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(y = &#39;Normalized abundance&#39;, title = &#39;Median normalized data&#39;) +
#   th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Convert tidy long table to SummarizedExperiment object and save it for further
# analysis
metaPlasmaMedi &lt;- df2SummExp(merge_metaPlasmaMediTab, row_id = &#39;Feature_ID&#39;, col_id = &#39;Sample&#39;,
                             values = &#39;mediAbundance&#39;, row_anno = &#39;m/z_RT&#39;, col_anno = smpAnno)
# Save median normalized data
saveRDS(metaPlasmaMedi, &#39;./data/MethodDev/AG_Hopf/metaPlasmaMedi.rds&#39;)</code></pre>
</div>
</div>
<div id="plasma-lipidomics" class="section level1">
<h1>Plasma Lipidomics</h1>
<div id="normalization-1" class="section level2">
<h2>Normalization</h2>
<pre class="r"><code># Load dataset
lipPlasmaTab &lt;- readxl::read_excel(&#39;./data/MethodDev/AG_Hopf/PLASMA_LIPIDOMICS_20221108.Feature list.xlsx&#39;)
# Take care of sample and feature identifications
# Put new suffixes to column names to indicate technical triplicates
colNam &lt;- colnames(lipPlasmaTab) %&gt;%
  stringr::str_remove(&#39;\\.\\.\\..*$&#39;)
colNam[1] &lt;- &#39;m/z_RT&#39;
smpNam &lt;- colNam[2:length(colNam)]
colNam[2:length(colNam)] &lt;- paste0(smpNam, &#39;_&#39;, rep(c(1,2,3), length(smpNam)/3))
colnames(lipPlasmaTab) &lt;- colNam

# Remove those features whose retention times are smaller than 0.3 and greater than 9 min
RT &lt;- stringr::str_extract(lipPlasmaTab$`m/z_RT`, &#39;/.*&#39;) %&gt;%
  stringr::str_remove(&#39;/&#39;) %&gt;%
  as.numeric()
lipPlasmaTab &lt;- lipPlasmaTab[RT &gt;= 0.3 &amp; RT &lt;= 9,]
# Remove those features whose intensities are smaller than 300?
# MZ &lt;- stringr::str_extract(lipPlasmaTab$`m/z_RT`, &#39;.*/&#39;) %&gt;%
#   stringr::str_remove(&#39;/&#39;) %&gt;%
#   as.numeric()
# sum(MZ &lt; 300) #NA

# Create feature IDs for m/z_RT to simplify downstream operations
lipPlasmaTab$Feature_ID &lt;- paste0(&#39;Feature&#39;, seq(nrow(lipPlasmaTab)))</code></pre>
<p>Display data dimensions (120 triplicate samples and 2456
features)</p>
<pre class="r"><code>dim(dplyr::select(lipPlasmaTab, -c(`m/z_RT`, Feature_ID)))</code></pre>
<pre><code>[1] 2456  120</code></pre>
<p>List duplicated features that have same m/z and retention time</p>
<pre class="r"><code># Check duplicated m/z_RT (features) to see if further actions are needed
cat(&#39;The following features have duplication:\n&#39;,
    paste(unique(lipPlasmaTab$`m/z_RT`[duplicated(lipPlasmaTab$`m/z_RT`)]),
          collapse = &#39;  &#39;))</code></pre>
<pre><code>The following features have duplication:
 731.84/1.03  739.83/1.04  773.82/1.04  875.80/1.04  302.02/0.77  293.10/0.76  247.09/0.77  381.99/0.77  364.06/0.78  352.90/1.02  420.88/1.02  906.83/1.04  770.85/1.04  896.79/1.05  794.81/1.06  862.80/1.06  888.81/1.05  778.84/1.04  870.79/1.06  804.84/1.04  702.86/1.04  901.81/1.04  710.85/1.04  833.82/1.03  841.81/1.04  498.90/1.04  812.83/1.04  226.95/1.04  430.91/1.04  514.87/1.05  718.84/1.05  846.82/1.04  807.82/1.04  838.84/1.04  974.81/1.04  362.93/1.04  867.82/1.04  1,110.79/1.04  436.86/1.06  854.81/1.05  368.87/1.06  274.87/1.08  286.14/1.32  682.33/2.38  301.21/3.06  641.30/3.49  669.33/4  780.55/4.22  828.55/4.44  806.57/4.45  804.55/4.62  782.57/4.62  806.56/4.89  856.58/5.08  431.39/5.09  834.60/5.08  760.58/5.24  810.60/5.29  786.60/5.39  787.60/5.39  810.60/5.82  781.62/5.82  833.65/5.86  903.65/6.23  813.68/6.24  664.60/7.8  369.35/7.94  666.62/7.94  369.35/8.09  369.35/8.1</code></pre>
<p>Display distribution of original data</p>
<pre class="r"><code># Convert messy wide data to tidy long table
lipPlasmaTab &lt;- tidyr::pivot_longer(lipPlasmaTab,
                                    cols = -c(&#39;m/z_RT&#39;, &#39;Feature_ID&#39;),
                                    names_to = &#39;Sample_ID&#39;,
                                    values_to = &#39;Abundance&#39;) %&gt;%
  # Convert zero values to NA since zeros are not real zeros, but undetected,
  # might be extremely small or normal values and perform log2-transformation on
  # feature abundance
  dplyr::mutate(Abundance = replace(Abundance, Abundance == 0, NA),
                Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;SC_T_A_.*_2_&#39;),
                log2Abundance = log2(Abundance)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display original data distribution
ggplot(lipPlasmaTab, aes(x=Sample_ID, y=Abundance)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = &#39;Sample&#39;, title = &#39;Original data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-41-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Display distribution of log2-transformed data</p>
<pre class="r"><code># Display log2-transformed data distribution
ggplot(lipPlasmaTab, aes(x=Sample_ID, y=log2Abundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Log2(Abundance)&#39;, title = &#39;Log2-transformed data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-42-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Percentage of missing values in data</p>
<pre class="r"><code># Display percentage of missing values
abun &lt;- lipPlasmaTab$Abundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), &#39;% observations are missing.&#39;))</code></pre>
<pre><code>0.18% observations are missing.</code></pre>
<p>Display distribution of vsn normalized data</p>
<pre class="r"><code># Convert long table to wide data
abunMat &lt;- dplyr::select(lipPlasmaTab, Feature_ID, Sample_ID, Abundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;Abundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  as.matrix()

# Perform VSN
fit &lt;- vsnMatrix(abunMat)
abunVsnMat &lt;- predict(fit, abunMat) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;)
lipPlasmaVsnTab &lt;- tidyr::pivot_longer(abunVsnMat,
                                       cols = -&#39;Feature_ID&#39;,
                                       names_to = &#39;Sample_ID&#39;,
                                       values_to = &#39;vsnAbundance&#39;) %&gt;%
  dplyr::mutate(Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;SC_T_A_.*_2_&#39;)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display VSN normalized data
ggplot(lipPlasmaVsnTab, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Vsn normalized data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-44-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Display distribution of median normalized data</p>
<pre class="r"><code># Perform median normalization (median scaling and log2-transformation)
lipPlasmaMediTab &lt;- limma::normalizeBetweenArrays(abunMat, method = &#39;scale&#39;) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;) %&gt;%
  tidyr::pivot_longer(cols = -&#39;Feature_ID&#39;,
                      names_to = &#39;Sample_ID&#39;,
                      values_to = &#39;mediAbundance&#39;) %&gt;%
  dplyr::mutate(mediAbundance = log2(mediAbundance),
                Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;SC_T_A_.*_2_&#39;)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display median normalized data
ggplot(lipPlasmaMediTab, aes(x=Sample_ID, y=mediAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Median normalized data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-45-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Compute standard deviation of each feature among triplicate measures.
Dashed line indicates mean standard deviation.</p>
<pre class="r"><code># Calculate standard deviations of each feature among triplicates
# Log2-transformation
log2Std &lt;- dplyr::group_by(lipPlasmaTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(log2Abundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;Log2&#39;) %&gt;%
  dplyr::select(Method, Std)
# VSN
vsnStd &lt;- dplyr::group_by(lipPlasmaVsnTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;VSN&#39;) %&gt;%
  dplyr::select(Method, Std)
# Median normalization
mediStd &lt;- dplyr::group_by(lipPlasmaMediTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(mediAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;Median norm&#39;) %&gt;%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab &lt;- rbind(log2Std, vsnStd, mediStd)
stdMean &lt;- dplyr::group_by(stdTab, Method) %&gt;%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.4, binwidth = 0.2, position = &#39;identity&#39;) +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype=&quot;dashed&quot;, linewidth = 0.7, show.legend = F) +
  labs(x = &#39;Standard deviation&#39;, y = &#39;Count&#39;,
       title = &#39;Standard deviation of each feature among triplicates&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-46-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="pca-1" class="section level2">
<h2>PCA</h2>
<p>Assess similarity among triplicate measures normalized by different
methods for quality control</p>
<p><strong>Log2-transformed data</strong></p>
<pre class="r"><code># Perform PCA to assess similarity among triplicates
# Log2-transformation
# Remove rows (features) that have any NA values
naFeats &lt;- unique(lipPlasmaTab$Feature_ID[is.na(lipPlasmaTab$Abundance)])
abunLog2MatSub &lt;- dplyr::select(lipPlasmaTab,
                                Feature_ID, Sample_ID, log2Abundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;log2Abundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

# Extract sample condition annotations
condition &lt;- dplyr::select(lipPlasmaTab,
                           Sample_ID, Patient, Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample_ID))

pcLog2Res &lt;- prcomp(t(abunLog2MatSub), center = T, scale. = F)
pcLog2Tab &lt;- pcLog2Res$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, &#39;_2_.&#39;),
                Batch = rep(c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;), nrow(.)/3))

ggplot(pcLog2Tab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Log2-transformed data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-47-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(pcLog2Tab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Log2-transformed data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-47-2.png" width="960" style="display: block; margin: auto;" /></p>
<p><strong>Vsn normalized data</strong></p>
<pre class="r"><code># VSN
abunVsnMatSub &lt;- dplyr::select(lipPlasmaVsnTab,
                               Feature_ID, Sample_ID, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcVsnRes &lt;- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab &lt;- pcVsnRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, &#39;_2_.&#39;),
                Batch = rep(c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;), nrow(.)/3)) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-48-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(pcVsnTab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-48-2.png" width="960" style="display: block; margin: auto;" /></p>
<p><strong>Median normalized data</strong></p>
<pre class="r"><code># Median normalization
abunMediMatSub &lt;- dplyr::select(lipPlasmaMediTab,
                                Feature_ID, Sample_ID, mediAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;mediAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcMediRes &lt;- prcomp(t(abunMediMatSub), center = T, scale. = F)
pcMediTab &lt;- pcMediRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, &#39;_2_.&#39;),
                Batch = rep(c(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;), nrow(.)/3))

ggplot(pcMediTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Median normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-49-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(pcMediTab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Median normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-49-2.png" width="960" style="display: block; margin: auto;" /></p>
<p>Check correlations between triplicate measures processed using
different data normalization methods due to batch effects. Red diagonal
shows perfect positive correlation, which is for inspecting data
distribution. <br/></p>
<p><strong>Log2-transformed data</strong></p>
<pre class="r"><code># Make scatterplots to see relationships between triplicates
# Log2-transformation
# Retrieve data according to Batch (different triplicates)
log2B1 &lt;- dplyr::filter(lipPlasmaTab, Batch == &#39;1&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, log2Abundance) %&gt;%
  dplyr::rename(Batch1 = log2Abundance)
log2B2 &lt;- dplyr::filter(lipPlasmaTab, Batch == &#39;2&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, log2Abundance) %&gt;%
  dplyr::rename(Batch2 = log2Abundance)
log2B3 &lt;- dplyr::filter(lipPlasmaTab, Batch == &#39;3&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, log2Abundance) %&gt;%
  dplyr::rename(Batch3 = log2Abundance)

# Batch 1 and 2
log2ScatTabB12 &lt;- dplyr::left_join(log2B1, log2B2, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(log2ScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Log2-transformed data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-50-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Batch 2 and 3
log2ScatTabB23 &lt;- dplyr::left_join(log2B2, log2B3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(log2ScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Log2-transformed data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-50-2.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Batch 1 and 3
log2ScatTabB13 &lt;- dplyr::left_join(log2B1, log2B3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(log2ScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Log2-transformed data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-50-3.png" width="960" style="display: block; margin: auto;" /></p>
<p><strong>Vsn normalized data</strong></p>
<pre class="r"><code># VSN
vsnB1 &lt;- dplyr::filter(lipPlasmaVsnTab, Batch == &#39;1&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch1 = vsnAbundance)
vsnB2 &lt;- dplyr::filter(lipPlasmaVsnTab, Batch == &#39;2&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch2 = vsnAbundance)
vsnB3 &lt;- dplyr::filter(lipPlasmaVsnTab, Batch == &#39;3&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch3 = vsnAbundance)

# Batch 1 and 2
vsnScatTabB12 &lt;- dplyr::left_join(vsnB1, vsnB2, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-51-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Batch 2 and 3
vsnScatTabB23 &lt;- dplyr::left_join(vsnB2, vsnB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-51-2.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Batch 1 and 3
vsnScatTabB13 &lt;- dplyr::left_join(vsnB1, vsnB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-51-3.png" width="960" style="display: block; margin: auto;" /></p>
<p><strong>Median normalized data</strong></p>
<pre class="r"><code># Median Normalization
mediB1 &lt;- dplyr::filter(lipPlasmaMediTab, Batch == &#39;1&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, mediAbundance) %&gt;%
  dplyr::rename(Batch1 = mediAbundance)
mediB2 &lt;- dplyr::filter(lipPlasmaMediTab, Batch == &#39;2&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, mediAbundance) %&gt;%
  dplyr::rename(Batch2 = mediAbundance)
mediB3 &lt;- dplyr::filter(lipPlasmaMediTab, Batch == &#39;3&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, mediAbundance) %&gt;%
  dplyr::rename(Batch3 = mediAbundance)

# Batch 1 and 2
mediScatTabB12 &lt;- dplyr::left_join(mediB1, mediB2, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(mediScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Median normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-52-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Batch 2 and 3
mediScatTabB23 &lt;- dplyr::left_join(mediB2, mediB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(mediScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Median normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-52-2.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Batch 1 and 3
mediScatTabB13 &lt;- dplyr::left_join(mediB1, mediB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(mediScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Median normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-52-3.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="batch-correction-1" class="section level2">
<h2>Batch correction</h2>
<p>Vsn normalized data is selected. <br/> <br/></p>
<p>Display distribution of vsn normalized data after batch
correction</p>
<pre class="r"><code># Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunVsnMat &lt;- dplyr::select(lipPlasmaVsnTab,
                            Feature_ID, Sample_ID, vsnAbundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  as.matrix()
# Define sample batches
batch &lt;- rep(c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;), ncol(abunVsnMat)/3)
# Define design matrix to keep particular effects, e.g., treatments
condition &lt;- dplyr::select(lipPlasmaVsnTab, Sample_ID, Sample, Batch, Patient,
                           Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample_ID))
designMat &lt;- model.matrix(~condition$Condition)
# Perform batch correction (limma)
lipPlasmaVsnTabBC &lt;- limma::removeBatchEffect(abunVsnMat,
                                              batch = batch,
                                              design = designMat) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;) %&gt;%
  tidyr::pivot_longer(cols = -&#39;Feature_ID&#39;,
                      names_to = &#39;Sample_ID&#39;,
                      values_to = &#39;vsnAbundance&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

# Display batch corrected VSN normalized data to check if there is any negative
# values
ggplot(lipPlasmaVsnTabBC, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Vsn normalized data (after batch correction)&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-53-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Compute standard deviation of each feature among triplicate
samples</p>
<pre class="r"><code># Calculate standard deviations of each feature among triplicates
# Batch corrected VSN
vsnStdBC &lt;- dplyr::group_by(lipPlasmaVsnTabBC, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;BC_VSN&#39;) %&gt;%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab &lt;- rbind(vsnStd, vsnStdBC)
stdMean &lt;- dplyr::group_by(stdTab, Method) %&gt;%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.4, binwidth = 0.2, position = &#39;identity&#39;) +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype=&quot;dashed&quot;, linewidth = 0.7, show.legend = F) +
  labs(x = &#39;Standard Deviation&#39;, y = &#39;Count&#39;,
       title = &#39;Standard deviation of each feature among triplicates&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-54-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>PCA</p>
<pre class="r"><code># Perform PCA
# Remove rows (features) that have any NA values
naFeats &lt;- unique(lipPlasmaVsnTabBC$Feature_ID[
  is.na(lipPlasmaVsnTabBC$vsnAbundance)])
abunVsnMatSubBC &lt;- dplyr::select(lipPlasmaVsnTabBC,
                                 Feature_ID, Sample_ID, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcVsnResBC &lt;- prcomp(t(abunVsnMatSubBC), center = T, scale. = F)
pcVsnTabBC &lt;- pcVsnResBC$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcVsnTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data (after batch correction)&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-55-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(pcVsnTabBC, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data (after batch correction)&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-55-2.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="data-fusion-1" class="section level2">
<h2>Data fusion</h2>
<p>Mean of triplicates is taken. <br/> <br/></p>
<p>Display distribution of merged data</p>
<pre class="r"><code># Merge triplicates (take mean)
merge_lipPlasmaVsnTab &lt;- dplyr::group_by(lipPlasmaVsnTabBC, Feature_ID, Sample) %&gt;%
  dplyr::summarise(vsnAbundance = mean(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Sample&#39;)

# Incorporate m/z_RT information
MZRT &lt;- dplyr::select(lipPlasmaTab, `m/z_RT`, Feature_ID) %&gt;%
  dplyr::filter(!duplicated(Feature_ID))
merge_lipPlasmaVsnTab &lt;- dplyr::left_join(merge_lipPlasmaVsnTab, MZRT,
                                          by = &#39;Feature_ID&#39;)

ggplot(merge_lipPlasmaVsnTab, aes(x=Sample, y=vsnAbundance)) +
  geom_boxplot() +
  labs(y = &#39;Normalized abundance&#39;, title = &#39;Vsn normalized data&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-56-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Percentage of missing values</p>
<pre class="r"><code># Display percentage of missing values
abun &lt;- merge_lipPlasmaVsnTab$vsnAbundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), &#39;% observations are missing.&#39;))</code></pre>
<pre><code>0.09% observations are missing.</code></pre>
<p><strong>Remove features quantified in less than 2/3 of samples in all
four sample groups</strong> <strong>of interest (Baseline/Follow-up
Recurrence/Non-recurrence)</strong><br />
</p>
<pre class="r"><code># Prepare sample time point information for feature filtering
merge_lipPlasmaVsnTab &lt;- dplyr::mutate(merge_lipPlasmaVsnTab,
                                       TimePoint = dplyr::case_when(
                                         Condition == &#39;Baseline&#39; ~ &#39;Baseline&#39;,
                                         Condition != &#39;Baseline&#39; ~ &#39;2 years later&#39;))

# Remove features quantified in less than 2/3 of samples in all sample groups of interest
rmFeats &lt;- dplyr::group_by(merge_lipPlasmaVsnTab, Feature_ID, TimePoint, Recurrence) %&gt;%
  dplyr::summarise(frac_nonNA = round(sum(!is.na(vsnAbundance)) / length(vsnAbundance), 2)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::filter(frac_nonNA &lt; 0.67) %&gt;%
  dplyr::group_by(Feature_ID) %&gt;%
  dplyr::summarise(Count = length(Feature_ID)) %&gt;%
  dplyr::filter(Count == 4) %&gt;%
  dplyr::pull(Feature_ID)
merge_lipPlasmaVsnTab &lt;- dplyr::filter(merge_lipPlasmaVsnTab, !Feature_ID %in% rmFeats)

# Convert tidy long table to SummarizedExperiment object and save it for further analysis
lipPlasmaVsn &lt;- df2SummExp(merge_lipPlasmaVsnTab, row_id = &#39;Feature_ID&#39;, col_id = &#39;Sample&#39;,
                            values = &#39;vsnAbundance&#39;, row_anno = &#39;m/z_RT&#39;, col_anno = smpAnno)
# Save vsn normalized data 
saveRDS(lipPlasmaVsn, &#39;./data/MethodDev/AG_Hopf/lipPlasmaVsn.rds&#39;)</code></pre>
<p>Display dimensions of filtered dataset</p>
<pre class="r"><code>dim(lipPlasmaVsn)</code></pre>
<pre><code>[1] 2353   40</code></pre>
<p>Show feature mean-variance relationship of vsn normalized data</p>
<pre class="r"><code>vsn::meanSdPlot(as.matrix(assay(lipPlasmaVsn)), ranks = T, plot = F)$gg +
  labs(x = &#39;Rank of mean&#39;, y = &#39;SD&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-60-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>PCA</p>
<pre class="r"><code># Perform PCA
# Remove rows (features) that have any NA values
naFeats &lt;- unique(merge_lipPlasmaVsnTab$Feature_ID[
  is.na(merge_lipPlasmaVsnTab$vsnAbundance)])
abunVsnMatSub &lt;- dplyr::select(merge_lipPlasmaVsnTab,
                               Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

# Extract sample condition annotations
condition &lt;- dplyr::select(merge_lipPlasmaVsnTab,
                           Sample, Patient, Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample)) %&gt;%
  dplyr::mutate(Time_point = dplyr::case_when(
    Condition == &#39;Baseline&#39; ~ &#39;0&#39;,
    Condition != &#39;Baseline&#39; ~ &#39;2&#39;
  ))

pcVsnRes &lt;- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab &lt;- pcVsnRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample&#39;)

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Time_point, shape=Condition,
                     group=Patient)) +
  geom_point(size = 3) +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  scale_color_discrete(name = &#39;Time point&#39;,
                       labels = c(&#39;Baseline&#39;, &#39;2 years later&#39;)) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-61-1.png" width="960" style="display: block; margin: auto;" />
<br/> -&gt; PCA mainly captures source of variation in time points when
samples were taken. <br/> <br/></p>
<p>Variance explained by each PC</p>
<pre class="r"><code># Display proportion of total variance captured by all PCs explained by each PC
varExplained &lt;- pcVsnRes$sdev^2 / sum(pcVsnRes$sdev^2)
PC &lt;- paste0(&#39;PC&#39;, seq(length(varExplained)))
varTab &lt;- data.frame(PC = factor(PC, levels = PC),
                     Var_explained = varExplained)

ggplot(varTab, aes(x=PC, y=Var_explained*100)) +
  geom_col() +
  labs(x = &#39;&#39;, y = &#39;Variance explained (%)&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-62-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Store median normalized data for computing log(FC) later
# Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunMediMat &lt;- dplyr::select(lipPlasmaMediTab,
                             Feature_ID, Sample_ID, mediAbundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;mediAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  as.matrix()
# Define sample batches
batch &lt;- rep(c(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;), ncol(abunMediMat)/3)
# Define design matrix to keep particular effects, e.g., treatments
condition &lt;- dplyr::select(lipPlasmaMediTab, Sample_ID, Sample, Batch, Patient,
                           Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample_ID))
designMat &lt;- model.matrix(~condition$Condition)

# Perform batch correction (limma)
lipPlasmaMediTabBC &lt;- limma::removeBatchEffect(abunMediMat,
                                               batch = batch,
                                               design = designMat) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;) %&gt;%
  tidyr::pivot_longer(cols = -&#39;Feature_ID&#39;,
                      names_to = &#39;Sample_ID&#39;,
                      values_to = &#39;mediAbundance&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

# Display batch corrected median normalized data to check if there is any negative
# values
# ggplot(lipPlasmaMediTabBC, aes(x=Sample_ID, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
#        title = &#39;Median normalized data (after batch correction)&#39;) +
#   th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# Perform PCA
# Remove rows (features) that have any NA values
abunMediMatBC &lt;- dplyr::select(lipPlasmaMediTabBC,
                               Feature_ID, Sample_ID, mediAbundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;mediAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcMediResBC &lt;- doPCA(abunMediMatBC)
pcMediTabBC &lt;- pcMediResBC$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

# ggplot(pcMediTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
#   geom_point() +
#   geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
#   labs(title = &#39;Median normalized data (after batch correction)&#39;) +
#   th

# Merge triplicates (take mean)
merge_lipPlasmaMediTab &lt;- dplyr::group_by(lipPlasmaMediTabBC, Feature_ID, Sample) %&gt;%
  dplyr::summarise(mediAbundance = mean(mediAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::filter(!Feature_ID %in% rmFeats) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Sample&#39;)

# Incorporate m/z_RT information
MZRT &lt;- dplyr::select(lipPlasmaTab, `m/z_RT`, Feature_ID) %&gt;%
  dplyr::filter(!duplicated(Feature_ID))
merge_lipPlasmaMediTab &lt;- dplyr::left_join(merge_lipPlasmaMediTab, MZRT,
                                           by = &#39;Feature_ID&#39;)

# ggplot(merge_lipPlasmaMediTab, aes(x=Sample, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(y = &#39;Normalized abundance&#39;, title = &#39;Median normalized data&#39;) +
#   th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Convert tidy long table to SummarizedExperiment object and save it for further
# analysis
lipPlasmaMedi &lt;- df2SummExp(merge_lipPlasmaMediTab, row_id = &#39;Feature_ID&#39;, col_id = &#39;Sample&#39;,
                            values = &#39;mediAbundance&#39;, row_anno = &#39;m/z_RT&#39;, col_anno = smpAnno)
saveRDS(lipPlasmaMedi, &#39;./data/MethodDev/AG_Hopf/lipPlasmaMedi.rds&#39;)</code></pre>
</div>
</div>
<div id="tissue-metabolomics" class="section level1">
<h1>Tissue Metabolomics</h1>
<div id="normalization-2" class="section level2">
<h2>Normalization</h2>
<pre class="r"><code># Load dataset
metaTissueTab &lt;- read.table(
  &#39;./data/MethodDev/AG_Hopf/TISSUE_METABOLOMICS_20230222.Feature list.txt&#39;,
  header = T, sep = &#39;\t&#39;, dec = &#39;,&#39;) %&gt;%
  dplyr::mutate(m.z.meas. = paste0(m.z.meas., &#39;/&#39;, RT..min.)) %&gt;%
  dplyr::select(-RT..min., -contains(&#39;Process_blank&#39;), -starts_with(&#39;QC&#39;)) %&gt;%
  dplyr::rename(`MZ/RT` = m.z.meas.)

# Prepare sample ID table for changing sample names
smpIDs &lt;- readxl::read_excel(&#39;./data/MethodDev/AG_Hopf/TISSUE.Sample IDs.xlsx&#39;) %&gt;%
  dplyr::select(`Number on MS vials`, `Code from OpenBis`) %&gt;%
  dplyr::rename(Sample_ID = `Number on MS vials`,
                Aliquot = `Code from OpenBis`) %&gt;%
  dplyr::mutate(Sample_ID = paste0(&#39;X&#39;, Sample_ID))

# Take care of sample and feature identifications
colNam &lt;- colnames(metaTissueTab) %&gt;%
  stringr::str_remove_all(&#39;Tissue_PITC_batch|_pos_.*&#39;)
smpNam &lt;- colNam[2:length(colNam)] %&gt;%
  stringr::str_remove(&#39;_.$&#39;) %&gt;%
  plyr::mapvalues(smpIDs$Sample_ID, smpIDs$Aliquot)
colNam[2:length(colNam)] &lt;- paste0(smpNam, &#39;_&#39;, c(rep(1, length(smpNam)/3),
                                                  rep(2, length(smpNam)/3),
                                                  rep(3, length(smpNam)/3)))
colnames(metaTissueTab) &lt;- colNam

# Remove those features whose retention times are smaller than 0.3 and greater than 8.5 min
RT &lt;- stringr::str_extract(metaTissueTab$`MZ/RT`, &#39;/.*&#39;) %&gt;%
  stringr::str_remove(&#39;/&#39;) %&gt;%
  as.numeric()
metaTissueTab &lt;- metaTissueTab[RT &gt;= 0.3 &amp; RT &lt;= 8.5,]
# Remove those features whose intensities are smaller than 300?
# MZ &lt;- stringr::str_extract(metaTissueTab$`MZ/RT`, &#39;.*/&#39;) %&gt;%
#   stringr::str_remove(&#39;/&#39;) %&gt;%
#   as.numeric()
# sum(MZ &lt; 300) #328

# Create feature IDs for MZ/RT to simplify downstream operations
metaTissueTab$Feature_ID &lt;- paste0(&#39;Feature&#39;, seq(nrow(metaTissueTab)))</code></pre>
<p>Display data dimensions (120 triplicate samples and 882 features)</p>
<pre class="r"><code>dim(dplyr::select(metaTissueTab, -c(`MZ/RT`, Feature_ID)))</code></pre>
<pre><code>[1] 882 120</code></pre>
<p>There is no duplicated feature that have same m/z and retention
time</p>
<pre class="r"><code># Check duplicated MZ/RT (features) to see if further actions are needed
cat(&#39;The following features have duplication: NA&#39;)</code></pre>
<pre><code>The following features have duplication: NA</code></pre>
<pre class="r"><code>    # paste(unique(metaTissueTab$`MZ/RT`[duplicated(metaTissueTab$`MZ/RT`)]),
    #       collapse = &#39;  &#39;))</code></pre>
<p>Display distribution of original data</p>
<pre class="r"><code># Convert messy wide data to tidy long table
metaTissueTab &lt;- tidyr::pivot_longer(metaTissueTab,
                                     cols = -c(&#39;MZ/RT&#39;, &#39;Feature_ID&#39;),
                                     names_to = &#39;Sample_ID&#39;,
                                     values_to = &#39;Abundance&#39;) %&gt;%
  # Convert zero values to NA since zeros are not real zeros, but undetected,
  # might be extremely small or normal values and perform log2-transformation on
  # feature abundance
  dplyr::mutate(Abundance = replace(Abundance, Abundance == 0, NA),
                Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;^.*_.*_&#39;),
                log2Abundance = log2(Abundance)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display original data distribution
ggplot(metaTissueTab, aes(x=Sample_ID, y=Abundance)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = &#39;Sample&#39;, title = &#39;Original data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-68-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Display distribution of log2-transformed data</p>
<pre class="r"><code># Display log2-transformed data distribution
ggplot(metaTissueTab, aes(x=Sample_ID, y=log2Abundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Log2(Abundance)&#39;, title = &#39;Log2-transformed data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-69-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Percentage of missing values in data</p>
<pre class="r"><code># Display percentage of missing values 
abun &lt;- metaTissueTab$Abundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), &#39;% observations are missing.&#39;))</code></pre>
<pre><code>0.32% observations are missing.</code></pre>
<p>Display distribution of vsn normalized data</p>
<pre class="r"><code># Convert long table to wide data
abunMat &lt;- dplyr::select(metaTissueTab, Feature_ID, Sample_ID, Abundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;Abundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  as.matrix()

# Perform VSN
fit &lt;- vsnMatrix(abunMat)
abunVsnMat &lt;- predict(fit, abunMat) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;)
metaTissueVsnTab &lt;- tidyr::pivot_longer(abunVsnMat,
                                        cols = -&#39;Feature_ID&#39;,
                                        names_to = &#39;Sample_ID&#39;,
                                        values_to = &#39;vsnAbundance&#39;) %&gt;%
  dplyr::mutate(Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;^.*_.*_&#39;)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display VSN normalized data
ggplot(metaTissueVsnTab, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Vsn normalized data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-71-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Every 6 measures are from same patients.</code></pre>
<p>Display distribution of median normalized data</p>
<pre class="r"><code># Perform median normalization (median scaling and log2-transformation)
metaTissueMediTab &lt;- limma::normalizeBetweenArrays(abunMat, method = &#39;scale&#39;) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;) %&gt;%
  tidyr::pivot_longer(cols = -&#39;Feature_ID&#39;,
                      names_to = &#39;Sample_ID&#39;,
                      values_to = &#39;mediAbundance&#39;) %&gt;%
  dplyr::mutate(mediAbundance = log2(mediAbundance),
                Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;^.*_.*_&#39;)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display median normalized data
ggplot(metaTissueMediTab, aes(x=Sample_ID, y=mediAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Median normalized data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-73-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Compute standard deviation of each feature among triplicate measures.
Dashed line indicates mean standard deviation.</p>
<pre class="r"><code># Calculate standard deviations of each feature among triplicates
# Log2-transformation
log2Std &lt;- dplyr::group_by(metaTissueTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(log2Abundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;Log2&#39;) %&gt;%
  dplyr::select(Method, Std)
# VSN
vsnStd &lt;- dplyr::group_by(metaTissueVsnTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;VSN&#39;) %&gt;%
  dplyr::select(Method, Std)
# Median normalization
mediStd &lt;- dplyr::group_by(metaTissueMediTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(mediAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;Median norm&#39;) %&gt;%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab &lt;- rbind(log2Std, vsnStd, mediStd)
stdMean &lt;- dplyr::group_by(stdTab, Method) %&gt;%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2, position = &#39;identity&#39;) +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype=&quot;dashed&quot;, linewidth = 0.7, show.legend = F) +
  labs(x = &#39;Standard deviation&#39;, y = &#39;Count&#39;,
       title = &#39;Standard deviation of each feature among triplicates&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-74-1.png" width="960" style="display: block; margin: auto;" />
-&gt; All three methods got similar standard deviations.</p>
</div>
<div id="pca-2" class="section level2">
<h2>PCA</h2>
<p>Assess similarity among triplicate measures normalized by different
methods for quality control</p>
<p><strong>Log2-transformed data</strong></p>
<pre class="r"><code># Perform PCA to assess similarity among triplicates
# Log2-transformation
# Remove rows (features) that have any NA values
naFeats &lt;- unique(metaTissueTab$Feature_ID[is.na(metaTissueTab$Abundance)])
abunLog2MatSub &lt;- dplyr::select(metaTissueTab,
                                Feature_ID, Sample_ID, log2Abundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;log2Abundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

# Extract sample condition annotations
condition &lt;- dplyr::select(metaTissueTab,
                           Sample_ID, Sample, Batch) %&gt;%
  dplyr::filter(!duplicated(Sample_ID))

pcLog2Res &lt;- prcomp(t(abunLog2MatSub), center = T, scale. = F)
pcLog2Tab &lt;- pcLog2Res$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcLog2Tab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Log2-transformed data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-75-1.png" width="960" style="display: block; margin: auto;" /></p>
<p><strong>Vsn normalized data</strong></p>
<pre class="r"><code># VSN
abunVsnMatSub &lt;- dplyr::select(metaTissueVsnTab,
                               Feature_ID, Sample_ID, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcVsnRes &lt;- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab &lt;- pcVsnRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-76-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># ggplot(pcVsnTab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
#   geom_point() +
#   geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
#   labs(title = &#39;Vsn normalized data&#39;)</code></pre>
<p><strong>Median normalized data</strong></p>
<pre class="r"><code># Median normalization
abunMediMatSub &lt;- dplyr::select(metaTissueMediTab,
                                Feature_ID, Sample_ID, mediAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;mediAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcMediRes &lt;- prcomp(t(abunMediMatSub), center = T, scale. = F)
pcMediTab &lt;- pcMediRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcMediTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Median normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-77-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="data-fusion-2" class="section level2">
<h2>Data fusion</h2>
<p>Vsn normalized data is selected and mean of triplicates is taken.
<br/> <br/></p>
<p>Display distribution of merged data</p>
<pre class="r"><code># Merge triplicates (take mean)
merge_metaTissueVsnTab &lt;- dplyr::group_by(metaTissueVsnTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(vsnAbundance = mean(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Sample&#39;)

# Incorporate MZ/RT information
MZRT &lt;- dplyr::select(metaTissueTab, `MZ/RT`, Feature_ID) %&gt;%
  dplyr::filter(!duplicated(Feature_ID))
merge_metaTissueVsnTab &lt;- dplyr::left_join(merge_metaTissueVsnTab, MZRT,
                                           by = &#39;Feature_ID&#39;)

ggplot(merge_metaTissueVsnTab, aes(x=Sample, y=vsnAbundance)) +
  geom_boxplot() +
  labs(y = &#39;Normalized abundance&#39;, title = &#39;Vsn normalized data&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-78-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Percentage of missing values</p>
<pre class="r"><code># Display percentage of missing values
abun &lt;- merge_metaTissueVsnTab$vsnAbundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), &#39;% observations are missing.&#39;))</code></pre>
<pre><code>0.17% observations are missing.</code></pre>
<p><strong>Remove features quantified in less than 2/3 of samples in all
four sample groups</strong> <strong>of interest (Normal/Tumor
Recurrence/Non-recurrence)</strong><br />
</p>
<pre class="r"><code># Remove features quantified in less than 2/3 of samples in all sample groups of interest
rmFeats &lt;- dplyr::group_by(merge_metaTissueVsnTab, Feature_ID, Condition, Recurrence) %&gt;%
  dplyr::summarise(frac_nonNA = round(sum(!is.na(vsnAbundance)) / length(vsnAbundance), 2)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::filter(frac_nonNA &lt; 0.67) %&gt;%
  dplyr::group_by(Feature_ID) %&gt;%
  dplyr::summarise(Count = length(Feature_ID)) %&gt;%
  dplyr::filter(Count == 4) %&gt;%
  dplyr::pull(Feature_ID)
merge_metaTissueVsnTab &lt;- dplyr::filter(merge_metaTissueVsnTab, !Feature_ID %in% rmFeats)

# Convert tidy long table to SummarizedExperiment object and save it for further analysis
metaTissueVsn &lt;- df2SummExp(merge_metaTissueVsnTab, row_id = &#39;Feature_ID&#39;, col_id = &#39;Sample&#39;,
                            values = &#39;vsnAbundance&#39;, row_anno = &#39;MZ/RT&#39;, col_anno = c(smpAnno, &#39;TumorPurity&#39;))
# Save vsn normalized data
saveRDS(metaTissueVsn, &#39;./data/MethodDev/AG_Hopf/metaTissueVsn.rds&#39;)</code></pre>
<p>Display dimensions of filtered dataset</p>
<pre class="r"><code>dim(metaTissueVsn)</code></pre>
<pre><code>[1] 775  40</code></pre>
<p>Show feature mean-variance relationship of vsn normalized data</p>
<pre class="r"><code>vsn::meanSdPlot(as.matrix(assay(metaTissueVsn)), ranks = T, plot = F, bins = 30)$gg +
  labs(x = &#39;Rank of mean&#39;, y = &#39;SD&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-82-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>PCA</p>
<pre class="r"><code># Perform PCA
# Remove rows (features) that have any NA values
naFeats &lt;- unique(merge_metaTissueVsnTab$Feature_ID[
  is.na(merge_metaTissueVsnTab$vsnAbundance)])
abunVsnMatSub &lt;- dplyr::select(merge_metaTissueVsnTab,
                               Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

# Extract sample condition annotations
condition &lt;- dplyr::select(merge_metaTissueVsnTab,
                         Sample, Patient, Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample))

pcVsnRes &lt;- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab &lt;- pcVsnRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample&#39;)

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Condition, shape=Recurrence,
                     group=Patient)) +
  geom_point(size = 3) +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-83-1.png" width="960" style="display: block; margin: auto;" />
<br/> -&gt; PCA mainly captures source of variation in tissue
conditions, which indicates decent data quality. <br/> <br/></p>
<p>Variance explained by each PC</p>
<pre class="r"><code># Display proportion of total variance captured by all PCs explained by each PC
varExplained &lt;- pcVsnRes$sdev^2 / sum(pcVsnRes$sdev^2)
PC &lt;- paste0(&#39;PC&#39;, seq(length(varExplained)))
varTab &lt;- data.frame(PC = factor(PC, levels = PC),
                     Var_explained = varExplained)

ggplot(varTab, aes(x=PC, y=Var_explained*100)) +
  geom_col() +
  labs(x = &#39;&#39;, y = &#39;Variance explained (%)&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-84-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Store median normalized data for computing log(FC) later
# Merge triplicates (take mean)
merge_metaTissueMediTab &lt;- dplyr::group_by(metaTissueMediTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(mediAbundance = mean(mediAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::filter(!Feature_ID %in% rmFeats) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Sample&#39;)

# Incorporate m/z_RT information
MZRT &lt;- dplyr::select(metaTissueTab, `MZ/RT`, Feature_ID) %&gt;%
  dplyr::filter(!duplicated(Feature_ID))
merge_metaTissueMediTab &lt;- dplyr::left_join(merge_metaTissueMediTab, MZRT,
                                            by = &#39;Feature_ID&#39;)

# ggplot(merge_metaTissueMediTab, aes(x=Sample, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(y = &#39;Normalized abundance&#39;, title = &#39;Median normalized data&#39;) +
#   th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Convert tidy long table to SummarizedExperiment object and save it for further
# analysis
metaTissueMedi &lt;- df2SummExp(merge_metaTissueMediTab, row_id = &#39;Feature_ID&#39;, col_id = &#39;Sample&#39;,
                             values = &#39;mediAbundance&#39;, row_anno = &#39;MZ/RT&#39;, col_anno = c(smpAnno, &#39;TumorPurity&#39;))
# Save median normalized data
saveRDS(metaTissueMedi, &#39;./data/MethodDev/AG_Hopf/metaTissueMedi.rds&#39;)</code></pre>
</div>
</div>
<div id="tissue-lipidomics" class="section level1">
<h1>Tissue Lipidomics</h1>
<div id="normalization-3" class="section level2">
<h2>Normalization</h2>
<pre class="r"><code># Load dataset
lipTissueTab &lt;- read.table(
  &#39;./data/MethodDev/AG_Hopf/TISSUE_LIPIDOMICS_20230222.Feature list.txt&#39;,
  header = T, sep = &#39;\t&#39;, dec = &#39;,&#39;) %&gt;%
  dplyr::mutate(m.z.meas. = paste0(m.z.meas., &#39;/&#39;, RT..min.)) %&gt;%
  dplyr::select(-RT..min., -starts_with(&#39;Blank&#39;), -starts_with(&#39;QC&#39;)) %&gt;%
  dplyr::rename(`MZ/RT` = m.z.meas.)

# Prepare sample ID table for changing sample names
smpIDs &lt;- readxl::read_excel(&#39;./data/MethodDev/AG_Hopf/TISSUE.Sample IDs.xlsx&#39;) %&gt;%
  dplyr::select(`Number on MS vials`, `Code from OpenBis`) %&gt;%
  dplyr::rename(Sample_ID = `Number on MS vials`,
                Aliquot = `Code from OpenBis`) %&gt;%
  dplyr::mutate(Sample_ID = paste0(&#39;Sample&#39;, Sample_ID))

# Take care of sample and feature identifications
colNam &lt;- colnames(lipTissueTab) %&gt;%
  stringr::str_remove_all(&#39;\\._|_lipids|batch|_pos_.*&#39;)
smpNam &lt;- colNam[2:length(colNam)] %&gt;%
  stringr::str_remove(&#39;_.$&#39;) %&gt;%
  plyr::mapvalues(smpIDs$Sample_ID, smpIDs$Aliquot)
colNam[2:length(colNam)] &lt;- paste0(smpNam, &#39;_&#39;, c(rep(1, length(smpNam)/3),
                                                  rep(2, length(smpNam)/3),
                                                  rep(3, length(smpNam)/3)))
colnames(lipTissueTab) &lt;- colNam

# Remove those features whose retention times are smaller than 0.3 and greater than 9 min
RT &lt;- stringr::str_extract(lipTissueTab$`MZ/RT`, &#39;/.*&#39;) %&gt;%
  stringr::str_remove(&#39;/&#39;) %&gt;%
  as.numeric()
lipTissueTab &lt;- lipTissueTab[RT &gt;= 0.3 &amp; RT &lt;= 9,]
# Remove those features whose intensities are smaller than 300?
# MZ &lt;- stringr::str_extract(lipTissueTab$`MZ/RT`, &#39;.*/&#39;) %&gt;%
#   stringr::str_remove(&#39;/&#39;) %&gt;%
#   as.numeric()
# sum(MZ &lt; 300) #58

# Create feature IDs for MZ/RT to simplify downstream operations
lipTissueTab$Feature_ID &lt;- paste0(&#39;Feature&#39;, seq(nrow(lipTissueTab)))</code></pre>
<p>Display data dimensions (120 triplicate samples and 2159
features)</p>
<pre class="r"><code>dim(dplyr::select(lipTissueTab, -c(`MZ/RT`, Feature_ID)))</code></pre>
<pre><code>[1] 2159  120</code></pre>
<p>List duplicated features that have same m/z and retention time</p>
<pre class="r"><code># Check duplicated MZ/RT (features) to see if further actions are needed
cat(&#39;The following features have duplication:\n&#39;,
    paste(unique(lipTissueTab$`MZ/RT`[duplicated(lipTissueTab$`MZ/RT`)]),
          collapse = &#39;  &#39;))</code></pre>
<pre><code>The following features have duplication:
 394.87422/1.11</code></pre>
<p>Display distribution of original data</p>
<pre class="r"><code># Convert messy wide data to tidy long table
lipTissueTab &lt;- tidyr::pivot_longer(lipTissueTab,
                                    cols = -c(&#39;MZ/RT&#39;, &#39;Feature_ID&#39;),
                                    names_to = &#39;Sample_ID&#39;,
                                    values_to = &#39;Abundance&#39;) %&gt;%
  # Convert zero values to NA since zeros are not real zeros, but undetected,
  # might be extremely small or normal values and perform log2-transformation on
  # feature abundance
  dplyr::mutate(Abundance = replace(Abundance, Abundance == 0, NA),
                Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;^.*_.*_&#39;),
                log2Abundance = log2(Abundance)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display original data distribution
ggplot(lipTissueTab, aes(x=Sample_ID, y=Abundance)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = &#39;Sample&#39;, title = &#39;Original data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-89-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Display distribution of log2-transformed data</p>
<pre class="r"><code># Display log2-transformed data distribution
ggplot(lipTissueTab, aes(x=Sample_ID, y=log2Abundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Log2(Abundance)&#39;, title = &#39;Log2-transformed data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-90-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Percentage of missing values in data</p>
<pre class="r"><code># Display percentage of missing values 
abun &lt;- lipTissueTab$Abundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), &#39;% observations are missing.&#39;))</code></pre>
<pre><code>0.18% observations are missing.</code></pre>
<p>Display distribution of vsn normalized data</p>
<pre class="r"><code># Convert long table to wide data
abunMat &lt;- dplyr::select(lipTissueTab, Feature_ID, Sample_ID, Abundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;Abundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  as.matrix()

# Perform VSN
fit &lt;- vsnMatrix(abunMat)
abunVsnMat &lt;- predict(fit, abunMat) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;)
lipTissueVsnTab &lt;- tidyr::pivot_longer(abunVsnMat,
                                       cols = -&#39;Feature_ID&#39;,
                                       names_to = &#39;Sample_ID&#39;,
                                       values_to = &#39;vsnAbundance&#39;) %&gt;%
  dplyr::mutate(Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;^.*_.*_&#39;)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display VSN normalized data
ggplot(lipTissueVsnTab, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Vsn normalized data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-92-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Display distribution of median normalized data</p>
<pre class="r"><code># Perform median normalization (median scaling and log2-transformation)
lipTissueMediTab &lt;- limma::normalizeBetweenArrays(abunMat, method = &#39;scale&#39;) %&gt;%
  tibble::as_tibble(rownames = &#39;Feature_ID&#39;) %&gt;%
  tidyr::pivot_longer(cols = -&#39;Feature_ID&#39;,
                      names_to = &#39;Sample_ID&#39;,
                      values_to = &#39;mediAbundance&#39;) %&gt;%
  dplyr::mutate(mediAbundance = log2(mediAbundance),
                Aliquot = stringr::str_remove(Sample_ID, &#39;_\\d$&#39;),
                Batch = stringr::str_remove(Sample_ID, &#39;^.*_.*_&#39;)) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Aliquot&#39;)

# Display median normalized data
ggplot(lipTissueMediTab, aes(x=Sample_ID, y=mediAbundance)) +
  geom_boxplot() +
  labs(x = &#39;Sample&#39;, y = &#39;Normalized Abundance&#39;,
       title = &#39;Median normalized data&#39;) +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-93-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Compute standard deviation of each feature among triplicate measures.
Dashed line indicates mean standard deviation.</p>
<pre class="r"><code># Calculate standard deviations of each feature among triplicates
# Log2-transformation
log2Std &lt;- dplyr::group_by(lipTissueTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(log2Abundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;Log2&#39;) %&gt;%
  dplyr::select(Method, Std)
# VSN
vsnStd &lt;- dplyr::group_by(lipTissueVsnTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;VSN&#39;) %&gt;%
  dplyr::select(Method, Std)
# Median normalization
mediStd &lt;- dplyr::group_by(lipTissueMediTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(Std = sd(mediAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::mutate(Method = &#39;Median norm&#39;) %&gt;%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab &lt;- rbind(log2Std, vsnStd, mediStd)
stdMean &lt;- dplyr::group_by(stdTab, Method) %&gt;%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2, position = &#39;identity&#39;) +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype=&quot;dashed&quot;, linewidth = 0.7, show.legend = F) +
  labs(x = &#39;Standard deviation&#39;, y = &#39;Count&#39;,
       title = &#39;Standard deviation of each feature among triplicates&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-94-1.png" width="960" style="display: block; margin: auto;" />
-&gt; VSN and median normalization got similar mean standard
deviations.</p>
</div>
<div id="pca-3" class="section level2">
<h2>PCA</h2>
<p>Assess similarity among triplicate measures normalized by different
methods for quality control</p>
<p><strong>Log2-transformed data</strong></p>
<pre class="r"><code># Perform PCA to assess similarity among triplicates
# Log2-transformation
# Remove rows (features) that have any NA values
naFeats &lt;- unique(lipTissueTab$Feature_ID[is.na(lipTissueTab$Abundance)])
abunLog2MatSub &lt;- dplyr::select(lipTissueTab,
                                Feature_ID, Sample_ID, log2Abundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;log2Abundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

# Extract sample condition annotations
condition &lt;- dplyr::select(lipTissueTab,
                         Sample_ID, Sample, Batch) %&gt;%
  dplyr::filter(!duplicated(Sample_ID))

pcLog2Res &lt;- prcomp(t(abunLog2MatSub), center = T, scale. = F)
pcLog2Tab &lt;- pcLog2Res$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcLog2Tab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Log2-transformed data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-95-1.png" width="960" style="display: block; margin: auto;" /></p>
<p><strong>Vsn normalized data</strong></p>
<pre class="r"><code># VSN
abunVsnMatSub &lt;- dplyr::select(lipTissueVsnTab,
                               Feature_ID, Sample_ID, vsnAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcVsnRes &lt;- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab &lt;- pcVsnRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Vsn normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-96-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># ggplot(pcVsnTab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
#   geom_point() +
#   geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
#   labs(title = &#39;Vsn normalized data&#39;)</code></pre>
<p><strong>Median normalized data</strong></p>
<pre class="r"><code># Median normalization
abunMediMatSub &lt;- dplyr::select(lipTissueMediTab,
                                Feature_ID, Sample_ID, mediAbundance) %&gt;%
  dplyr::filter(!(Feature_ID %in% naFeats)) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample_ID&#39;, values_from = &#39;mediAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;)

pcMediRes &lt;- prcomp(t(abunMediMatSub), center = T, scale. = F)
pcMediTab &lt;- pcMediRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample_ID&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample_ID&#39;)

ggplot(pcMediTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  labs(title = &#39;Median normalized data&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-97-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Check correlations between triplicate measures processed using VSN
due to batch effects. Red diagonal shows perfect positive correlation,
which is for inspecting data distribution. <br/></p>
<p><strong>Vsn normalized data</strong></p>
<pre class="r"><code># VSN
vsnB1 &lt;- dplyr::filter(lipTissueVsnTab, Batch == &#39;1&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch1 = vsnAbundance)
vsnB2 &lt;- dplyr::filter(lipTissueVsnTab, Batch == &#39;2&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch2 = vsnAbundance)
vsnB3 &lt;- dplyr::filter(lipTissueVsnTab, Batch == &#39;3&#39;) %&gt;%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %&gt;%
  dplyr::rename(Batch3 = vsnAbundance)

# Batch 1 and 2
vsnScatTabB12 &lt;- dplyr::left_join(vsnB1, vsnB2, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-98-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Batch 2 and 3
vsnScatTabB23 &lt;- dplyr::left_join(vsnB2, vsnB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-98-2.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Batch 1 and 3
vsnScatTabB13 &lt;- dplyr::left_join(vsnB1, vsnB3, by = c(&#39;Feature_ID&#39;, &#39;Sample&#39;))
ggplot(vsnScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = &#39;Vsn normalized data&#39;) +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = &#39;pearson&#39;, size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = &#39;red&#39;, linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = &#39;bold&#39;),
                                   axis.title = element_text(size = 14, face = &#39;bold&#39;))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-98-3.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="data-fusion-3" class="section level2">
<h2>Data fusion</h2>
<p>Mean of triplicates is taken. <br/> <br/></p>
<p>Display distribution of merged data</p>
<pre class="r"><code># Merge triplicates (take mean)
merge_lipTissueVsnTab &lt;- dplyr::group_by(lipTissueVsnTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(vsnAbundance = mean(vsnAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Sample&#39;)

# Incorporate MZ/RT information
MZRT &lt;- dplyr::select(lipTissueTab, `MZ/RT`, Feature_ID) %&gt;%
  dplyr::filter(!duplicated(Feature_ID))
merge_lipTissueVsnTab &lt;- dplyr::left_join(merge_lipTissueVsnTab, MZRT,
                                          by = &#39;Feature_ID&#39;)

ggplot(merge_lipTissueVsnTab, aes(x=Sample, y=vsnAbundance)) +
  geom_boxplot() +
  labs(y = &#39;Normalized abundance&#39;, title = &#39;Vsn normalized data&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-100-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>Percentage of missing values</p>
<pre class="r"><code># Display percentage of missing values
abun &lt;- merge_lipTissueVsnTab$vsnAbundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), &#39;% observations are missing.&#39;))</code></pre>
<pre><code>0.11% observations are missing.</code></pre>
<p><strong>Remove features quantified in less than 2/3 of samples in all
four sample groups</strong> <strong>of interest (Normal/Tumor
Recurrence/Non-recurrence)</strong><br />
</p>
<pre class="r"><code># Remove features quantified in less than 2/3 of samples in all sample groups of interest
rmFeats &lt;- dplyr::group_by(merge_lipTissueVsnTab, Feature_ID, Condition, Recurrence) %&gt;%
  dplyr::summarise(frac_nonNA = round(sum(!is.na(vsnAbundance)) / length(vsnAbundance), 2)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::filter(frac_nonNA &lt; 0.67) %&gt;%
  dplyr::group_by(Feature_ID) %&gt;%
  dplyr::summarise(Count = length(Feature_ID)) %&gt;%
  dplyr::filter(Count == 4) %&gt;%
  dplyr::pull(Feature_ID)
merge_lipTissueVsnTab &lt;- dplyr::filter(merge_lipTissueVsnTab, !Feature_ID %in% rmFeats)

# Convert tidy long table to SummarizedExperiment object and save it for further analysis
lipTissueVsn &lt;- df2SummExp(merge_lipTissueVsnTab, row_id = &#39;Feature_ID&#39;, col_id = &#39;Sample&#39;,
                           values = &#39;vsnAbundance&#39;, row_anno = &#39;MZ/RT&#39;, col_anno = c(smpAnno, &#39;TumorPurity&#39;))
# Save vsn normalized data
saveRDS(lipTissueVsn, &#39;./data/MethodDev/AG_Hopf/lipTissueVsn.rds&#39;)</code></pre>
<p>Display dimensions of filtered dataset</p>
<pre class="r"><code>dim(lipTissueVsn)</code></pre>
<pre><code>[1] 1992   40</code></pre>
<p>Show feature mean-variance relationship of vsn normalized data</p>
<pre class="r"><code>vsn::meanSdPlot(as.matrix(assay(lipTissueVsn)), ranks = T, plot = F)$gg +
  labs(x = &#39;Rank of mean&#39;, y = &#39;SD&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-104-1.png" width="960" style="display: block; margin: auto;" /></p>
<p>PCA</p>
<pre class="r"><code># Perform PCA
# Remove rows (features) that have any NA values
abunVsnMatSub &lt;- dplyr::select(merge_lipTissueVsnTab,
                               Feature_ID, Sample, vsnAbundance) %&gt;%
  tidyr::pivot_wider(names_from = &#39;Sample&#39;, values_from = &#39;vsnAbundance&#39;) %&gt;%
  tibble::column_to_rownames(&#39;Feature_ID&#39;) %&gt;%
  dplyr::filter(complete.cases(.))

# Extract sample condition annotations
condition &lt;- dplyr::select(merge_lipTissueVsnTab,
                         Sample, Patient, Condition, Recurrence) %&gt;%
  dplyr::filter(!duplicated(Sample))

pcVsnRes &lt;- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab &lt;- pcVsnRes$x[, 1:10] %&gt;%
  tibble::as_tibble(rownames = &#39;Sample&#39;) %&gt;%
  dplyr::left_join(condition, by = &#39;Sample&#39;)

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Condition, shape=Recurrence,
                     group=Patient)) +
  geom_point(size = 3) +
  geom_line(col = &#39;grey50&#39;, linetype = &#39;dashed&#39;) +
  th</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-105-1.png" width="960" style="display: block; margin: auto;" />
<br/> -&gt; PCA mainly captures source of variation in tissue
conditions, which indicates decent data quality. <br/> <br/></p>
<p>Variance explained by each PC</p>
<pre class="r"><code># Display proportion of total variance captured by all PCs explained by each PC
varExplained &lt;- pcVsnRes$sdev^2 / sum(pcVsnRes$sdev^2)
PC &lt;- paste0(&#39;PC&#39;, seq(length(varExplained)))
varTab &lt;- data.frame(PC = factor(PC, levels = PC),
                     Var_explained = varExplained)

ggplot(varTab, aes(x=PC, y=Var_explained*100)) +
  geom_col() +
  labs(x = &#39;&#39;, y = &#39;Variance explained (%)&#39;) +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))</code></pre>
<p><img src="figure/MethodDev_01_preprocessing_untargeted.Rmd/unnamed-chunk-106-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Store median normalized data for computing log(FC) later
# Merge triplicates (take mean)
merge_lipTissueMediTab &lt;- dplyr::group_by(lipTissueMediTab, Feature_ID, Sample) %&gt;%
  dplyr::summarise(mediAbundance = mean(mediAbundance, na.rm = T)) %&gt;%
  dplyr::ungroup() %&gt;%
  dplyr::filter(!Feature_ID %in% rmFeats) %&gt;%
  dplyr::left_join(summMetadat, by = &#39;Sample&#39;)

# Incorporate m/z_RT information
MZRT &lt;- dplyr::select(lipTissueTab, `MZ/RT`, Feature_ID) %&gt;%
  dplyr::filter(!duplicated(Feature_ID))
merge_lipTissueMediTab &lt;- dplyr::left_join(merge_lipTissueMediTab, MZRT,
                                           by = &#39;Feature_ID&#39;)

# ggplot(merge_lipTissueMediTab, aes(x=Sample, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(y = &#39;Normalized abundance&#39;, title = &#39;Median normalized data&#39;) +
#   th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Convert tidy long table to SummarizedExperiment object and save it for further
# analysis
lipTissueMedi &lt;- df2SummExp(merge_lipTissueMediTab, row_id = &#39;Feature_ID&#39;, col_id = &#39;Sample&#39;,
                             values = &#39;mediAbundance&#39;, row_anno = &#39;MZ/RT&#39;, col_anno = c(smpAnno, &#39;TumorPurity&#39;))
saveRDS(lipTissueMedi, &#39;./data/MethodDev/AG_Hopf/lipTissueMedi.rds&#39;)</code></pre>
<br>
<p>
<button type="button" class="btn btn-default btn-workflowr btn-workflowr-sessioninfo" data-toggle="collapse" data-target="#workflowr-sessioninfo" style="display: block;">
<span class="glyphicon glyphicon-wrench" aria-hidden="true"></span>
Session information
</button>
</p>
<div id="workflowr-sessioninfo" class="collapse">
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 4.3.0 (2023-04-21)
Platform: aarch64-apple-darwin20 (64-bit)
Running under: macOS Ventura 13.4

Matrix products: default
BLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib 
LAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

time zone: Europe/Berlin
tzcode source: internal

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
 [1] proDA_1.14.0                pcaMethods_1.92.0          
 [3] lubridate_1.9.2             forcats_1.0.0              
 [5] stringr_1.5.0               dplyr_1.1.3                
 [7] purrr_1.0.2                 readr_2.1.4                
 [9] tidyr_1.3.0                 tibble_3.2.1               
[11] ggplot2_3.4.4               tidyverse_2.0.0            
[13] SummarizedExperiment_1.30.2 GenomicRanges_1.52.0       
[15] GenomeInfoDb_1.36.1         IRanges_2.34.1             
[17] S4Vectors_0.38.1            MatrixGenerics_1.12.2      
[19] matrixStats_1.0.0           DEP_1.22.0                 
[21] sva_3.48.0                  BiocParallel_1.34.2        
[23] genefilter_1.82.1           mgcv_1.9-0                 
[25] nlme_3.1-162                limma_3.56.2               
[27] vsn_3.68.0                  Biobase_2.60.0             
[29] BiocGenerics_0.46.0         readxl_1.4.3               
[31] workflowr_1.7.0            

loaded via a namespace (and not attached):
  [1] splines_4.3.0           later_1.3.1             norm_1.0-11.1          
  [4] bitops_1.0-7            cellranger_1.1.0        preprocessCore_1.62.1  
  [7] XML_3.99-0.14           lifecycle_1.0.3         rstatix_0.7.2          
 [10] edgeR_3.42.4            doParallel_1.0.17       rprojroot_2.0.3        
 [13] processx_3.8.2          lattice_0.21-8          MASS_7.3-60            
 [16] backports_1.4.1         magrittr_2.0.3          sass_0.4.7             
 [19] rmarkdown_2.23          jquerylib_0.1.4         yaml_2.3.7             
 [22] httpuv_1.6.11           MsCoreUtils_1.12.0      DBI_1.1.3              
 [25] RColorBrewer_1.1-3      abind_1.4-5             zlibbioc_1.46.0        
 [28] RCurl_1.98-1.12         sandwich_3.0-2          git2r_0.32.0           
 [31] circlize_0.4.15         GenomeInfoDbData_1.2.10 MSnbase_2.26.0         
 [34] annotate_1.78.0         ncdf4_1.21              codetools_0.2-19       
 [37] DelayedArray_0.26.6     DT_0.28                 tidyselect_1.2.0       
 [40] gmm_1.8                 shape_1.4.6             farver_2.1.1           
 [43] jsonlite_1.8.7          GetoptLong_1.0.5        ellipsis_0.3.2         
 [46] survival_3.5-5          iterators_1.0.14        foreach_1.5.2          
 [49] tools_4.3.0             Rcpp_1.0.11             glue_1.6.2             
 [52] xfun_0.39               shinydashboard_0.7.2    withr_2.5.1            
 [55] BiocManager_1.30.21     fastmap_1.1.1           fansi_1.0.5            
 [58] callr_3.7.3             digest_0.6.33           timechange_0.2.0       
 [61] R6_2.5.1                mime_0.12               imputeLCMD_2.1         
 [64] colorspace_2.1-0        RSQLite_2.3.1           hexbin_1.28.3          
 [67] utf8_1.2.4              generics_0.1.3          httr_1.4.6             
 [70] htmlwidgets_1.6.2       S4Arrays_1.0.4          whisker_0.4.1          
 [73] pkgconfig_2.0.3         gtable_0.3.4            blob_1.2.4             
 [76] ComplexHeatmap_2.16.0   impute_1.74.1           XVector_0.40.0         
 [79] htmltools_0.5.5         carData_3.0-5           MALDIquant_1.22.1      
 [82] ProtGenerics_1.32.0     clue_0.3-64             scales_1.2.1           
 [85] tmvtnorm_1.5            png_0.1-8               knitr_1.43             
 [88] rstudioapi_0.15.0       tzdb_0.4.0              rjson_0.2.21           
 [91] cachem_1.0.8            zoo_1.8-12              GlobalOptions_0.1.2    
 [94] parallel_4.3.0          AnnotationDbi_1.62.2    mzID_1.38.0            
 [97] pillar_1.9.0            grid_4.3.0              vctrs_0.6.4            
[100] promises_1.2.0.1        ggpubr_0.6.0            car_3.1-2              
[103] xtable_1.8-4            cluster_2.1.4           evaluate_0.21          
[106] mvtnorm_1.2-2           cli_3.6.1               locfit_1.5-9.8         
[109] compiler_4.3.0          rlang_1.1.1             crayon_1.5.2           
[112] ggsignif_0.6.4          labeling_0.4.3          ps_1.7.5               
[115] affy_1.78.1             getPass_0.2-2           plyr_1.8.8             
[118] fs_1.6.2                stringi_1.7.12          assertthat_0.2.1       
[121] munsell_0.5.0           Biostrings_2.68.1       Matrix_1.6-0           
[124] hms_1.1.3               bit64_4.0.5             KEGGREST_1.40.0        
[127] shiny_1.7.4.1           highr_0.10              mzR_2.34.1             
[130] broom_1.0.5             memoise_2.0.1           affyio_1.70.0          
[133] bslib_0.5.0             bit_4.0.5              </code></pre>
</div>
</div>
</div>


<!-- Adjust MathJax settings so that all math formulae are shown using
TeX fonts only; see
https://docs.mathjax.org/en/latest/web/configuration.html. This will make
the presentation more consistent at the cost of the webpage sometimes
taking slightly longer to load. Note that this only works because the
footer is added to webpages before the MathJax javascript. -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": { availableFonts: ["TeX"] }
  });
</script>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
