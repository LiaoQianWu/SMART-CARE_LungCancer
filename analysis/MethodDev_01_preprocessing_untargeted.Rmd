---
title: 'Preprocessing: Untargeted Metabolomics and Lipidomics of Method Development cohort'
author: "Qian-Wu Liao"
output:
  workflowr::wflow_html:
    toc: true
    toc_float: true
    code_folding: hide
---

<font size='4'> Description: Preprocess Plasma and Tissue Untargeted Metabolomics
and Lipidomics generated by Qiuqin Zhou and Kelechi Amatobi from AG Hopf. This script
includes (1) performing varied data normalization techniques (log2-transformation,
VSN, and median normalization) on data and comparing them in terms of whether all
samples are brought to same scale and similarity of triplicate measures of each sample,
(2) conducting batch correction if needed, and (3) merging triplicates into individual
measures and storing all information in SummarizedExperiment objects for further
analyses. Among varied normalization methods, vsn normalized data was selected.
Note that, since features have not been annotated yet by comparing against databases,
we defined them by m/z and retention time.\

Update: Remove those features whose Retention Times are shorter than 0.3 min and
longer than 8.5 min for Metabolomics and 9 min for Lipidomics.\

Update2: Remove those features quantified in less than 2/3 of samples in all sample
groups of interest after data fusion. </font>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 8, fig.width = 10, warning = F)
knitr::opts_knit$set(root.dir = '/Users/qianwu/Desktop/SMART-CARE_LungCancer')
```

Load libraries
```{r library loading, message = F, warning = F}
library('readxl')
library('vsn')
library('limma')
library('sva')
library('DEP')
library('SummarizedExperiment')
library('tidyverse')
# Load user-defined functions
source('./code/misc.R')

# Set plot theme
th <- theme_bw(base_size = 15) +
  theme(axis.title = element_text(face = 'bold'),
        axis.text = element_text(face = 'bold'),
        axis.ticks = element_line(linewidth = 0.8),
        legend.text = element_text(size = 15))
```

```{r prepare global info, message=F}
# Load sample metadata
smpMetadat <- readxl::read_excel('./data/sample_metadata.xlsx')
colnames(smpMetadat) <- smpMetadat[3,, drop = F]
smpMetadat <- dplyr::slice(smpMetadat, -c(1:3)) %>%
  dplyr::select(c(Code, Parents, Visit, `Material submitted`, `Date and time of collection or surgery`,
                  `SMART-CARE cohort identifier`)) %>%
  dplyr::rename(Sample = Code, Patient = Parents, TimePoint = Visit, SmpType = `Material submitted`,
                Date = `Date and time of collection or surgery`, Cohort = `SMART-CARE cohort identifier`) %>%
  dplyr::mutate(Sample = stringr::str_remove_all(Sample, '^SC_T_S_|^SC_DIS_S_|^SC_S_|_P'),
                Patient = stringr::str_remove(Patient, '^/THRX_SPACE/THRX_DB/'),
                TimePoint = dplyr::case_when(TimePoint == 'PRETHERAPEUTIC' ~ 'Baseline',
                                             TimePoint == 'FOLLOW-UP' ~ 'Follow-up',
                                             TimePoint == 'RECURRENCE' ~ 'Recurrence'),
                SmpType = dplyr::case_when(SmpType == 'EDTA_PLASMA' ~ 'Plasma',
                                           SmpType == 'FRESH_FROZEN_TISSUE' ~ 'Tissue'),
                Condition = dplyr::case_when(grepl('_TU|TG', Sample) ~ 'Tumor',
                                             grepl('_NG', Sample) ~ 'Normal',
                                             !grepl('_TU|_NG', Sample) ~ TimePoint),
                Date = stringr::str_extract(Date, '^\\d+-\\d+-\\d+'),
                Cohort = dplyr::case_when(Cohort == 'DISCOVERY_COHORT' ~ 'Discovery',
                                          Cohort == 'METHOD_DEVELOPMENT_COHORT' ~ 'MethodDev'),
                Date = as.Date(Date, format = '%Y-%m-%d'))

# Load patient metadata
patientMetadat <- readxl::read_excel('./data/patient_metadata.xlsx')
colnames(patientMetadat) <- patientMetadat[3,, drop = F]
patientMetadat <- dplyr::slice(patientMetadat, -c(1:3)) %>%
  dplyr::select(c(Code, Gender, `Age at diagnosis`, `Pathological stage`, `Smoking status`,
                  `Adjuvant chemotherapy`,)) %>%
  dplyr::rename(Patient = Code, Age = `Age at diagnosis`, Stage = `Pathological stage`,
                Smoking = `Smoking status`, Adjuvant = `Adjuvant chemotherapy`) %>%
  dplyr::mutate(Gender = dplyr::case_when(Gender == 'MALE' ~ 'Male',
                                          Gender == 'FEMALE' ~ 'Female'),
                Smoking = dplyr::case_when(Smoking == 'SMOKER' ~ 'Smoker',
                                           Smoking == 'EX-SMOKER' ~ 'Ex-smoker',
                                           Smoking == 'NON-SMOKER' ~ 'Non-smoker'),
                Adjuvant = dplyr::case_when(Adjuvant == 'true' ~ 'True',
                                            Adjuvant == 'false' ~ 'False'),
                Age = as.numeric(Age))
# Include patient recurrence information in patient metadata
recurPats <- dplyr::filter(smpMetadat, TimePoint == 'Recurrence') %>%
  dplyr::pull(Patient)
patientMetadat <- dplyr::mutate(patientMetadat, Recurrence = dplyr::case_when(Patient %in% recurPats ~ 'Yes',
                                                                              !Patient %in% recurPats ~ 'No'))

# Load aliquot metadata
aliquotMetadat <- readxl::read_excel('./data/aliquot_metadata.xlsx')
colnames(aliquotMetadat) <- aliquotMetadat[3,, drop = F]
aliquotMetadat <- dplyr::slice(aliquotMetadat, -c(1:3)) %>%
  dplyr::select(Code, Parents, `Tumor Cell Content (%)`, `Cohort Identifier`, `Submission to`,
                `Delivered?`) %>%
  dplyr::rename(Aliquot = Code, Sample = Parents, TumorPurity = `Tumor Cell Content (%)`,
                Cohort = `Cohort Identifier`, To = `Submission to`, Delivered = `Delivered?`) %>%
  dplyr::mutate(Sample = stringr::str_remove_all(Sample, '^/THRX_SPACE/THRX_DB/SC_T_S_|_P'),
                Sample = stringr::str_remove(Sample, '^/THRX_SPACE/THRX_DB/SC_DIS_S_'),
                Sample = stringr::str_remove(Sample, '^/THRX_SPACE/THRX_DB/SC_S_'),
                Sample = stringr::str_remove(Sample, '^/THRX_SPACE/THRX_DB/SC_DIS_'),
                Sample = dplyr::case_when(Sample == 'SDIR55_TU' ~ 'PDIR55_TU',
                                          Sample == 'SDIR55_NG' ~ 'PDIR55_NG',
                                          !Sample %in% c('SDIR55_TU', 'SDIR55_NG') ~ Sample),
                Cohort = dplyr::case_when(Cohort == 'method establishment' ~ 'MethodDev',
                                          Cohort == 'DISCOVERY_COHORT' ~ 'Discovery'),
                TumorPurity = as.numeric(TumorPurity),
                Sample = dplyr::case_when(grepl('^SC_DIS_A_Y4W4L7_P_V2', Aliquot) ~ 'Y4W4L7_V2',
                                          !grepl('^SC_DIS_A_Y4W4L7_P_V2', Aliquot) ~ Sample)) %>%
  dplyr::filter(To %in% c('HOPF'))
# Prepare aliquot metadata containing tumor purity information
tumorPurityInfo <- dplyr::select(aliquotMetadat, Aliquot, Sample, TumorPurity)

# Combine all needed metadata
summMetadat <- dplyr::left_join(tumorPurityInfo, smpMetadat, by = 'Sample') %>%
  dplyr::left_join(patientMetadat, by = 'Patient')

# List sample annotations to keep in SE objects
smpAnno <- c('Patient', 'SmpType', 'TimePoint', 'Date', 'Cohort', 'Condition',
             'Recurrence', 'Gender', 'Age', 'Smoking', 'Stage', 'Adjuvant')
```

# Plasma Metabolomics

```{r message = F}
# Load dataset
metaPlasmaTab <- readxl::read_excel('./data/MethodDev/AG_Hopf/PLASMA_METABOLOMICS_20221108.Feature list.xlsx')
# Take care of sample and feature identifications
# Put new suffixes to column names to indicate technical triplicates
colNam <- colnames(metaPlasmaTab) %>%
  stringr::str_remove('\\.\\.\\..*$')
colNam[1] <- 'm/z_RT'
smpNam <- colNam[2:length(colNam)]
colNam[2:length(colNam)] <- paste0(smpNam, '_', rep(c(1,2,3), length(smpNam)/3))
colnames(metaPlasmaTab) <- colNam

# Remove those features whose retention times are smaller than 0.3 and greater than 8.5 min
RT <- stringr::str_extract(metaPlasmaTab$`m/z_RT`, '/.*') %>%
  stringr::str_remove('/') %>%
  as.numeric()
metaPlasmaTab <- metaPlasmaTab[RT >= 0.3 & RT <= 8.5,]
# Remove those features whose intensities are smaller than 300?
# MZ <- stringr::str_extract(metaPlasmaTab$`m/z_RT`, '.*/') %>%
#   stringr::str_remove('/') %>%
#   as.numeric()
# sum(MZ < 300) #458

# Create feature IDs for m/z_RT to simplify downstream operations
metaPlasmaTab$Feature_ID <- paste0('Feature', seq(nrow(metaPlasmaTab)))
```

Display data dimensions (120 triplicate samples and 974 features)
```{r}
dim(dplyr::select(metaPlasmaTab, -c(`m/z_RT`, Feature_ID)))
```

List duplicated features that have same m/z and retention time
```{r}
# Check duplicated m/z_RT (features) to see if further actions are needed
cat('The following features have duplication:\n',
    paste(metaPlasmaTab$`m/z_RT`[duplicated(metaPlasmaTab$`m/z_RT`)],
          collapse = '  '))
```

Display distribution of original data
```{r}
# Convert messy wide data to tidy long table
metaPlasmaTab <- tidyr::pivot_longer(metaPlasmaTab, cols = -c('m/z_RT', 'Feature_ID'),
                                     names_to = 'Sample_ID', values_to = 'Abundance') %>%
  # Convert zero values to NA since zeros are not real zeros, but undetected,
  # might be extremely small or normal values and perform log2-transformation on
  # feature abundance
  dplyr::mutate(Abundance = replace(Abundance, Abundance == 0, NA),
                Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, 'SC_T_A_.*_2_'),
                log2Abundance = log2(Abundance)) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display original data distribution
ggplot(metaPlasmaTab, aes(x=Sample_ID, y=Abundance)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = 'Sample', title = 'Original data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Display distribution of log2-transformed data
```{r}
# Display log2-transformed data distribution
ggplot(metaPlasmaTab, aes(x=Sample_ID, y=log2Abundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Log2(Abundance)', title = 'Log2-transformed data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Percentage of missing values in data
```{r}
# Display percentage of missing values
abun <- metaPlasmaTab$Abundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), '% observations are missing.'))
```

```{r include = F, eval = F}
# Calculate mean and median of original feature abundance of each sample to see
# what processing data may have been done
abunSumm <- group_by(metaPlasmaTab, Sample_ID) %>%
  summarise(Mean = mean(Abundance, na.rm = T),
            Median = median(Abundance, na.rm = T)) %>%
  tidyr::pivot_longer(cols = -'Sample_ID',
                      names_to = 'Summary',
                      values_to = 'Value')

ggplot(abunSumm, aes(x=Sample_ID, y=Value, col=Summary)) +
  geom_point() +
  labs(x = 'Sample', title = 'Original data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```
<br/>
- Is data on the same scale (mean and median)?\
- Does data have stable variance?\
- Use glog2-transformation if there are lots of zeros.

## Normalization

### VSN

Display distribution of vsn normalized data
```{r}
# Convert long table to wide data
abunMat <- dplyr::select(metaPlasmaTab, Feature_ID, Sample_ID, Abundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'Abundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()

# Perform VSN
fit <- vsnMatrix(abunMat) # fit contains fitted calibration and transformation parameters
abunVsnMat <- predict(fit, abunMat) %>% # predict applies fit to data
  tibble::as_tibble(rownames = 'Feature_ID')
metaPlasmaVsnTab <- tidyr::pivot_longer(abunVsnMat,
                                        cols = -'Feature_ID',
                                        names_to = 'Sample_ID',
                                        values_to = 'vsnAbundance') %>%
  dplyr::mutate(Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, 'SC_T_A_.*_2_')) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display VSN normalized data
ggplot(metaPlasmaVsnTab, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Vsn normalized data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

### Median normalization

Display distribution of median normalized data
```{r}
# Perform median normalization (median scaling and log2-transformation)
# Similar procedure as that of VSN where affine transformation is conducted followed
# by glog2-transformation. Yet, notice that median transformation may produce negative
# values that are problematic to log2-transformation
metaPlasmaMediTab <- limma::normalizeBetweenArrays(abunMat, method = 'scale') %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'mediAbundance') %>%
  dplyr::mutate(mediAbundance = log2(mediAbundance),
                Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, 'SC_T_A_.*_2_')) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display median normalized data
ggplot(metaPlasmaMediTab, aes(x=Sample_ID, y=mediAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Median normalized data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# - Check how median scaling works in limma?
```

## Histogram for standard deviations
Compute standard deviation of each feature among triplicate measures. Dashed line
indicates mean standard deviation.

```{r message = F}
# Calculate standard deviations of each feature among triplicates
# Log2-transformation
log2Std <- dplyr::group_by(metaPlasmaTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(log2Abundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'Log2') %>%
  dplyr::select(Method, Std)
# VSN
vsnStd <- dplyr::group_by(metaPlasmaVsnTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'VSN') %>%
  dplyr::select(Method, Std)
# Median normalization
mediStd <- dplyr::group_by(metaPlasmaMediTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(mediAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'Median norm') %>%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab <- rbind(log2Std, vsnStd, mediStd)
stdMean <- dplyr::group_by(stdTab, Method) %>%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2, position = 'identity') +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype="dashed", linewidth = 0.7, show.legend = F) +
  labs(x = 'Standard Deviation', y = 'Count',
       title = 'Standard deviation of each feature among triplicates') +
  th
```
<br/>
- Is the standard deviation near zero among triplicates?

## PCA
Assess similarity among triplicate measures normalized by different methods for quality control

### Log2-transformation

```{r}
# Perform PCA to assess similarity among triplicates
# Log2-transformation
# Remove rows (features) that have any NA values
naFeats <- unique(metaPlasmaTab$Feature_ID[is.na(metaPlasmaTab$Abundance)])
abunLog2MatSub <- dplyr::select(metaPlasmaTab,
                                Feature_ID, Sample_ID, log2Abundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'log2Abundance') %>%
  tibble::column_to_rownames('Feature_ID')

# Extract Sample condition annotations
condition <- dplyr::select(metaPlasmaTab,
                           Sample_ID, Patient, Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample_ID))

pcLog2Res <- prcomp(t(abunLog2MatSub), center = T, scale. = F)
pcLog2Tab <- pcLog2Res$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, '_2_.'),
                Batch = rep(c('1','2','3'), nrow(.)/3))

ggplot(pcLog2Tab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Log2-transformed data') +
  th
```
<br/>
- What is the meaning of separation?\
- What is the pattern of separation?


### VSN

```{r}
# VSN
abunVsnMatSub <- dplyr::select(metaPlasmaVsnTab,
                               Feature_ID, Sample_ID, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcVsnRes <- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab <- pcVsnRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, '_2_.'),
                Batch = rep(c('1','2','3'), nrow(.)/3)) %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data') +
  th

# ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Condition, group=Sample)) +
#   geom_point() +
#   geom_line(col = 'grey50', linetype = 'dashed') +
#   labs(title = 'Vsn normalized data')
```

### Median normalization

```{r}
# Median normalization
abunMediMatSub <- dplyr::select(metaPlasmaMediTab,
                                Feature_ID, Sample_ID, mediAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'mediAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcMediRes <- prcomp(t(abunMediMatSub), center = T, scale. = F)
pcMediTab <- pcMediRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, '_2_.'),
                Batch = rep(c('1','2','3'), nrow(.)/3))

ggplot(pcMediTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Median normalized data') +
  th
```

## Scatterplots between triplicates
Check correlations between triplicate measures processed using different data
normalization methods due to batch effects. Red diagonal shows perfect positive
correlation, which is for inspecting data distribution.

### Log2-transformation

Batch1 vs Batch2
```{r}
# Make scatterplots to see relationships between triplicates
# Log2-transformation
# Retrieve data according to Batch (different triplicates)
log2B1 <- dplyr::filter(metaPlasmaTab, Batch == '1') %>%
  dplyr::select(Feature_ID, Sample, log2Abundance) %>%
  dplyr::rename(Batch1 = log2Abundance)
log2B2 <- dplyr::filter(metaPlasmaTab, Batch == '2') %>%
  dplyr::select(Feature_ID, Sample, log2Abundance) %>%
  dplyr::rename(Batch2 = log2Abundance)
log2B3 <- dplyr::filter(metaPlasmaTab, Batch == '3') %>%
  dplyr::select(Feature_ID, Sample, log2Abundance) %>%
  dplyr::rename(Batch3 = log2Abundance)

# Batch 1 and 2
log2ScatTabB12 <- dplyr::left_join(log2B1, log2B2, by = c('Feature_ID', 'Sample'))
ggplot(log2ScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Log2-transformed data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

Batch2 vs Batch3
```{r}
# Batch 2 and 3
log2ScatTabB23 <- dplyr::left_join(log2B2, log2B3, by = c('Feature_ID', 'Sample'))
ggplot(log2ScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Log2-transformed data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

Batch1 vs Batch3
```{r}
# Batch 1 and 3
log2ScatTabB13 <- dplyr::left_join(log2B1, log2B3, by = c('Feature_ID', 'Sample'))
ggplot(log2ScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Log2-transformed data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```
<br/>
- Is there data shifting (linear relationship)?

### VSN

Batch1 vs Batch2
```{r}
# VSN
vsnB1 <- dplyr::filter(metaPlasmaVsnTab, Batch == '1') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch1 = vsnAbundance)
vsnB2 <- dplyr::filter(metaPlasmaVsnTab, Batch == '2') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch2 = vsnAbundance)
vsnB3 <- dplyr::filter(metaPlasmaVsnTab, Batch == '3') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch3 = vsnAbundance)

# Batch 1 and 2
vsnScatTabB12 <- dplyr::left_join(vsnB1, vsnB2, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

Batch2 vs Batch3
```{r}
# Batch 2 and 3
vsnScatTabB23 <- dplyr::left_join(vsnB2, vsnB3, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

Batch1 vs Batch3
```{r}
# Batch 1 and 3
vsnScatTabB13 <- dplyr::left_join(vsnB1, vsnB3, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

### Median normalization

Batch1 vs Batch2
```{r}
# Median Normalization
mediB1 <- dplyr::filter(metaPlasmaMediTab, Batch == '1') %>%
  dplyr::select(Feature_ID, Sample, mediAbundance) %>%
  dplyr::rename(Batch1 = mediAbundance)
mediB2 <- dplyr::filter(metaPlasmaMediTab, Batch == '2') %>%
  dplyr::select(Feature_ID, Sample, mediAbundance) %>%
  dplyr::rename(Batch2 = mediAbundance)
mediB3 <- dplyr::filter(metaPlasmaMediTab, Batch == '3') %>%
  dplyr::select(Feature_ID, Sample, mediAbundance) %>%
  dplyr::rename(Batch3 = mediAbundance)

# Batch 1 and 2
mediScatTabB12 <- dplyr::left_join(mediB1, mediB2, by = c('Feature_ID', 'Sample'))
ggplot(mediScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Median normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

Batch2 vs Batch3
```{r}
# Batch 2 and 3
mediScatTabB23 <- dplyr::left_join(mediB2, mediB3, by = c('Feature_ID', 'Sample'))
ggplot(mediScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Median normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

Batch1 vs Batch3
```{r}
# Batch 1 and 3
mediScatTabB13 <- dplyr::left_join(mediB1, mediB3, by = c('Feature_ID', 'Sample'))
ggplot(mediScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Median normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

## Batch correction
To be consistent, vsn normalized data is selected because VSN works well in all
Untargeted omics datasets in terms of bringing samples to same scale and containing
more features that have zero or low variance among triplicate samples.
<br/>
<br/>

Display distribution of vsn normalized data after batch correction
```{r}
# Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunVsnMat <- dplyr::select(metaPlasmaVsnTab,
                            Feature_ID, Sample_ID, vsnAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()
# Define sample batches
batch <- rep(c('1', '2', '3'), ncol(abunVsnMat)/3)
# Define design matrix to keep particular effects, e.g., treatments
condition <- dplyr::select(metaPlasmaVsnTab, Sample_ID, Sample, Batch, Patient,
                           Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample_ID))
designMat <- model.matrix(~condition$Condition)

# Perform batch correction (limma)
metaPlasmaVsnTabBC <- limma::removeBatchEffect(abunVsnMat,
                                               batch = batch,
                                               design = designMat) %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'vsnAbundance') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

# Display batch corrected VSN normalized data to check if there is any negative
# values
ggplot(metaPlasmaVsnTabBC, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Vsn normalized data (after batch correction)') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Compute standard deviation of each feature among triplicate samples
```{r message = F}
# Calculate standard deviations of each feature among triplicates
# Batch corrected VSN
vsnStdBC <- dplyr::group_by(metaPlasmaVsnTabBC, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'BC_VSN') %>%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab <- rbind(vsnStd, vsnStdBC)
stdMean <- dplyr::group_by(stdTab, Method) %>%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2, position = 'identity') +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype="dashed", linewidth = 0.7, show.legend = F) +
  labs(x = 'Standard Deviation', y = 'Count',
       title = 'Standard deviation of each feature among triplicates') +
  th
```

PCA
```{r}
# Perform PCA
# Remove rows (features) that have any NA values
naFeats <- unique(metaPlasmaVsnTabBC$Feature_ID[
  is.na(metaPlasmaVsnTabBC$vsnAbundance)])
abunVsnMatSubBC <- dplyr::select(metaPlasmaVsnTabBC,
                                 Feature_ID, Sample_ID, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcVsnResBC <- prcomp(t(abunVsnMatSubBC), center = T, scale. = F)
pcVsnTabBC <- pcVsnResBC$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcVsnTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data (after batch correction)') +
  th
```

Showcase changes in data points of PC1 top features with highest loadings. Large
dot indicates mean.
```{r message = F}
# Take a look at PC1 top features with highest weights in samples before and
# after batch correction
# Retrieve PC1 top features with highest weights
topFeatPC1 <- names(sort(pcVsnRes$rotation[, 1], decreasing = T)[1:20])

# Vsn normalized data before batch correction
# Filter data
metaPlasmaVsnTabSub <- filter(metaPlasmaVsnTab,
                              Feature_ID %in% topFeatPC1)
# Compute mean of each batch per group
abunVsnSubMean <- group_by(metaPlasmaVsnTabSub, Feature_ID, Batch) %>%
  summarise(Mean = mean(vsnAbundance, na.rm = T))

ggplot(metaPlasmaVsnTabSub, aes(x=Feature_ID, y=vsnAbundance, col=Batch)) +
  geom_point() +
  geom_point(data = abunVsnSubMean, aes(x=Feature_ID, y=Mean, col=Batch),
             size = 4, alpha = 0.7, show.legend = F) +
  labs(x = 'Feature ID', y = 'Normalized abundance',
       title = 'Before batch correction') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# After batch correction
metaPlasmaVsnTabBCSub <- filter(metaPlasmaVsnTabBC,
                                Feature_ID %in% topFeatPC1)
abunVsnSubMeanBC <- group_by(metaPlasmaVsnTabBCSub, Feature_ID, Batch) %>%
  summarise(Mean = mean(vsnAbundance, na.rm = T))

ggplot(metaPlasmaVsnTabBCSub, aes(x=Feature_ID, y=vsnAbundance, col=Batch)) +
  geom_point() +
  geom_point(data = abunVsnSubMeanBC, aes(x=Feature_ID, y=Mean, col=Batch),
             size = 4, alpha = 0.7, show.legend = F) +
  labs(x = 'Feature ID', y = 'Normalized abundance',
       title = 'After batch correction') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

```{r include = F, eval = F}
# PC1 lower-rank features
# Retrieve features
featPC1 <- names(sort(pcVsnRes$rotation[, 1], decreasing = T)[101:120])

# Vsn normalized data before batch correction
# Filter data
metaPlasmaVsnTabSub <- filter(metaPlasmaVsnTab,
                              Feature_ID %in% featPC1)
# Compute mean of each batch per group
abunVsnSubMean <- group_by(metaPlasmaVsnTabSub, Feature_ID, Batch) %>%
  summarise(Mean = mean(vsnAbundance, na.rm = T))

ggplot(metaPlasmaVsnTabSub, aes(x=Feature_ID, y=vsnAbundance, col=Batch)) +
  geom_point() +
  geom_point(data = abunVsnSubMean, aes(x=Feature_ID, y=Mean, col=Batch),
             size = 4, alpha = 0.7, show.legend = F) +
  labs(x = 'Feature ID', y = 'Normalized abundance',
       title = 'Before batch correction (lower-rank features)') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# After batch correction
metaPlasmaVsnTabBCSub <- filter(metaPlasmaVsnTabBC,
                                Feature_ID %in% featPC1)
abunVsnSubMeanBC <- group_by(metaPlasmaVsnTabBCSub, Feature_ID, Batch) %>%
  summarise(Mean = mean(vsnAbundance, na.rm = T))

ggplot(metaPlasmaVsnTabBCSub, aes(x=Feature_ID, y=vsnAbundance, col=Batch)) +
  geom_point() +
  geom_point(data = abunVsnSubMeanBC, aes(x=Feature_ID, y=Mean, col=Batch),
             size = 4, alpha = 0.7, show.legend = F) +
  labs(x = 'Feature ID', y = 'Normalized abundance',
       title = 'After batch correction (lower-rank features)') +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

featPC1_MZRT <- dplyr::select(metaPlasmaTab, `m/z_RT`, Feature_ID) %>%
  dplyr::filter(Feature_ID %in% featPC1, !duplicated(Feature_ID))
cat(paste(c('PC1 lower-rank features:', featPC1_MZRT$`m/z_RT`),
          collapse = '  '))





# Perform batch correction (ComBat) (trouble in missing values)
# abunVsnMat2 <- abunVsnMat
# colnames(abunVsnMat2) <- batch
# rowNam <- rownames(abunVsnMat2)
# 
# abunVsnMat2B1 <- abunVsnMat2[, which(colnames(abunVsnMat2) == '1')]
# abunVsnMat2B2 <- abunVsnMat2[, which(colnames(abunVsnMat2) == '2')]
# abunVsnMat2B3 <- abunVsnMat2[, which(colnames(abunVsnMat2) == '3')]
# 
# naRowB1 <- rowNam[apply(abunVsnMat2B1, MARGIN = 1,
#                         FUN = function(x){any(is.na(x))})]
# naRowB2 <- rowNam[apply(abunVsnMat2B2, 1, function(x){any(is.na(x))})]
# naRowB3 <- rowNam[apply(abunVsnMat2B3, 1, function(x){any(is.na(x))})]
# naRow <- unique(c(naRowB1, naRowB2, naRowB3))
# 
# abunVsnMat2 <- abunVsnMat2[!(rowNam %in% naRow),]
# 
# metaPlasmaVsnTabBC <- sva::ComBat(abunVsnMat2, batch = batch, mod = designMat,
#                                   par.prior = T)
```

## Data fusion
Mean of triplicates is taken.
<br/>
<br/>

Display distribution of merged data
```{r message = F}
# Merge triplicates (take mean)
merge_metaPlasmaVsnTab <- dplyr::group_by(metaPlasmaVsnTabBC, Feature_ID, Sample) %>%
  dplyr::summarise(vsnAbundance = mean(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::left_join(summMetadat, by = 'Sample')

# Incorporate m/z_RT information
MZRT <- dplyr::select(metaPlasmaTab, `m/z_RT`, Feature_ID) %>%
  dplyr::filter(!duplicated(Feature_ID))
merge_metaPlasmaVsnTab <- dplyr::left_join(merge_metaPlasmaVsnTab, MZRT,
                                           by = 'Feature_ID')

ggplot(merge_metaPlasmaVsnTab, aes(x=Sample, y=vsnAbundance)) +
  geom_boxplot() +
  labs(y = 'Normalized abundance', title = 'Vsn normalized data') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

Percentage of missing values
```{r}
# Display percentage of missing values
abun <- merge_metaPlasmaVsnTab$vsnAbundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), '% observations are missing.'))
```

**Remove features quantified in less than 2/3 of samples in all four sample groups**
**of interest (Baseline/Follow-up Recurrence/Non-recurrence)**\
Missing data is more likely to happen in features with small abundances due to detection
limit. Image comparison between two sample groups, certain metabolites are highly
missing in one group and present in the other
```{r message=F}
# Prepare sample time point information for feature filtering
merge_metaPlasmaVsnTab <- dplyr::mutate(merge_metaPlasmaVsnTab,
                                        TimePoint = dplyr::case_when(
                                          Condition == 'Baseline' ~ 'Baseline',
                                          Condition != 'Baseline' ~ '2 years later'))

# Remove features quantified in less than 2/3 of samples in all sample groups of interest
# Grouping like this since Baseline and Follow-up samples will be analyzed separately
rmFeats <- dplyr::group_by(merge_metaPlasmaVsnTab, Feature_ID, TimePoint, Recurrence) %>%
  # Compute proportion of observed data points of each group
  dplyr::summarise(frac_nonNA = round(sum(!is.na(vsnAbundance)) / length(vsnAbundance), 2)) %>%
  dplyr::ungroup() %>%
  # Keep features observed in less than 2/3 of samples of groups
  dplyr::filter(frac_nonNA < 0.67) %>%
  dplyr::group_by(Feature_ID) %>%
  dplyr::summarise(Count = length(Feature_ID)) %>%
  # Keep features observed in less than 2/3 of samples of all groups
  dplyr::filter(Count == 4) %>%
  dplyr::pull(Feature_ID)
merge_metaPlasmaVsnTab <- dplyr::filter(merge_metaPlasmaVsnTab, !Feature_ID %in% rmFeats)

# Convert tidy long table to SummarizedExperiment object and save it for further analysis
metaPlasmaVsn <- df2SummExp(merge_metaPlasmaVsnTab, row_id = 'Feature_ID', col_id = 'Sample',
                            values = 'vsnAbundance', row_anno = 'm/z_RT', col_anno = smpAnno)
# Save vsn normalized data
saveRDS(metaPlasmaVsn, './data/MethodDev/AG_Hopf/metaPlasmaVsn.rds')
```

Display dimensions of filtered dataset
```{r}
dim(metaPlasmaVsn)
```

Show feature mean-variance relationship of vsn normalized data
```{r}
vsn::meanSdPlot(as.matrix(assay(metaPlasmaVsn)), ranks = T, plot = F, bins = 30)$gg +
  labs(x = 'Rank of mean', y = 'SD') +
  th
```

PCA
```{r}
# Perform PCA
# Remove rows (features) that have any NA values
naFeats <- unique(merge_metaPlasmaVsnTab$Feature_ID[
  is.na(merge_metaPlasmaVsnTab$vsnAbundance)])
abunVsnMatSub <- dplyr::select(merge_metaPlasmaVsnTab,
                               Feature_ID, Sample, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

# Extract sample condition annotations
condition <- dplyr::select(merge_metaPlasmaVsnTab,
                           Sample, Patient, Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample)) %>%
  dplyr::mutate(Time_point = dplyr::case_when(
    Condition == 'Baseline' ~ '0',
    Condition != 'Baseline' ~ '2'
  ))

pcVsnRes <- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab <- pcVsnRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample') %>%
  dplyr::left_join(condition, by = 'Sample')

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Time_point, shape=Condition,
                     group=Patient)) +
  geom_point(size = 3) +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data') +
  scale_color_discrete(name = 'Time point',
                       labels = c('Baseline', '2 years later')) +
  th
```
<br/>
-> PCA mainly captures source of variation in time points when samples were taken.
<br/>
<br/>

Variance explained by each PC
```{r}
# Display proportion of total variance captured by all PCs explained by each PC
varExplained <- pcVsnRes$sdev^2 / sum(pcVsnRes$sdev^2)
PC <- paste0('PC', seq(length(varExplained)))
varTab <- data.frame(PC = factor(PC, levels = PC),
                     Var_explained = varExplained)

ggplot(varTab, aes(x=PC, y=Var_explained*100)) +
  geom_col() +
  labs(x = '', y = 'Variance explained (%)') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

```{r message = F}
# Store median normalized data for computing log(FC) later
# Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunMediMat <- dplyr::select(metaPlasmaMediTab,
                             Feature_ID, Sample_ID, mediAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'mediAbundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()
# Define sample batches
batch <- rep(c('1', '2', '3'), ncol(abunMediMat)/3)
# Define design matrix to keep particular effects, e.g., treatments
condition <- dplyr::select(metaPlasmaMediTab, Sample_ID, Sample, Batch, Patient,
                           Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample_ID))
designMat <- model.matrix(~condition$Condition)

# Perform batch correction (limma)
metaPlasmaMediTabBC <- limma::removeBatchEffect(abunMediMat,
                                                batch = batch,
                                                design = designMat) %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'mediAbundance') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

# Display batch corrected median normalized data to check if there is any negative
# values
# ggplot(metaPlasmaMediTabBC, aes(x=Sample_ID, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(x = 'Sample', y = 'Normalized Abundance',
#        title = 'Median normalized data (after batch correction)') +
#   th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# Perform PCA
# Remove rows (features) that have any NA values
abunMediMatBC <- dplyr::select(metaPlasmaMediTabBC,
                               Feature_ID, Sample_ID, mediAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'mediAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcMediResBC <- doPCA(abunMediMatBC)
pcMediTabBC <- pcMediResBC$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

# ggplot(pcMediTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
#   geom_point() +
#   geom_line(col = 'grey50', linetype = 'dashed') +
#   labs(title = 'Median normalized data (after batch correction)') +
#   th

# Merge triplicates (take mean)
merge_metaPlasmaMediTab <- dplyr::group_by(metaPlasmaMediTabBC, Feature_ID, Sample) %>%
  dplyr::summarise(mediAbundance = mean(mediAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::filter(!Feature_ID %in% rmFeats) %>%
  dplyr::left_join(summMetadat, 'Sample')

# Incorporate m/z_RT information
MZRT <- dplyr::select(metaPlasmaTab, `m/z_RT`, Feature_ID) %>%
  dplyr::filter(!duplicated(Feature_ID))
merge_metaPlasmaMediTab <- dplyr::left_join(merge_metaPlasmaMediTab, MZRT,
                                            by = 'Feature_ID')

# ggplot(merge_metaPlasmaMediTab, aes(x=Sample, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(y = 'Normalized abundance', title = 'Median normalized data') +
#   th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Convert tidy long table to SummarizedExperiment object and save it for further
# analysis
metaPlasmaMedi <- df2SummExp(merge_metaPlasmaMediTab, row_id = 'Feature_ID', col_id = 'Sample',
                             values = 'mediAbundance', row_anno = 'm/z_RT', col_anno = smpAnno)
# Save median normalized data
saveRDS(metaPlasmaMedi, './data/MethodDev/AG_Hopf/metaPlasmaMedi.rds')
```

```{r eval = F, include=F}
# Missing values imputation
# Load normalized data
metaPlasmaVsn <- readRDS('./data/AG_Hopf/metaPlasmaVsn.rds')
# Modify SE object for DEP package
metaPlasmaImpu <- metaPlasmaVsn
colData(metaPlasmaImpu) <- subset(colData(metaPlasmaImpu), select = Condition)
colnames(colData(metaPlasmaImpu)) <- 'condition'
colData(metaPlasmaImpu)['label'] <- colnames(metaPlasmaImpu)
colData(metaPlasmaImpu)['replicate'] <- 1
rowData(metaPlasmaImpu)['name'] <- rownames(metaPlasmaImpu)
rowData(metaPlasmaImpu)['ID'] <- stringr::str_remove(rownames(metaPlasmaImpu),
                                                     'Feature')
rowData(metaPlasmaImpu) <- subset(rowData(metaPlasmaImpu), select = -`m/z_RT`)

# Overview missing values across samples
DEP::plot_frequency(metaPlasmaImpu) +
  labs(y = 'Number of metabolites', title = 'Metabolite identifications overlap')

# Filter features
metaPlasmaImpuFilt <- filter_proteins(metaPlasmaImpu, 'fraction', min = 0.66)

# Explore pattern of missing values
tmp_metaPlasma <- metaPlasmaImpuFilt
newColNames <- paste0(colData(metaPlasmaVsn)$Patient, '_',
                      colData(metaPlasmaVsn)$Condition) %>%
  stringr::str_remove('aseline|ollow.up|ecurrence')
colnames(tmp_metaPlasma) <- newColNames
DEP::plot_missval(tmp_metaPlasma)

# Check if missing values are biased to lower intensities (distributions with
# and without missing values)
DEP::plot_detect(metaPlasmaImpuFilt)

# Impute missing values (mixed imputation on features)
# Pinpoint features missing not at random (MNAR)
colAnno <- tibble::as_tibble(colData(metaPlasmaImpuFilt))%>%
  dplyr::select(label, condition)
metaMNAR <- SummarizedExperiment::assay(metaPlasmaImpuFilt) %>%
  tibble::rownames_to_column('name') %>%
  tidyr::pivot_longer(cols = -'name',
                      names_to = 'label',
                      values_to = 'vsnAbundance') %>%
  dplyr::left_join(colAnno, by = 'label') %>%
  dplyr::group_by(name, condition) %>%
  dplyr::summarise(NAs = all(is.na(vsnAbundance))) %>%
  dplyr::filter(NAs == T) %>%
  dplyr::pull(name) %>%
  unique()
MNAR <- rownames(metaPlasmaImpuFilt) %in% metaMNAR

metaPlasmaImpuFilt2 <- DEP::impute(metaPlasmaImpuFilt, fun = 'mixed',
  randna = !MNAR, # we have to define MAR which is the opposite of MNAR
  mar = 'knn', # imputation function for MAR
  mnar = 'zero') # imputation function for MNAR

# Modify imputed SE object for further analysis
if (identical(rownames(colData(metaPlasmaImpuFilt2)),
              rownames(colData(metaPlasmaVsn)))) {
  colData(metaPlasmaImpuFilt2) <- subset(colData(metaPlasmaImpuFilt2),
                                       select = condition)
  colnames(colData(metaPlasmaImpuFilt2)) <- 'Condition'
  colData(metaPlasmaImpuFilt2)['Patient'] <- colData(metaPlasmaVsn)$Patient
  colData(metaPlasmaImpuFilt2)['Recurrence'] <- colData(metaPlasmaVsn)$Recurrence
}
rowData(metaPlasmaImpuFilt2) <- subset(rowData(metaPlasmaImpuFilt2),
                                       select = -c(name, ID))
featFilt <- rownames(metaPlasmaVsn) %in% rownames(metaPlasmaImpuFilt2)
if (identical(rownames(metaPlasmaImpuFilt2),
              rownames(metaPlasmaVsn)[featFilt])) {
  rowData(metaPlasmaImpuFilt2)['m/z_RT'] <- rowData(metaPlasmaVsn)$`m/z_RT`[featFilt]
}

# saveRDS(metaPlasmaImpuFilt2, './data/AG_Hopf/metaPlasmaVsnImpu.rds')
```

```{r include = F, eval = F}
# Make scatterplots to see relationships between triplicates
# Original data
B1 <- dplyr::filter(metaPlasmaTab, Batch == '1') %>%
  dplyr::select(Feature_ID, Sample, Abundance) %>%
  dplyr::rename(Batch1 = Abundance)
B2 <- dplyr::filter(metaPlasmaTab, Batch == '2') %>%
  dplyr::select(Feature_ID, Sample, Abundance) %>%
  dplyr::rename(Batch2 = Abundance)
B3 <- dplyr::filter(metaPlasmaTab, Batch == '3') %>%
  dplyr::select(Feature_ID, Sample, Abundance) %>%
  dplyr::rename(Batch3 = Abundance)

# Batch 1 and 2
scatTabB12 <- dplyr::left_join(B1, B2, by = c('Feature_ID', 'Sample'))
ggplot(scatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  # Scaling or not for visualization affects correlation computation
  # scale_x_log10() + scale_y_log10() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Original data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'spearman', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', size = 0.5)

# Sanity check
scatTabB12_2 <- filter(scatTabB12, !is.na(Batch1), !is.na(Batch2))
cor(scatTabB12_2$Batch1, scatTabB12_2$Batch2, method = 'spearman')

# Batch 2 and 3
scatTabB23 <- dplyr::left_join(B2, B3, by = c('Feature_ID', 'Sample'))
ggplot(scatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Original data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'spearman', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', size = 0.5)

# Batch 1 and 3
scatTabB13 <- dplyr::left_join(B1, B3, by = c('Feature_ID', 'Sample'))
ggplot(scatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Original data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'spearman', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', size = 0.5)


# Calculate mean and median of Vsn normalized and median normalized feature
# abundance of each sample
vsnAbunSumm <- group_by(metaPlasmaVsnTab, Sample_ID) %>%
  summarise(Mean = mean(vsnAbundance, na.rm = T),
            Median = median(vsnAbundance, na.rm = T)) %>%
  mutate(Method = 'VSN')
# Calculate mean and median of median normalized feature abundance of each sample
mediAbunSumm <- group_by(metaPlasmaMediTab, Sample_ID) %>%
  summarise(Mean = mean(mediAbundance, na.rm = T),
            Median = median(mediAbundance, na.rm = T)) %>%
  mutate(Method = 'Median norm')
# Bind two summarized tables into one for plotting dot plots
abunSumm4Plot <- rbind(vsnAbunSumm, mediAbunSumm)

# Mean
ggplot(abunSumm4Plot, aes(x=Sample_ID, y=Mean, col=Method)) +
  geom_point() +
  labs(x = 'Sample') +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
# Median
ggplot(abunSumm4Plot, aes(x=Sample_ID, y=Median, col=Method)) +
  geom_point() +
  labs(x = 'Sample') +
  theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```




# Plasma Lipidomics

## Normalization

```{r message = F}
# Load dataset
lipPlasmaTab <- readxl::read_excel('./data/MethodDev/AG_Hopf/PLASMA_LIPIDOMICS_20221108.Feature list.xlsx')
# Take care of sample and feature identifications
# Put new suffixes to column names to indicate technical triplicates
colNam <- colnames(lipPlasmaTab) %>%
  stringr::str_remove('\\.\\.\\..*$')
colNam[1] <- 'm/z_RT'
smpNam <- colNam[2:length(colNam)]
colNam[2:length(colNam)] <- paste0(smpNam, '_', rep(c(1,2,3), length(smpNam)/3))
colnames(lipPlasmaTab) <- colNam

# Remove those features whose retention times are smaller than 0.3 and greater than 9 min
RT <- stringr::str_extract(lipPlasmaTab$`m/z_RT`, '/.*') %>%
  stringr::str_remove('/') %>%
  as.numeric()
lipPlasmaTab <- lipPlasmaTab[RT >= 0.3 & RT <= 9,]
# Remove those features whose intensities are smaller than 300?
# MZ <- stringr::str_extract(lipPlasmaTab$`m/z_RT`, '.*/') %>%
#   stringr::str_remove('/') %>%
#   as.numeric()
# sum(MZ < 300) #NA

# Create feature IDs for m/z_RT to simplify downstream operations
lipPlasmaTab$Feature_ID <- paste0('Feature', seq(nrow(lipPlasmaTab)))
```

Display data dimensions (120 triplicate samples and 2456 features)
```{r}
dim(dplyr::select(lipPlasmaTab, -c(`m/z_RT`, Feature_ID)))
```

List duplicated features that have same m/z and retention time
```{r}
# Check duplicated m/z_RT (features) to see if further actions are needed
cat('The following features have duplication:\n',
    paste(unique(lipPlasmaTab$`m/z_RT`[duplicated(lipPlasmaTab$`m/z_RT`)]),
          collapse = '  '))
```

Display distribution of original data
```{r}
# Convert messy wide data to tidy long table
lipPlasmaTab <- tidyr::pivot_longer(lipPlasmaTab,
                                    cols = -c('m/z_RT', 'Feature_ID'),
                                    names_to = 'Sample_ID',
                                    values_to = 'Abundance') %>%
  # Convert zero values to NA since zeros are not real zeros, but undetected,
  # might be extremely small or normal values and perform log2-transformation on
  # feature abundance
  dplyr::mutate(Abundance = replace(Abundance, Abundance == 0, NA),
                Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, 'SC_T_A_.*_2_'),
                log2Abundance = log2(Abundance)) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display original data distribution
ggplot(lipPlasmaTab, aes(x=Sample_ID, y=Abundance)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = 'Sample', title = 'Original data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Display distribution of log2-transformed data
```{r}
# Display log2-transformed data distribution
ggplot(lipPlasmaTab, aes(x=Sample_ID, y=log2Abundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Log2(Abundance)', title = 'Log2-transformed data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Percentage of missing values in data
```{r}
# Display percentage of missing values
abun <- lipPlasmaTab$Abundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), '% observations are missing.'))
```

Display distribution of vsn normalized data
```{r}
# Convert long table to wide data
abunMat <- dplyr::select(lipPlasmaTab, Feature_ID, Sample_ID, Abundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'Abundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()

# Perform VSN
fit <- vsnMatrix(abunMat)
abunVsnMat <- predict(fit, abunMat) %>%
  tibble::as_tibble(rownames = 'Feature_ID')
lipPlasmaVsnTab <- tidyr::pivot_longer(abunVsnMat,
                                       cols = -'Feature_ID',
                                       names_to = 'Sample_ID',
                                       values_to = 'vsnAbundance') %>%
  dplyr::mutate(Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, 'SC_T_A_.*_2_')) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display VSN normalized data
ggplot(lipPlasmaVsnTab, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Vsn normalized data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Display distribution of median normalized data
```{r}
# Perform median normalization (median scaling and log2-transformation)
lipPlasmaMediTab <- limma::normalizeBetweenArrays(abunMat, method = 'scale') %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'mediAbundance') %>%
  dplyr::mutate(mediAbundance = log2(mediAbundance),
                Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, 'SC_T_A_.*_2_')) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display median normalized data
ggplot(lipPlasmaMediTab, aes(x=Sample_ID, y=mediAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Median normalized data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Compute standard deviation of each feature among triplicate measures. Dashed line
indicates mean standard deviation.
```{r message = F}
# Calculate standard deviations of each feature among triplicates
# Log2-transformation
log2Std <- dplyr::group_by(lipPlasmaTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(log2Abundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'Log2') %>%
  dplyr::select(Method, Std)
# VSN
vsnStd <- dplyr::group_by(lipPlasmaVsnTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'VSN') %>%
  dplyr::select(Method, Std)
# Median normalization
mediStd <- dplyr::group_by(lipPlasmaMediTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(mediAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'Median norm') %>%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab <- rbind(log2Std, vsnStd, mediStd)
stdMean <- dplyr::group_by(stdTab, Method) %>%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.4, binwidth = 0.2, position = 'identity') +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype="dashed", linewidth = 0.7, show.legend = F) +
  labs(x = 'Standard deviation', y = 'Count',
       title = 'Standard deviation of each feature among triplicates') +
  th
```

## PCA
Assess similarity among triplicate measures normalized by different methods for quality control

**Log2-transformed data**
```{r}
# Perform PCA to assess similarity among triplicates
# Log2-transformation
# Remove rows (features) that have any NA values
naFeats <- unique(lipPlasmaTab$Feature_ID[is.na(lipPlasmaTab$Abundance)])
abunLog2MatSub <- dplyr::select(lipPlasmaTab,
                                Feature_ID, Sample_ID, log2Abundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'log2Abundance') %>%
  tibble::column_to_rownames('Feature_ID')

# Extract sample condition annotations
condition <- dplyr::select(lipPlasmaTab,
                           Sample_ID, Patient, Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample_ID))

pcLog2Res <- prcomp(t(abunLog2MatSub), center = T, scale. = F)
pcLog2Tab <- pcLog2Res$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, '_2_.'),
                Batch = rep(c('1','2','3'), nrow(.)/3))

ggplot(pcLog2Tab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Log2-transformed data') +
  th

ggplot(pcLog2Tab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Log2-transformed data') +
  th
```

**Vsn normalized data**
```{r}
# VSN
abunVsnMatSub <- dplyr::select(lipPlasmaVsnTab,
                               Feature_ID, Sample_ID, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcVsnRes <- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab <- pcVsnRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, '_2_.'),
                Batch = rep(c('1','2','3'), nrow(.)/3)) %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data') +
  th

ggplot(pcVsnTab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data') +
  th
```

**Median normalized data**
```{r}
# Median normalization
abunMediMatSub <- dplyr::select(lipPlasmaMediTab,
                                Feature_ID, Sample_ID, mediAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'mediAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcMediRes <- prcomp(t(abunMediMatSub), center = T, scale. = F)
pcMediTab <- pcMediRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, '_2_.'),
                Batch = rep(c('1','2','3'), nrow(.)/3))

ggplot(pcMediTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Median normalized data') +
  th

ggplot(pcMediTab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Median normalized data') +
  th
```

Check correlations between triplicate measures processed using different data
normalization methods due to batch effects. Red diagonal shows perfect positive
correlation, which is for inspecting data distribution.
<br/>

**Log2-transformed data**
```{r}
# Make scatterplots to see relationships between triplicates
# Log2-transformation
# Retrieve data according to Batch (different triplicates)
log2B1 <- dplyr::filter(lipPlasmaTab, Batch == '1') %>%
  dplyr::select(Feature_ID, Sample, log2Abundance) %>%
  dplyr::rename(Batch1 = log2Abundance)
log2B2 <- dplyr::filter(lipPlasmaTab, Batch == '2') %>%
  dplyr::select(Feature_ID, Sample, log2Abundance) %>%
  dplyr::rename(Batch2 = log2Abundance)
log2B3 <- dplyr::filter(lipPlasmaTab, Batch == '3') %>%
  dplyr::select(Feature_ID, Sample, log2Abundance) %>%
  dplyr::rename(Batch3 = log2Abundance)

# Batch 1 and 2
log2ScatTabB12 <- dplyr::left_join(log2B1, log2B2, by = c('Feature_ID', 'Sample'))
ggplot(log2ScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Log2-transformed data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))

# Batch 2 and 3
log2ScatTabB23 <- dplyr::left_join(log2B2, log2B3, by = c('Feature_ID', 'Sample'))
ggplot(log2ScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Log2-transformed data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))

# Batch 1 and 3
log2ScatTabB13 <- dplyr::left_join(log2B1, log2B3, by = c('Feature_ID', 'Sample'))
ggplot(log2ScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Log2-transformed data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

**Vsn normalized data**
```{r}
# VSN
vsnB1 <- dplyr::filter(lipPlasmaVsnTab, Batch == '1') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch1 = vsnAbundance)
vsnB2 <- dplyr::filter(lipPlasmaVsnTab, Batch == '2') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch2 = vsnAbundance)
vsnB3 <- dplyr::filter(lipPlasmaVsnTab, Batch == '3') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch3 = vsnAbundance)

# Batch 1 and 2
vsnScatTabB12 <- dplyr::left_join(vsnB1, vsnB2, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))

# Batch 2 and 3
vsnScatTabB23 <- dplyr::left_join(vsnB2, vsnB3, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))

# Batch 1 and 3
vsnScatTabB13 <- dplyr::left_join(vsnB1, vsnB3, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

**Median normalized data**
```{r}
# Median Normalization
mediB1 <- dplyr::filter(lipPlasmaMediTab, Batch == '1') %>%
  dplyr::select(Feature_ID, Sample, mediAbundance) %>%
  dplyr::rename(Batch1 = mediAbundance)
mediB2 <- dplyr::filter(lipPlasmaMediTab, Batch == '2') %>%
  dplyr::select(Feature_ID, Sample, mediAbundance) %>%
  dplyr::rename(Batch2 = mediAbundance)
mediB3 <- dplyr::filter(lipPlasmaMediTab, Batch == '3') %>%
  dplyr::select(Feature_ID, Sample, mediAbundance) %>%
  dplyr::rename(Batch3 = mediAbundance)

# Batch 1 and 2
mediScatTabB12 <- dplyr::left_join(mediB1, mediB2, by = c('Feature_ID', 'Sample'))
ggplot(mediScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Median normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))

# Batch 2 and 3
mediScatTabB23 <- dplyr::left_join(mediB2, mediB3, by = c('Feature_ID', 'Sample'))
ggplot(mediScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Median normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))

# Batch 1 and 3
mediScatTabB13 <- dplyr::left_join(mediB1, mediB3, by = c('Feature_ID', 'Sample'))
ggplot(mediScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Median normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

## Batch correction
Vsn normalized data is selected.
<br/>
<br/>

Display distribution of vsn normalized data after batch correction
```{r}
# Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunVsnMat <- dplyr::select(lipPlasmaVsnTab,
                            Feature_ID, Sample_ID, vsnAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()
# Define sample batches
batch <- rep(c('1', '2', '3'), ncol(abunVsnMat)/3)
# Define design matrix to keep particular effects, e.g., treatments
condition <- dplyr::select(lipPlasmaVsnTab, Sample_ID, Sample, Batch, Patient,
                           Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample_ID))
designMat <- model.matrix(~condition$Condition)
# Perform batch correction (limma)
lipPlasmaVsnTabBC <- limma::removeBatchEffect(abunVsnMat,
                                              batch = batch,
                                              design = designMat) %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'vsnAbundance') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

# Display batch corrected VSN normalized data to check if there is any negative
# values
ggplot(lipPlasmaVsnTabBC, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Vsn normalized data (after batch correction)') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Compute standard deviation of each feature among triplicate samples
```{r message = F}
# Calculate standard deviations of each feature among triplicates
# Batch corrected VSN
vsnStdBC <- dplyr::group_by(lipPlasmaVsnTabBC, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'BC_VSN') %>%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab <- rbind(vsnStd, vsnStdBC)
stdMean <- dplyr::group_by(stdTab, Method) %>%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.4, binwidth = 0.2, position = 'identity') +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype="dashed", linewidth = 0.7, show.legend = F) +
  labs(x = 'Standard Deviation', y = 'Count',
       title = 'Standard deviation of each feature among triplicates') +
  th
```

PCA
```{r}
# Perform PCA
# Remove rows (features) that have any NA values
naFeats <- unique(lipPlasmaVsnTabBC$Feature_ID[
  is.na(lipPlasmaVsnTabBC$vsnAbundance)])
abunVsnMatSubBC <- dplyr::select(lipPlasmaVsnTabBC,
                                 Feature_ID, Sample_ID, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcVsnResBC <- prcomp(t(abunVsnMatSubBC), center = T, scale. = F)
pcVsnTabBC <- pcVsnResBC$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcVsnTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data (after batch correction)') +
  th

ggplot(pcVsnTabBC, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data (after batch correction)') +
  th
```

## Data fusion
Mean of triplicates is taken.
<br/>
<br/>

Display distribution of merged data
```{r message = F}
# Merge triplicates (take mean)
merge_lipPlasmaVsnTab <- dplyr::group_by(lipPlasmaVsnTabBC, Feature_ID, Sample) %>%
  dplyr::summarise(vsnAbundance = mean(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::left_join(summMetadat, by = 'Sample')

# Incorporate m/z_RT information
MZRT <- dplyr::select(lipPlasmaTab, `m/z_RT`, Feature_ID) %>%
  dplyr::filter(!duplicated(Feature_ID))
merge_lipPlasmaVsnTab <- dplyr::left_join(merge_lipPlasmaVsnTab, MZRT,
                                          by = 'Feature_ID')

ggplot(merge_lipPlasmaVsnTab, aes(x=Sample, y=vsnAbundance)) +
  geom_boxplot() +
  labs(y = 'Normalized abundance', title = 'Vsn normalized data') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

Percentage of missing values
```{r}
# Display percentage of missing values
abun <- merge_lipPlasmaVsnTab$vsnAbundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), '% observations are missing.'))
```

**Remove features quantified in less than 2/3 of samples in all four sample groups**
**of interest (Baseline/Follow-up Recurrence/Non-recurrence)**\
```{r message=F}
# Prepare sample time point information for feature filtering
merge_lipPlasmaVsnTab <- dplyr::mutate(merge_lipPlasmaVsnTab,
                                       TimePoint = dplyr::case_when(
                                         Condition == 'Baseline' ~ 'Baseline',
                                         Condition != 'Baseline' ~ '2 years later'))

# Remove features quantified in less than 2/3 of samples in all sample groups of interest
rmFeats <- dplyr::group_by(merge_lipPlasmaVsnTab, Feature_ID, TimePoint, Recurrence) %>%
  dplyr::summarise(frac_nonNA = round(sum(!is.na(vsnAbundance)) / length(vsnAbundance), 2)) %>%
  dplyr::ungroup() %>%
  dplyr::filter(frac_nonNA < 0.67) %>%
  dplyr::group_by(Feature_ID) %>%
  dplyr::summarise(Count = length(Feature_ID)) %>%
  dplyr::filter(Count == 4) %>%
  dplyr::pull(Feature_ID)
merge_lipPlasmaVsnTab <- dplyr::filter(merge_lipPlasmaVsnTab, !Feature_ID %in% rmFeats)

# Convert tidy long table to SummarizedExperiment object and save it for further analysis
lipPlasmaVsn <- df2SummExp(merge_lipPlasmaVsnTab, row_id = 'Feature_ID', col_id = 'Sample',
                            values = 'vsnAbundance', row_anno = 'm/z_RT', col_anno = smpAnno)
# Save vsn normalized data 
saveRDS(lipPlasmaVsn, './data/MethodDev/AG_Hopf/lipPlasmaVsn.rds')
```

Display dimensions of filtered dataset
```{r}
dim(lipPlasmaVsn)
```

Show feature mean-variance relationship of vsn normalized data
```{r}
vsn::meanSdPlot(as.matrix(assay(lipPlasmaVsn)), ranks = T, plot = F)$gg +
  labs(x = 'Rank of mean', y = 'SD') +
  th
```

PCA
```{r}
# Perform PCA
# Remove rows (features) that have any NA values
naFeats <- unique(merge_lipPlasmaVsnTab$Feature_ID[
  is.na(merge_lipPlasmaVsnTab$vsnAbundance)])
abunVsnMatSub <- dplyr::select(merge_lipPlasmaVsnTab,
                               Feature_ID, Sample, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

# Extract sample condition annotations
condition <- dplyr::select(merge_lipPlasmaVsnTab,
                           Sample, Patient, Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample)) %>%
  dplyr::mutate(Time_point = dplyr::case_when(
    Condition == 'Baseline' ~ '0',
    Condition != 'Baseline' ~ '2'
  ))

pcVsnRes <- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab <- pcVsnRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample') %>%
  dplyr::left_join(condition, by = 'Sample')

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Time_point, shape=Condition,
                     group=Patient)) +
  geom_point(size = 3) +
  geom_line(col = 'grey50', linetype = 'dashed') +
  scale_color_discrete(name = 'Time point',
                       labels = c('Baseline', '2 years later')) +
  th
```
<br/>
-> PCA mainly captures source of variation in time points when samples were taken. 
<br/>
<br/>

Variance explained by each PC
```{r}
# Display proportion of total variance captured by all PCs explained by each PC
varExplained <- pcVsnRes$sdev^2 / sum(pcVsnRes$sdev^2)
PC <- paste0('PC', seq(length(varExplained)))
varTab <- data.frame(PC = factor(PC, levels = PC),
                     Var_explained = varExplained)

ggplot(varTab, aes(x=PC, y=Var_explained*100)) +
  geom_col() +
  labs(x = '', y = 'Variance explained (%)') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

```{r message = F}
# Store median normalized data for computing log(FC) later
# Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunMediMat <- dplyr::select(lipPlasmaMediTab,
                             Feature_ID, Sample_ID, mediAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'mediAbundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()
# Define sample batches
batch <- rep(c('1', '2', '3'), ncol(abunMediMat)/3)
# Define design matrix to keep particular effects, e.g., treatments
condition <- dplyr::select(lipPlasmaMediTab, Sample_ID, Sample, Batch, Patient,
                           Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample_ID))
designMat <- model.matrix(~condition$Condition)

# Perform batch correction (limma)
lipPlasmaMediTabBC <- limma::removeBatchEffect(abunMediMat,
                                               batch = batch,
                                               design = designMat) %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'mediAbundance') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

# Display batch corrected median normalized data to check if there is any negative
# values
# ggplot(lipPlasmaMediTabBC, aes(x=Sample_ID, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(x = 'Sample', y = 'Normalized Abundance',
#        title = 'Median normalized data (after batch correction)') +
#   th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# Perform PCA
# Remove rows (features) that have any NA values
abunMediMatBC <- dplyr::select(lipPlasmaMediTabBC,
                               Feature_ID, Sample_ID, mediAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'mediAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcMediResBC <- doPCA(abunMediMatBC)
pcMediTabBC <- pcMediResBC$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

# ggplot(pcMediTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
#   geom_point() +
#   geom_line(col = 'grey50', linetype = 'dashed') +
#   labs(title = 'Median normalized data (after batch correction)') +
#   th

# Merge triplicates (take mean)
merge_lipPlasmaMediTab <- dplyr::group_by(lipPlasmaMediTabBC, Feature_ID, Sample) %>%
  dplyr::summarise(mediAbundance = mean(mediAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::filter(!Feature_ID %in% rmFeats) %>%
  dplyr::left_join(summMetadat, by = 'Sample')

# Incorporate m/z_RT information
MZRT <- dplyr::select(lipPlasmaTab, `m/z_RT`, Feature_ID) %>%
  dplyr::filter(!duplicated(Feature_ID))
merge_lipPlasmaMediTab <- dplyr::left_join(merge_lipPlasmaMediTab, MZRT,
                                           by = 'Feature_ID')

# ggplot(merge_lipPlasmaMediTab, aes(x=Sample, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(y = 'Normalized abundance', title = 'Median normalized data') +
#   th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Convert tidy long table to SummarizedExperiment object and save it for further
# analysis
lipPlasmaMedi <- df2SummExp(merge_lipPlasmaMediTab, row_id = 'Feature_ID', col_id = 'Sample',
                            values = 'mediAbundance', row_anno = 'm/z_RT', col_anno = smpAnno)
saveRDS(lipPlasmaMedi, './data/MethodDev/AG_Hopf/lipPlasmaMedi.rds')
```

```{r eval = F, include=F}
# Missing values imputation
# Load normalized data
lipPlasmaVsn <- readRDS('./data/AG_Hopf/lipPlasmaVsn.rds')
# Modify SE object for DEP package
lipPlasmaImpu <- lipPlasmaVsn
colData(lipPlasmaImpu) <- subset(colData(lipPlasmaImpu), select = Condition)
colnames(colData(lipPlasmaImpu)) <- 'condition'
colData(lipPlasmaImpu)['label'] <- colnames(lipPlasmaImpu)
colData(lipPlasmaImpu)['replicate'] <- 1
rowData(lipPlasmaImpu)['name'] <- rownames(lipPlasmaImpu)
rowData(lipPlasmaImpu)['ID'] <- stringr::str_remove(rownames(lipPlasmaImpu),
                                                    'Feature')
rowData(lipPlasmaImpu) <- subset(rowData(lipPlasmaImpu), select = -`m/z_RT`)

# Overview missing values across samples
DEP::plot_frequency(lipPlasmaImpu) +
  labs(y = 'Number of lipid', title = 'lipid identifications overlap')

# Filter features
lipPlasmaImpuFilt <- filter_proteins(lipPlasmaImpu, 'fraction', min = 0.66)

# Explore pattern of missing values
tmp_lipPlasma <- lipPlasmaImpuFilt
newColNames <- paste0(colData(lipPlasmaVsn)$Patient, '_',
                      colData(lipPlasmaVsn)$Condition) %>%
  stringr::str_remove('aseline|ollow.up|ecurrence')
colnames(tmp_lipPlasma) <- newColNames
DEP::plot_missval(tmp_lipPlasma)

# Check if missing values are biased to lower intensities (distributions with
# and without missing values)
DEP::plot_detect(lipPlasmaImpuFilt)

# Impute missing values (mixed imputation on features)
# Pinpoint features missing not at random (MNAR)
colAnno <- tibble::as_tibble(colData(lipPlasmaImpuFilt))%>%
  dplyr::select(label, condition)
lipMNAR <- SummarizedExperiment::assay(lipPlasmaImpuFilt) %>%
  tibble::rownames_to_column('name') %>%
  tidyr::pivot_longer(cols = -'name',
                      names_to = 'label',
                      values_to = 'vsnAbundance') %>%
  dplyr::left_join(colAnno, by = 'label') %>%
  dplyr::group_by(name, condition) %>%
  dplyr::summarise(NAs = all(is.na(vsnAbundance))) %>%
  dplyr::filter(NAs == T) %>%
  dplyr::pull(name) %>%
  unique()
MNAR <- rownames(lipPlasmaImpuFilt) %in% lipMNAR

lipPlasmaImpuFilt2 <- DEP::impute(lipPlasmaImpuFilt, fun = 'mixed',
  randna = !MNAR, # we have to define MAR which is the opposite of MNAR
  mar = 'knn', # imputation function for MAR
  mnar = 'zero') # imputation function for MNAR

# Modify imputed SE object for further analysis
if (identical(rownames(colData(lipPlasmaImpuFilt2)),
              rownames(colData(lipPlasmaVsn)))) {
  colData(lipPlasmaImpuFilt2) <- subset(colData(lipPlasmaImpuFilt2),
                                       select = condition)
  colnames(colData(lipPlasmaImpuFilt2)) <- 'Condition'
  colData(lipPlasmaImpuFilt2)['Patient'] <- colData(lipPlasmaVsn)$Patient
  colData(lipPlasmaImpuFilt2)['Recurrence'] <- colData(lipPlasmaVsn)$Recurrence
}
rowData(lipPlasmaImpuFilt2) <- subset(rowData(lipPlasmaImpuFilt2),
                                       select = -c(name, ID))
featFilt <- rownames(lipPlasmaVsn) %in% rownames(lipPlasmaImpuFilt2)
if (identical(rownames(lipPlasmaImpuFilt2),
              rownames(lipPlasmaVsn)[featFilt])) {
  rowData(lipPlasmaImpuFilt2)['m/z_RT'] <- rowData(lipPlasmaVsn)$`m/z_RT`[featFilt]
}

# saveRDS(lipPlasmaImpuFilt2, './data/AG_Hopf/lipPlasmaVsnImpu.rds')
```




# Tissue Metabolomics

## Normalization

```{r message = F}
# Load dataset
metaTissueTab <- read.table(
  './data/MethodDev/AG_Hopf/TISSUE_METABOLOMICS_20230222.Feature list.txt',
  header = T, sep = '\t', dec = ',') %>%
  dplyr::mutate(m.z.meas. = paste0(m.z.meas., '/', RT..min.)) %>%
  dplyr::select(-RT..min., -contains('Process_blank'), -starts_with('QC')) %>%
  dplyr::rename(`MZ/RT` = m.z.meas.)

# Prepare sample ID table for changing sample names
smpIDs <- readxl::read_excel('./data/MethodDev/AG_Hopf/TISSUE.Sample IDs.xlsx') %>%
  dplyr::select(`Number on MS vials`, `Code from OpenBis`) %>%
  dplyr::rename(Sample_ID = `Number on MS vials`,
                Aliquot = `Code from OpenBis`) %>%
  dplyr::mutate(Sample_ID = paste0('X', Sample_ID))

# Take care of sample and feature identifications
colNam <- colnames(metaTissueTab) %>%
  stringr::str_remove_all('Tissue_PITC_batch|_pos_.*')
smpNam <- colNam[2:length(colNam)] %>%
  stringr::str_remove('_.$') %>%
  plyr::mapvalues(smpIDs$Sample_ID, smpIDs$Aliquot)
colNam[2:length(colNam)] <- paste0(smpNam, '_', c(rep(1, length(smpNam)/3),
                                                  rep(2, length(smpNam)/3),
                                                  rep(3, length(smpNam)/3)))
colnames(metaTissueTab) <- colNam

# Remove those features whose retention times are smaller than 0.3 and greater than 8.5 min
RT <- stringr::str_extract(metaTissueTab$`MZ/RT`, '/.*') %>%
  stringr::str_remove('/') %>%
  as.numeric()
metaTissueTab <- metaTissueTab[RT >= 0.3 & RT <= 8.5,]
# Remove those features whose intensities are smaller than 300?
# MZ <- stringr::str_extract(metaTissueTab$`MZ/RT`, '.*/') %>%
#   stringr::str_remove('/') %>%
#   as.numeric()
# sum(MZ < 300) #328

# Create feature IDs for MZ/RT to simplify downstream operations
metaTissueTab$Feature_ID <- paste0('Feature', seq(nrow(metaTissueTab)))
```

Display data dimensions (120 triplicate samples and 882 features)
```{r}
dim(dplyr::select(metaTissueTab, -c(`MZ/RT`, Feature_ID)))
```

There is no duplicated feature that have same m/z and retention time
```{r}
# Check duplicated MZ/RT (features) to see if further actions are needed
cat('The following features have duplication: NA')
    # paste(unique(metaTissueTab$`MZ/RT`[duplicated(metaTissueTab$`MZ/RT`)]),
    #       collapse = '  '))
```

Display distribution of original data
```{r}
# Convert messy wide data to tidy long table
metaTissueTab <- tidyr::pivot_longer(metaTissueTab,
                                     cols = -c('MZ/RT', 'Feature_ID'),
                                     names_to = 'Sample_ID',
                                     values_to = 'Abundance') %>%
  # Convert zero values to NA since zeros are not real zeros, but undetected,
  # might be extremely small or normal values and perform log2-transformation on
  # feature abundance
  dplyr::mutate(Abundance = replace(Abundance, Abundance == 0, NA),
                Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, '^.*_.*_'),
                log2Abundance = log2(Abundance)) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display original data distribution
ggplot(metaTissueTab, aes(x=Sample_ID, y=Abundance)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = 'Sample', title = 'Original data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Display distribution of log2-transformed data
```{r}
# Display log2-transformed data distribution
ggplot(metaTissueTab, aes(x=Sample_ID, y=log2Abundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Log2(Abundance)', title = 'Log2-transformed data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Percentage of missing values in data
```{r}
# Display percentage of missing values 
abun <- metaTissueTab$Abundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), '% observations are missing.'))
```

Display distribution of vsn normalized data
```{r}
# Convert long table to wide data
abunMat <- dplyr::select(metaTissueTab, Feature_ID, Sample_ID, Abundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'Abundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()

# Perform VSN
fit <- vsnMatrix(abunMat)
abunVsnMat <- predict(fit, abunMat) %>%
  tibble::as_tibble(rownames = 'Feature_ID')
metaTissueVsnTab <- tidyr::pivot_longer(abunVsnMat,
                                        cols = -'Feature_ID',
                                        names_to = 'Sample_ID',
                                        values_to = 'vsnAbundance') %>%
  dplyr::mutate(Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, '^.*_.*_')) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display VSN normalized data
ggplot(metaTissueVsnTab, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Vsn normalized data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# Every 6 measures are from same patients.
```

```{r include = F}
# Display mean and median of original data
# Compute mean and median of each sample
mu <- dplyr::group_by(metaTissueTab, Sample_ID) %>%
  dplyr::summarise(Value = mean(Abundance, na.rm = T)) %>%
  dplyr::mutate(Stat = 'Mean')
medi <- dplyr::group_by(metaTissueTab, Sample_ID) %>%
  dplyr::summarise(Value = median(Abundance, na.rm = T)) %>%
  dplyr::mutate(Stat = 'Median')
mu_medi <- dplyr::bind_rows(mu, medi)
rm(mu, medi)

ggplot(mu_medi, aes(x=Sample_ID, y=Value, col=Stat)) +
  geom_point() +
  labs(x = 'Sample') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Display distribution of median normalized data
```{r}
# Perform median normalization (median scaling and log2-transformation)
metaTissueMediTab <- limma::normalizeBetweenArrays(abunMat, method = 'scale') %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'mediAbundance') %>%
  dplyr::mutate(mediAbundance = log2(mediAbundance),
                Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, '^.*_.*_')) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display median normalized data
ggplot(metaTissueMediTab, aes(x=Sample_ID, y=mediAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Median normalized data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Compute standard deviation of each feature among triplicate measures. Dashed line
indicates mean standard deviation.
```{r message = F}
# Calculate standard deviations of each feature among triplicates
# Log2-transformation
log2Std <- dplyr::group_by(metaTissueTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(log2Abundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'Log2') %>%
  dplyr::select(Method, Std)
# VSN
vsnStd <- dplyr::group_by(metaTissueVsnTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'VSN') %>%
  dplyr::select(Method, Std)
# Median normalization
mediStd <- dplyr::group_by(metaTissueMediTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(mediAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'Median norm') %>%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab <- rbind(log2Std, vsnStd, mediStd)
stdMean <- dplyr::group_by(stdTab, Method) %>%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2, position = 'identity') +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype="dashed", linewidth = 0.7, show.legend = F) +
  labs(x = 'Standard deviation', y = 'Count',
       title = 'Standard deviation of each feature among triplicates') +
  th
```
-> All three methods got similar standard deviations.

## PCA
Assess similarity among triplicate measures normalized by different methods for quality control

**Log2-transformed data**
```{r}
# Perform PCA to assess similarity among triplicates
# Log2-transformation
# Remove rows (features) that have any NA values
naFeats <- unique(metaTissueTab$Feature_ID[is.na(metaTissueTab$Abundance)])
abunLog2MatSub <- dplyr::select(metaTissueTab,
                                Feature_ID, Sample_ID, log2Abundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'log2Abundance') %>%
  tibble::column_to_rownames('Feature_ID')

# Extract sample condition annotations
condition <- dplyr::select(metaTissueTab,
                           Sample_ID, Sample, Batch) %>%
  dplyr::filter(!duplicated(Sample_ID))

pcLog2Res <- prcomp(t(abunLog2MatSub), center = T, scale. = F)
pcLog2Tab <- pcLog2Res$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcLog2Tab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Log2-transformed data') +
  th
```

**Vsn normalized data**
```{r}
# VSN
abunVsnMatSub <- dplyr::select(metaTissueVsnTab,
                               Feature_ID, Sample_ID, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcVsnRes <- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab <- pcVsnRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data') +
  th

# ggplot(pcVsnTab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
#   geom_point() +
#   geom_line(col = 'grey50', linetype = 'dashed') +
#   labs(title = 'Vsn normalized data')
```

**Median normalized data**
```{r}
# Median normalization
abunMediMatSub <- dplyr::select(metaTissueMediTab,
                                Feature_ID, Sample_ID, mediAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'mediAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcMediRes <- prcomp(t(abunMediMatSub), center = T, scale. = F)
pcMediTab <- pcMediRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcMediTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Median normalized data') +
  th
```

## Data fusion
Vsn normalized data is selected and mean of triplicates is taken.
<br/>
<br/>

Display distribution of merged data
```{r message = F}
# Merge triplicates (take mean)
merge_metaTissueVsnTab <- dplyr::group_by(metaTissueVsnTab, Feature_ID, Sample) %>%
  dplyr::summarise(vsnAbundance = mean(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::left_join(summMetadat, by = 'Sample')

# Incorporate MZ/RT information
MZRT <- dplyr::select(metaTissueTab, `MZ/RT`, Feature_ID) %>%
  dplyr::filter(!duplicated(Feature_ID))
merge_metaTissueVsnTab <- dplyr::left_join(merge_metaTissueVsnTab, MZRT,
                                           by = 'Feature_ID')

ggplot(merge_metaTissueVsnTab, aes(x=Sample, y=vsnAbundance)) +
  geom_boxplot() +
  labs(y = 'Normalized abundance', title = 'Vsn normalized data') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

Percentage of missing values
```{r}
# Display percentage of missing values
abun <- merge_metaTissueVsnTab$vsnAbundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), '% observations are missing.'))
```

**Remove features quantified in less than 2/3 of samples in all four sample groups**
**of interest (Normal/Tumor Recurrence/Non-recurrence)**\
```{r message=F}
# Remove features quantified in less than 2/3 of samples in all sample groups of interest
rmFeats <- dplyr::group_by(merge_metaTissueVsnTab, Feature_ID, Condition, Recurrence) %>%
  dplyr::summarise(frac_nonNA = round(sum(!is.na(vsnAbundance)) / length(vsnAbundance), 2)) %>%
  dplyr::ungroup() %>%
  dplyr::filter(frac_nonNA < 0.67) %>%
  dplyr::group_by(Feature_ID) %>%
  dplyr::summarise(Count = length(Feature_ID)) %>%
  dplyr::filter(Count == 4) %>%
  dplyr::pull(Feature_ID)
merge_metaTissueVsnTab <- dplyr::filter(merge_metaTissueVsnTab, !Feature_ID %in% rmFeats)

# Convert tidy long table to SummarizedExperiment object and save it for further analysis
metaTissueVsn <- df2SummExp(merge_metaTissueVsnTab, row_id = 'Feature_ID', col_id = 'Sample',
                            values = 'vsnAbundance', row_anno = 'MZ/RT', col_anno = c(smpAnno, 'TumorPurity'))
# Save vsn normalized data
saveRDS(metaTissueVsn, './data/MethodDev/AG_Hopf/metaTissueVsn.rds')
```

Display dimensions of filtered dataset
```{r}
dim(metaTissueVsn)
```

Show feature mean-variance relationship of vsn normalized data
```{r}
vsn::meanSdPlot(as.matrix(assay(metaTissueVsn)), ranks = T, plot = F, bins = 30)$gg +
  labs(x = 'Rank of mean', y = 'SD') +
  th
```

PCA
```{r}
# Perform PCA
# Remove rows (features) that have any NA values
naFeats <- unique(merge_metaTissueVsnTab$Feature_ID[
  is.na(merge_metaTissueVsnTab$vsnAbundance)])
abunVsnMatSub <- dplyr::select(merge_metaTissueVsnTab,
                               Feature_ID, Sample, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

# Extract sample condition annotations
condition <- dplyr::select(merge_metaTissueVsnTab,
                         Sample, Patient, Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample))

pcVsnRes <- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab <- pcVsnRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample') %>%
  dplyr::left_join(condition, by = 'Sample')

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Condition, shape=Recurrence,
                     group=Patient)) +
  geom_point(size = 3) +
  geom_line(col = 'grey50', linetype = 'dashed') +
  th
```
<br/>
-> PCA mainly captures source of variation in tissue conditions, which indicates decent data quality.
<br/>
<br/>

Variance explained by each PC
```{r}
# Display proportion of total variance captured by all PCs explained by each PC
varExplained <- pcVsnRes$sdev^2 / sum(pcVsnRes$sdev^2)
PC <- paste0('PC', seq(length(varExplained)))
varTab <- data.frame(PC = factor(PC, levels = PC),
                     Var_explained = varExplained)

ggplot(varTab, aes(x=PC, y=Var_explained*100)) +
  geom_col() +
  labs(x = '', y = 'Variance explained (%)') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

```{r message = F}
# Store median normalized data for computing log(FC) later
# Merge triplicates (take mean)
merge_metaTissueMediTab <- dplyr::group_by(metaTissueMediTab, Feature_ID, Sample) %>%
  dplyr::summarise(mediAbundance = mean(mediAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::filter(!Feature_ID %in% rmFeats) %>%
  dplyr::left_join(summMetadat, by = 'Sample')

# Incorporate m/z_RT information
MZRT <- dplyr::select(metaTissueTab, `MZ/RT`, Feature_ID) %>%
  dplyr::filter(!duplicated(Feature_ID))
merge_metaTissueMediTab <- dplyr::left_join(merge_metaTissueMediTab, MZRT,
                                            by = 'Feature_ID')

# ggplot(merge_metaTissueMediTab, aes(x=Sample, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(y = 'Normalized abundance', title = 'Median normalized data') +
#   th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Convert tidy long table to SummarizedExperiment object and save it for further
# analysis
metaTissueMedi <- df2SummExp(merge_metaTissueMediTab, row_id = 'Feature_ID', col_id = 'Sample',
                             values = 'mediAbundance', row_anno = 'MZ/RT', col_anno = c(smpAnno, 'TumorPurity'))
# Save median normalized data
saveRDS(metaTissueMedi, './data/MethodDev/AG_Hopf/metaTissueMedi.rds')
```




# Tissue Lipidomics

## Normalization

```{r message = F}
# Load dataset
lipTissueTab <- read.table(
  './data/MethodDev/AG_Hopf/TISSUE_LIPIDOMICS_20230222.Feature list.txt',
  header = T, sep = '\t', dec = ',') %>%
  dplyr::mutate(m.z.meas. = paste0(m.z.meas., '/', RT..min.)) %>%
  dplyr::select(-RT..min., -starts_with('Blank'), -starts_with('QC')) %>%
  dplyr::rename(`MZ/RT` = m.z.meas.)

# Prepare sample ID table for changing sample names
smpIDs <- readxl::read_excel('./data/MethodDev/AG_Hopf/TISSUE.Sample IDs.xlsx') %>%
  dplyr::select(`Number on MS vials`, `Code from OpenBis`) %>%
  dplyr::rename(Sample_ID = `Number on MS vials`,
                Aliquot = `Code from OpenBis`) %>%
  dplyr::mutate(Sample_ID = paste0('Sample', Sample_ID))

# Take care of sample and feature identifications
colNam <- colnames(lipTissueTab) %>%
  stringr::str_remove_all('\\._|_lipids|batch|_pos_.*')
smpNam <- colNam[2:length(colNam)] %>%
  stringr::str_remove('_.$') %>%
  plyr::mapvalues(smpIDs$Sample_ID, smpIDs$Aliquot)
colNam[2:length(colNam)] <- paste0(smpNam, '_', c(rep(1, length(smpNam)/3),
                                                  rep(2, length(smpNam)/3),
                                                  rep(3, length(smpNam)/3)))
colnames(lipTissueTab) <- colNam

# Remove those features whose retention times are smaller than 0.3 and greater than 9 min
RT <- stringr::str_extract(lipTissueTab$`MZ/RT`, '/.*') %>%
  stringr::str_remove('/') %>%
  as.numeric()
lipTissueTab <- lipTissueTab[RT >= 0.3 & RT <= 9,]
# Remove those features whose intensities are smaller than 300?
# MZ <- stringr::str_extract(lipTissueTab$`MZ/RT`, '.*/') %>%
#   stringr::str_remove('/') %>%
#   as.numeric()
# sum(MZ < 300) #58

# Create feature IDs for MZ/RT to simplify downstream operations
lipTissueTab$Feature_ID <- paste0('Feature', seq(nrow(lipTissueTab)))
```

Display data dimensions (120 triplicate samples and 2159 features)
```{r}
dim(dplyr::select(lipTissueTab, -c(`MZ/RT`, Feature_ID)))
```

List duplicated features that have same m/z and retention time
```{r}
# Check duplicated MZ/RT (features) to see if further actions are needed
cat('The following features have duplication:\n',
    paste(unique(lipTissueTab$`MZ/RT`[duplicated(lipTissueTab$`MZ/RT`)]),
          collapse = '  '))
```

Display distribution of original data
```{r}
# Convert messy wide data to tidy long table
lipTissueTab <- tidyr::pivot_longer(lipTissueTab,
                                    cols = -c('MZ/RT', 'Feature_ID'),
                                    names_to = 'Sample_ID',
                                    values_to = 'Abundance') %>%
  # Convert zero values to NA since zeros are not real zeros, but undetected,
  # might be extremely small or normal values and perform log2-transformation on
  # feature abundance
  dplyr::mutate(Abundance = replace(Abundance, Abundance == 0, NA),
                Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, '^.*_.*_'),
                log2Abundance = log2(Abundance)) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display original data distribution
ggplot(lipTissueTab, aes(x=Sample_ID, y=Abundance)) +
  geom_boxplot() +
  scale_y_log10() +
  labs(x = 'Sample', title = 'Original data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Display distribution of log2-transformed data
```{r}
# Display log2-transformed data distribution
ggplot(lipTissueTab, aes(x=Sample_ID, y=log2Abundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Log2(Abundance)', title = 'Log2-transformed data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Percentage of missing values in data
```{r}
# Display percentage of missing values 
abun <- lipTissueTab$Abundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), '% observations are missing.'))
```

Display distribution of vsn normalized data
```{r}
# Convert long table to wide data
abunMat <- dplyr::select(lipTissueTab, Feature_ID, Sample_ID, Abundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'Abundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()

# Perform VSN
fit <- vsnMatrix(abunMat)
abunVsnMat <- predict(fit, abunMat) %>%
  tibble::as_tibble(rownames = 'Feature_ID')
lipTissueVsnTab <- tidyr::pivot_longer(abunVsnMat,
                                       cols = -'Feature_ID',
                                       names_to = 'Sample_ID',
                                       values_to = 'vsnAbundance') %>%
  dplyr::mutate(Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, '^.*_.*_')) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display VSN normalized data
ggplot(lipTissueVsnTab, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Vsn normalized data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Display distribution of median normalized data
```{r}
# Perform median normalization (median scaling and log2-transformation)
lipTissueMediTab <- limma::normalizeBetweenArrays(abunMat, method = 'scale') %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'mediAbundance') %>%
  dplyr::mutate(mediAbundance = log2(mediAbundance),
                Aliquot = stringr::str_remove(Sample_ID, '_\\d$'),
                Batch = stringr::str_remove(Sample_ID, '^.*_.*_')) %>%
  dplyr::left_join(summMetadat, by = 'Aliquot')

# Display median normalized data
ggplot(lipTissueMediTab, aes(x=Sample_ID, y=mediAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Median normalized data') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())
```

Compute standard deviation of each feature among triplicate measures. Dashed line
indicates mean standard deviation.
```{r message = F}
# Calculate standard deviations of each feature among triplicates
# Log2-transformation
log2Std <- dplyr::group_by(lipTissueTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(log2Abundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'Log2') %>%
  dplyr::select(Method, Std)
# VSN
vsnStd <- dplyr::group_by(lipTissueVsnTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'VSN') %>%
  dplyr::select(Method, Std)
# Median normalization
mediStd <- dplyr::group_by(lipTissueMediTab, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(mediAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'Median norm') %>%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab <- rbind(log2Std, vsnStd, mediStd)
stdMean <- dplyr::group_by(stdTab, Method) %>%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2, position = 'identity') +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype="dashed", linewidth = 0.7, show.legend = F) +
  labs(x = 'Standard deviation', y = 'Count',
       title = 'Standard deviation of each feature among triplicates') +
  th
```
-> VSN and median normalization got similar mean standard deviations.

## PCA
Assess similarity among triplicate measures normalized by different methods for quality control

**Log2-transformed data**
```{r}
# Perform PCA to assess similarity among triplicates
# Log2-transformation
# Remove rows (features) that have any NA values
naFeats <- unique(lipTissueTab$Feature_ID[is.na(lipTissueTab$Abundance)])
abunLog2MatSub <- dplyr::select(lipTissueTab,
                                Feature_ID, Sample_ID, log2Abundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'log2Abundance') %>%
  tibble::column_to_rownames('Feature_ID')

# Extract sample condition annotations
condition <- dplyr::select(lipTissueTab,
                         Sample_ID, Sample, Batch) %>%
  dplyr::filter(!duplicated(Sample_ID))

pcLog2Res <- prcomp(t(abunLog2MatSub), center = T, scale. = F)
pcLog2Tab <- pcLog2Res$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcLog2Tab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Log2-transformed data') +
  th
```

**Vsn normalized data**
```{r}
# VSN
abunVsnMatSub <- dplyr::select(lipTissueVsnTab,
                               Feature_ID, Sample_ID, vsnAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcVsnRes <- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab <- pcVsnRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data') +
  th

# ggplot(pcVsnTab, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
#   geom_point() +
#   geom_line(col = 'grey50', linetype = 'dashed') +
#   labs(title = 'Vsn normalized data')
```

**Median normalized data**
```{r}
# Median normalization
abunMediMatSub <- dplyr::select(lipTissueMediTab,
                                Feature_ID, Sample_ID, mediAbundance) %>%
  dplyr::filter(!(Feature_ID %in% naFeats)) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'mediAbundance') %>%
  tibble::column_to_rownames('Feature_ID')

pcMediRes <- prcomp(t(abunMediMatSub), center = T, scale. = F)
pcMediTab <- pcMediRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcMediTab, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Median normalized data') +
  th
```

Check correlations between triplicate measures processed using VSN due to batch
effects. Red diagonal shows perfect positive correlation, which is for inspecting
data distribution.
<br/>

**Vsn normalized data**
```{r}
# VSN
vsnB1 <- dplyr::filter(lipTissueVsnTab, Batch == '1') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch1 = vsnAbundance)
vsnB2 <- dplyr::filter(lipTissueVsnTab, Batch == '2') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch2 = vsnAbundance)
vsnB3 <- dplyr::filter(lipTissueVsnTab, Batch == '3') %>%
  dplyr::select(Feature_ID, Sample, vsnAbundance) %>%
  dplyr::rename(Batch3 = vsnAbundance)

# Batch 1 and 2
vsnScatTabB12 <- dplyr::left_join(vsnB1, vsnB2, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB12, aes(x=Batch1, y=Batch2)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))

# Batch 2 and 3
vsnScatTabB23 <- dplyr::left_join(vsnB2, vsnB3, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB23, aes(x=Batch2, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))

# Batch 1 and 3
vsnScatTabB13 <- dplyr::left_join(vsnB1, vsnB3, by = c('Feature_ID', 'Sample'))
ggplot(vsnScatTabB13, aes(x=Batch1, y=Batch3)) +
  geom_point() +
  facet_wrap(vars(Sample), ncol = 8) +
  labs(title = 'Vsn normalized data') +
  ggpubr::stat_cor(aes(label=after_stat(r.label)), method = 'pearson', size = 3.5) +
  geom_abline(intercept = 0, slope = 1, col = 'red', linewidth = 0.5) +
  theme_bw(base_size = 12) + theme(strip.text = element_text(face = 'bold'),
                                   axis.title = element_text(size = 14, face = 'bold'))
```

```{r, include = F, eval = F}
## Batch correction
# Vsn normalized data is selected.
# <br/>
# <br/>

# Display distribution of vsn normalized data after batch correction

# Perform batch correction to see if triplicates can be clustered
# Convert long table to wide data
abunVsnMat <- dplyr::select(lipTissueVsnTab,
                            Feature_ID, Sample_ID, vsnAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  as.matrix()
# Define sample batches
batch <- stringr::str_remove(colnames(abunVsnMat), '^.*_.*_')
# Define design matrix to keep particular effects, e.g., treatments
condition <- dplyr::select(lipTissueVsnTab,
                           Sample_ID, Patient, Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample_ID))
designMat <- model.matrix(~condition$Condition+condition$Recurrence)
# Perform batch correction (limma)
lipTissueVsnTabBC <- limma::removeBatchEffect(abunVsnMat,
                                              batch = batch,
                                              design = designMat) %>%
  tibble::as_tibble(rownames = 'Feature_ID') %>%
  tidyr::pivot_longer(cols = -'Feature_ID',
                      names_to = 'Sample_ID',
                      values_to = 'vsnAbundance') %>%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, '_.$'),
                Batch = stringr::str_remove(Sample_ID, '^.*_.*_'))

# Display batch corrected VSN normalized data to check if there is any negative
# values
ggplot(lipTissueVsnTabBC, aes(x=Sample_ID, y=vsnAbundance)) +
  geom_boxplot() +
  labs(x = 'Sample', y = 'Normalized Abundance',
       title = 'Vsn normalized data (after batch correction)') +
  th + theme(axis.text.x = element_blank(), axis.ticks.x = element_blank())

# Compute standard deviation of each feature among triplicate samples

# Calculate standard deviations of each feature among triplicates
# Batch corrected VSN
vsnStdBC <- dplyr::group_by(lipTissueVsnTabBC, Feature_ID, Sample) %>%
  dplyr::summarise(Std = sd(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Method = 'BC_VSN') %>%
  dplyr::select(Method, Std)
# Bind standard deviation tables into one for plotting histogram
stdTab <- rbind(vsnStd, vsnStdBC)
stdMean <- dplyr::group_by(stdTab, Method) %>%
  dplyr::summarise(Mean = mean(Std, na.rm = T))

ggplot(stdTab, aes(x=Std, col=Method, fill=Method)) +
  geom_histogram(alpha = 0.5, binwidth = 0.2) + #, position = 'identity') +
  geom_vline(data = stdMean, aes(xintercept=Mean, col=Method),
             linetype="dashed", linewidth = 0.7, show.legend = F) +
  labs(x = 'Standard Deviation', y = 'Count',
       title = 'Standard deviation of each feature among triplicates') +
  th

# PCA

# Perform PCA
# Remove rows (features) that have any NA values
abunVsnMatSubBC <- dplyr::select(lipTissueVsnTabBC,
                                 Feature_ID, Sample_ID, vsnAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample_ID', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  dplyr::filter(complete.cases(.))

pcVsnResBC <- prcomp(t(abunVsnMatSubBC), center = T, scale. = F)
pcVsnTabBC <- pcVsnResBC$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample_ID') %>%
  dplyr::mutate(Sample = stringr::str_remove(Sample_ID, '_.$'),
                Batch = stringr::str_remove(Sample_ID, '.*_.._')) %>%
  dplyr::left_join(condition, by = 'Sample_ID')

ggplot(pcVsnTabBC, aes(x=PC1, y=PC2, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data (after batch correction)') +
  th

ggplot(pcVsnTabBC, aes(x=PC3, y=PC4, col=Batch, group=Sample)) +
  geom_point() +
  geom_line(col = 'grey50', linetype = 'dashed') +
  labs(title = 'Vsn normalized data (after batch correction)') +
  th
```

## Data fusion
Mean of triplicates is taken.
<br/>
<br/>

Display distribution of merged data
```{r message = F}
# Merge triplicates (take mean)
merge_lipTissueVsnTab <- dplyr::group_by(lipTissueVsnTab, Feature_ID, Sample) %>%
  dplyr::summarise(vsnAbundance = mean(vsnAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::left_join(summMetadat, by = 'Sample')

# Incorporate MZ/RT information
MZRT <- dplyr::select(lipTissueTab, `MZ/RT`, Feature_ID) %>%
  dplyr::filter(!duplicated(Feature_ID))
merge_lipTissueVsnTab <- dplyr::left_join(merge_lipTissueVsnTab, MZRT,
                                          by = 'Feature_ID')

ggplot(merge_lipTissueVsnTab, aes(x=Sample, y=vsnAbundance)) +
  geom_boxplot() +
  labs(y = 'Normalized abundance', title = 'Vsn normalized data') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

Percentage of missing values
```{r}
# Display percentage of missing values
abun <- merge_lipTissueVsnTab$vsnAbundance
cat(paste0(round(sum(is.na(abun))/length(abun), 2), '% observations are missing.'))
```

**Remove features quantified in less than 2/3 of samples in all four sample groups**
**of interest (Normal/Tumor Recurrence/Non-recurrence)**\
```{r message=F}
# Remove features quantified in less than 2/3 of samples in all sample groups of interest
rmFeats <- dplyr::group_by(merge_lipTissueVsnTab, Feature_ID, Condition, Recurrence) %>%
  dplyr::summarise(frac_nonNA = round(sum(!is.na(vsnAbundance)) / length(vsnAbundance), 2)) %>%
  dplyr::ungroup() %>%
  dplyr::filter(frac_nonNA < 0.67) %>%
  dplyr::group_by(Feature_ID) %>%
  dplyr::summarise(Count = length(Feature_ID)) %>%
  dplyr::filter(Count == 4) %>%
  dplyr::pull(Feature_ID)
merge_lipTissueVsnTab <- dplyr::filter(merge_lipTissueVsnTab, !Feature_ID %in% rmFeats)

# Convert tidy long table to SummarizedExperiment object and save it for further analysis
lipTissueVsn <- df2SummExp(merge_lipTissueVsnTab, row_id = 'Feature_ID', col_id = 'Sample',
                           values = 'vsnAbundance', row_anno = 'MZ/RT', col_anno = c(smpAnno, 'TumorPurity'))
# Save vsn normalized data
saveRDS(lipTissueVsn, './data/MethodDev/AG_Hopf/lipTissueVsn.rds')
```

Display dimensions of filtered dataset
```{r}
dim(lipTissueVsn)
```

Show feature mean-variance relationship of vsn normalized data
```{r}
vsn::meanSdPlot(as.matrix(assay(lipTissueVsn)), ranks = T, plot = F)$gg +
  labs(x = 'Rank of mean', y = 'SD') +
  th
```

PCA
```{r}
# Perform PCA
# Remove rows (features) that have any NA values
abunVsnMatSub <- dplyr::select(merge_lipTissueVsnTab,
                               Feature_ID, Sample, vsnAbundance) %>%
  tidyr::pivot_wider(names_from = 'Sample', values_from = 'vsnAbundance') %>%
  tibble::column_to_rownames('Feature_ID') %>%
  dplyr::filter(complete.cases(.))

# Extract sample condition annotations
condition <- dplyr::select(merge_lipTissueVsnTab,
                         Sample, Patient, Condition, Recurrence) %>%
  dplyr::filter(!duplicated(Sample))

pcVsnRes <- prcomp(t(abunVsnMatSub), center = T, scale. = F)
pcVsnTab <- pcVsnRes$x[, 1:10] %>%
  tibble::as_tibble(rownames = 'Sample') %>%
  dplyr::left_join(condition, by = 'Sample')

ggplot(pcVsnTab, aes(x=PC1, y=PC2, col=Condition, shape=Recurrence,
                     group=Patient)) +
  geom_point(size = 3) +
  geom_line(col = 'grey50', linetype = 'dashed') +
  th
```
<br/>
-> PCA mainly captures source of variation in tissue conditions, which indicates decent data quality. 
<br/>
<br/>

Variance explained by each PC
```{r}
# Display proportion of total variance captured by all PCs explained by each PC
varExplained <- pcVsnRes$sdev^2 / sum(pcVsnRes$sdev^2)
PC <- paste0('PC', seq(length(varExplained)))
varTab <- data.frame(PC = factor(PC, levels = PC),
                     Var_explained = varExplained)

ggplot(varTab, aes(x=PC, y=Var_explained*100)) +
  geom_col() +
  labs(x = '', y = 'Variance explained (%)') +
  th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```

```{r message = F}
# Store median normalized data for computing log(FC) later
# Merge triplicates (take mean)
merge_lipTissueMediTab <- dplyr::group_by(lipTissueMediTab, Feature_ID, Sample) %>%
  dplyr::summarise(mediAbundance = mean(mediAbundance, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::filter(!Feature_ID %in% rmFeats) %>%
  dplyr::left_join(summMetadat, by = 'Sample')

# Incorporate m/z_RT information
MZRT <- dplyr::select(lipTissueTab, `MZ/RT`, Feature_ID) %>%
  dplyr::filter(!duplicated(Feature_ID))
merge_lipTissueMediTab <- dplyr::left_join(merge_lipTissueMediTab, MZRT,
                                           by = 'Feature_ID')

# ggplot(merge_lipTissueMediTab, aes(x=Sample, y=mediAbundance)) +
#   geom_boxplot() +
#   labs(y = 'Normalized abundance', title = 'Median normalized data') +
#   th + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))

# Convert tidy long table to SummarizedExperiment object and save it for further
# analysis
lipTissueMedi <- df2SummExp(merge_lipTissueMediTab, row_id = 'Feature_ID', col_id = 'Sample',
                             values = 'mediAbundance', row_anno = 'MZ/RT', col_anno = c(smpAnno, 'TumorPurity'))
saveRDS(lipTissueMedi, './data/MethodDev/AG_Hopf/lipTissueMedi.rds')
```
