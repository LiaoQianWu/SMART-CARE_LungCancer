---
title: 'Feature selection: Machine learning models'
author: "Qian-Wu Liao"
output:
  workflowr::wflow_html:
    toc: true
    toc_float: true
    code_folding: hide
---

<font size='4'> Description: Do feature selection with machine learning models trained
on combined data of cohorts (Method Development and Discovery) to identify potential
biomarkers for predicting lung cancer recurrence. ML models used currently include
lasso logistic regression, random forest, and XGBoost. </font>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 8, fig.width = 10, warning = F)
knitr::opts_knit$set(root.dir = '/Users/qianwu/Desktop/SMART-CARE_LungCancer')
```

Load libraries
```{r library loading, message = F}
library('spsUtil')
library(ggh4x)
library(DT)
library('randomForest')
library('missForest')
library(xgboost)
library('caret')
library('glmnet')
library(ggvenn)
library('SummarizedExperiment')
library('tidyverse')
# Load user-defined functions
source('./code/misc.R')
source('./code/ml_funcs.R')

# Set plot theme
th <- theme_bw(base_size = 15) +
  theme(axis.title = element_text(face = 'bold'),
        axis.text = element_text(face = 'bold'),
        axis.ticks = element_line(linewidth = 0.8),
        legend.text = element_text(size = 15))
```

# NTP (AG Klin.)
Normal Tissue DIA Proteomics from AG Klingmüller

## Lasso logistic regression

<font size='5'> **Stability selection** </font>

**Performance statistics of 1000 models**
```{r warning=T}
# Load preprocessed data
proTissue_Klin <- readRDS('./data/Discovery/AG_Klingmueller/proTissueVsn.rds')
proNormal_Klin <- proTissue_Klin[, colData(proTissue_Klin)$Condition %in% 'Normal']
# Load SOA results
proNormalRes_Klin <- readRDS('./data/Discovery/AG_Klingmueller/soaRes/proNormalRes_Stage.rds')

# Prepare imputed data
# impuProNormal_Klin <- imputeByMF(proNormal_Klin)
# saveRDS(impuProNormal_Klin, './data/Discovery/AG_Klingmueller/impuProNormalVsn.rds')
# impuProNormal_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuProNormalVsn.rds')

# Prepare imputed adjusted data
adjProNormal_Klin <- proNormal_Klin
assay(adjProNormal_Klin) <- proNormalRes_Klin$SOA.res$dataCorrect
# impuAdjProNormal_Klin <- imputeByMF(adjProNormal_Klin)
# saveRDS(impuAdjProNormal_Klin, './data/Discovery/AG_Klingmueller/impuAdjProNormalVsn.rds')
impuAdjProNormal_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProNormalVsn.rds')

# Train models iteratively
# Prepare significant feature list
sigFeatList <- proNormalRes_Klin$sig.feat.tab$Var1
# 'auc' is not applicable for CV when too few (< 10) observations per fold. Instead,
# 'deviance' will be used.
# lrRes <- iterLogisR(impuAdjProNormal_Klin, doImputation = F, doInitFeatSelection = T, sigFeatList = sigFeatList,
#                     doFeatClustering = T, iter = 1000, cvFold = 5, cvMeasure = 'auc')
# saveRDS(lrRes, './data/Discovery/logisR/lrResSOA_Stage_impuAdjProNormal_0.8r_randSplit_1000_5fold_auc_lmin_Klin.rds')
lrRes <- readRDS('./data/Discovery/logisR/lrResSOA_Stage_impuAdjProNormal_0.8r_randSplit_1000_5fold_auc_lmin_Klin.rds')

# Pinpoint useless models that will be removed, i.e., models with no any non-zero beta
uselessModels <- which(lrRes$lrRes$nNonZero == 0) #higher lambda results in simpler model
# for (i in uselessModels) {
#   pred <- lrRes$lrRes$y_pred[[i]]
#   truth <- lrRes$lrRes$y_truth[[i]]
#   scores <- caret::confusionMatrix(data = pred, reference = truth, positive = '1')
#   cat(scores$overall[['Accuracy']], '\n')
# } # Models that got only intercept make random predictions, 0.5 accuracy and AUC-ROC

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
if (length(uselessModels) != 0) {
  pred <- lrRes$lrRes$y_pred[-uselessModels]
  truth <- lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- lrRes$lrRes$y_pred
  truth <- lrRes$lrRes$y_truth
  auc_roc <- lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc)) #warning due to sometimes only pos or neg predictions
```

**Top important features that are most frequently selected**
```{r}
# Visualize top important features
# Prepare feature annotation table
featAnno <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')
topImpoFeatViz <- vizTopImpoFeatsLR(lrRes, featAnno = featAnno, num_p1TopFeats = 30)
topImpoFeatViz$pick
```

**Full feature importance table**
```{r}
# Display full feature importance table
DT::datatable(topImpoFeatViz$fullImpoFeatTab)
```

<font size='5'> **Systematic training and evaluation** </font>

**Performance of models trained with different numbers of top important features**
```{r}
# Systematically train models with different numbers of top important features
# sysTrainModels <- doSysTrainLogisR(lrRes, impuAdjProNormal_Klin, max_numTopFeats = 50)
# saveRDS(sysTrainModels, './data/Discovery/logisR/sysTrain_lrResSOA_Stage_impuAdjProNormal_randSplit_1000_5fold_auc_lmin_Klin.rds')
sysTrainModels <- readRDS('./data/Discovery/logisR/sysTrain_lrResSOA_Stage_impuAdjProNormal_randSplit_1000_5fold_auc_lmin_Klin.rds')

# Visualize systematic training
vizSysTrainModelPerf(sysTrainModels, numTopFeats = 40)
# ggsave('./output/Junyan/stabSelec_Stats_proNormal.png', device = 'png', dpi = 400, height = 8, width = 10)
```
=> Top 16 important features are selected, resulting in model with AUC of 0.962 [0.89,1].

**Noninformative models that demonstrate effects of top important features**
```{r}
# Train models without top important features, aka noninformative models
numTopImpoFeats <- c(10, 50, 100, 200)
# for (num in numTopImpoFeats) {
#   topImpoFeats <- topImpoFeatViz$fullImpoFeatTab$Feature[1:num]
#   # Train lasso logistic regression model
#   reducedData <- lrRes$featClusters$reducedData
#   x <- t(reducedData[!rownames(reducedData) %in% topImpoFeats,])
#   y <- colData(impuAdjProNormal_Klin)$Recurrence
#   lrResNonInfo <- runLogisR(x, y, targetClass = 'Yes', iter = 1000, regularized_method = 'lasso',
#                             cvFold = 5, cvMeasure = 'auc', used_lambda = 'lambda.min',
#                             trainSet_ratio = 0.8, split_method = 'random split',
#                             plot_ROC = F, save_model = T)
#   saveRDS(lrResNonInfo, paste0('./data/Discovery/logisR/NonInfo_rmTop', num, '_lrResSOA_',
#                                'impuAdjProNormal_randSplit_1000_5fold_auc_lmin_Klin.rds'))
# }

# Display performance of noninformative models
meanAUC <- c()
lowerAUC <- c()
upperAUC <- c()
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  auc_roc <- lrRes$lrRes$auc_roc
}
meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
ci <- calcCI(auc_roc, bootstrap = T)
lowerAUC <- c(lowerAUC, ci[1])
upperAUC <- c(upperAUC, ci[2])
for (num in numTopImpoFeats) {
  lrResNonInfo <- readRDS(paste0('./data/Discovery/logisR/NonInfo_rmTop', num, '_lrResSOA_',
                                 'impuAdjProNormal_randSplit_1000_5fold_auc_lmin_Klin.rds'))
  uselessModels <- which(lrResNonInfo$nNonZero == 0)
  if (length(uselessModels) != 0) {
    auc_roc <- lrResNonInfo$auc_roc[-uselessModels]
  } else {
    auc_roc <- lrResNonInfo$auc_roc
  }
  meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
  ci <- calcCI(auc_roc, bootstrap = T)
  lowerAUC <- c(lowerAUC, ci[1])
  upperAUC <- c(upperAUC, ci[2])
}
aucStatTab <- data.frame(FeatSpace = c('Complete', paste0('-Top ', numTopImpoFeats)),
                         MeanAUC = meanAUC, UpperAUC = upperAUC, LowerAUC = lowerAUC) %>%
  dplyr::mutate(FeatSpace = factor(FeatSpace, levels = FeatSpace))

ggplot(aucStatTab, aes(x=FeatSpace, y=MeanAUC)) +
  geom_bar(stat = 'identity', position = position_dodge(), alpha = 0.9) +
  geom_errorbar(aes(ymin=LowerAUC, ymax=UpperAUC), width = 0.4) +
  labs(x = 'Feature space used to train 1000 models', y = 'Mean AUC-ROC',
       title = 'Noninformative models') +
  th
```

<font size='5'> **Investigation of core features** </font>

<font size='3'> Imputed data: </font>\
**Heatmap where samples are ordered by linear regression scores**
```{r}
coreFeatPlotsImpu <- vizCoreFeats(lrRes, sysTrainModels, impuAdjProNormal_Klin,
                                  heatmap_numCoreFeats = 16, colFeatAnno = 'Gene',
                                  scatter_twoCoreFeats = c('LMTK2', 'MAPK8IP2'),
                                  fontsize = 10, fontsize_col = 7, fontsize_row = 11,
                                  cellwidth = 6, cellheight = 18)
coreFeatPlotsImpu$heatmap
# ggsave('./output/Junyan/stabSelec_heatmap_proNormal_impu.png', device = 'png', dpi = 400, height = 8, width = 10)
```

**Scatterplot of two core features**
```{r}
coreFeatPlotsImpu$scatterplot
# ggsave('./output/Junyan/stabSelec_top2_proNormal_impu.png', device = 'png', dpi = 400, height = 8, width = 10)
```

<font size='3'> Original data: </font>\
**Heatmap**
```{r}
coreFeatPlots <- vizCoreFeats(lrRes, sysTrainModels, adjProNormal_Klin,
                              heatmap_numCoreFeats = 16, colFeatAnno = 'Gene',
                              scatter_twoCoreFeats = c('LMTK2', 'MAPK8IP2'),
                              fontsize = 10, fontsize_col = 7, fontsize_row = 11,
                              cellwidth = 6, cellheight = 18)
coreFeatPlots$heatmap
# ggsave('./output/Junyan/stabSelec_heatmap_proNormal_ori.png', device = 'png', dpi = 400, height = 8, width = 10)
```

**Scatterplot**
```{r}
coreFeatPlots$scatterplot
# ggsave('./output/Junyan/stabSelec_top2_proNormal_ori.png', device = 'png', dpi = 400, height = 8, width = 10)
```

**Missingness and availability of core features**
```{r message=F}
numTopImpoFeats <- 16
# Prepare top important feature list
topImpoFeats <- topImpoFeatViz$fullImpoFeatTab$Feature[1:numTopImpoFeats] %>%
  stringr::str_remove(';.+')
topImpoFeatAnnos <- topImpoFeatViz$fullImpoFeatTab$Annotation[1:numTopImpoFeats] %>%
  stringr::str_remove(';.+')

# Show data missingness
proNormal_Klin <- proTissue_Klin[, colData(proTissue_Klin)$Condition %in% 'Normal']
featAnnoTab <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')
featAvailTab <- summExp2df(proNormal_Klin, row_id = 'Feature', col_id = 'Sample') %>%
  dplyr::select(Feature, Value, Recurrence) %>%
  dplyr::left_join(featAnnoTab, by = 'Feature') %>%
  dplyr::mutate(Value = dplyr::case_when(!is.na(Value) ~ 'Observed',
                                         is.na(Value) ~ 'Missing'),
                Feature = stringr::str_remove(Feature, ';.+'),
                Gene = stringr::str_remove(Gene, ';.+'),
                Recurrence = dplyr::case_when(Recurrence %in% 'Yes' ~ 'Recurrence',
                                              Recurrence %in% 'No' ~ 'Non-Recurrence')) %>%
  dplyr::filter(Feature %in% topImpoFeats) %>%
  dplyr::group_by(Recurrence, Gene, Feature, Value) %>%
  dplyr::summarise(Count = dplyr::n()) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Gene = factor(Gene, levels = topImpoFeatAnnos),
                Recurrence = factor(Recurrence, levels = c('Recurrence', 'Non-Recurrence')),
                Value = factor(Value, levels = c('Missing', 'Observed')))

ggplot(featAvailTab, aes(x=Gene, y=Count, fill=Value)) +
  geom_col(position = 'stack') +
  facet_wrap(vars(Recurrence), scales = 'free') +
  scale_fill_manual(values = c(Missing = 'grey', Observed = 'black')) +
  labs(title = 'Normal Tissue Proteomics') +
  theme_bw() +
  theme(axis.text.x = element_text(size = 18, face = 'bold', angle = 90, hjust = 1, vjust = 0.5),
        axis.text.y = element_text(size = 12, face = 'bold'),
        axis.title = element_text(size = 20, face = 'bold'),
        legend.title = element_blank(), legend.text = element_text(size = 18),
        strip.text = element_text(size = 18, face = 'bold'),
        plot.title = element_text(size = 22, face = 'bold', hjust = 0.5, vjust = 1.5))


# Show availability of top important features in other datasets
# Prepare feature space of other datasets
# Klingmüller Preprocessed Combined dataset
old_proTissue_Combined_Klin <- readRDS('./data/MethodDev/AG_Klingmueller/proTissueVsn.rds')
featSpace_old_Prepro_Combined_Klin <- rownames(old_proTissue_Combined_Klin) %>%
  stringr::str_remove(';.+')
# Klingmüller Original Combined dataset
featSpace_old_Ori_Combined_Klin <- readr::read_tsv(paste0('./data/MethodDev/AG_Klingmueller/',
                                                          '20230309_103228_SmartCare_TumorFree_Tumor_Yang001_Report.tsv')) %>%
  dplyr::pull(PG.ProteinGroups) %>%
  stringr::str_remove(';.+')
# Krijgsveld Preprocessed Combined dataset
proTissue_Combined_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/combined_proTissueVsnBC.rds')
featSpace_Prepro_Combined_Krij <- rownames(proTissue_Combined_Krij) %>%
  stringr::str_remove(';.+')
# Krijgsveld Original Discovery dataset
featSpace_Ori_Discovery_Krij <- readr::read_tsv(paste0('./data/Discovery/AG_Krijgsveld/',
                                                       '20230815_MarcS_Discovery_Tissue.pg_matrix.tsv')) %>%
  dplyr::pull(Protein.Group) %>%
  stringr::str_remove(';.+')
# Krijgsveld Original Method Development dataset
featSpace_Ori_MethodDev_Krij <- readr::read_delim(paste0('./data/MethodDev/AG_Krijgsveld/',
                                                         '20230726_Thorax_Method_Est_tissue.txt')) %>%
  dplyr::pull(Protein.Group) %>%
  stringr::str_remove(';.+')
# Collect all feature spaces into a list
featSpaceList <- list(Ori_Old_Klin = featSpace_old_Ori_Combined_Klin, Prepro_Old_Klin = featSpace_old_Prepro_Combined_Klin,
                      Ori_MDev_Krij = featSpace_Ori_MethodDev_Krij, Ori_Dis_Krij = featSpace_Ori_Discovery_Krij,
                      Prepro_Comb_Krij = featSpace_Prepro_Combined_Krij)
# Store feature availability in a matrix
featAvailMat <- matrix(nrow = 5, ncol = numTopImpoFeats,
                       dimnames = list(c('Ori_Old_Klin', 'Prepro_Old_Klin', 'Ori_MDev_Krij',
                                         'Ori_Dis_Krij', 'Prepro_Comb_Krij'), topImpoFeats))
for (i in seq_len(nrow(featAvailMat))) {
  for (j in seq_len(ncol(featAvailMat))) {
    if (colnames(featAvailMat)[j] %in% featSpaceList[[rownames(featAvailMat)[i]]]) {
      featAvailMat[i, j] <- 'Yes'
    } else {
      featAvailMat[i, j] <- 'No'
    }
  }
}
# Convert matrix to long data for visualization
featAvailMat <- tibble::as_tibble(featAvailMat, rownames = 'Dataset') %>%
  tidyr::pivot_longer(cols = -'Dataset', names_to = 'Feature', values_to = 'Captured') %>%
  dplyr::mutate(Dataset = factor(Dataset, levels = rev(names(featSpaceList))),
                Captured = factor(Captured, levels = c('Yes', 'No')),
                Feature = plyr::mapvalues(Feature, from = topImpoFeats, to = topImpoFeatAnnos),
                Feature = factor(Feature, levels = topImpoFeatAnnos))

ggplot(featAvailMat, aes(x=Feature, y=Dataset, fill=Captured)) +
  geom_tile() +
  scale_fill_manual(values = c('black', 'grey80')) +
  labs(title = 'Normal Tissue Proteomics') +
  theme(axis.ticks = element_blank(), panel.grid = element_blank(), panel.background = element_blank(),
        axis.text.x = element_text(size = 18, face = 'bold', angle = 45, hjust = 1, vjust = 1),
        axis.text.y = element_text(size = 18, face = 'bold'),
        axis.title = element_text(size = 20, face = 'bold'),
        legend.title = element_text(size = 20), legend.text = element_text(size = 18),
        plot.title = element_text(size = 28, face = 'bold', hjust = 0.5, vjust = 1.5))
```

```{r eval=F}
# <font size='5'> **Investigation of model behaviors** </font>

# Show number of unique selected features, i.e., features with non-zero coefficients,
# from certain subsets of trained models depending on AUC-ROC, e.g., 0.9 >= M > 0.8
cutoffs <- c(0.9, 0.8, 0.7, 0.6, 0.5)
numPickedFeats <- c()
topImpoFeatList <- list()
for (cuto in cutoffs) {
  models <- which(lrRes$lrRes$auc_roc > cuto & lrRes$lrRes$auc_roc <= cuto+0.1)
  coefMat <- lrRes$lrRes$coefficient[, models]
  topImpoFeats <- as.data.frame(coefMat) %>%
    dplyr::mutate(across(everything(), ~ case_when(.x != 0 ~ 1,
                                                   .x == 0 ~ 0))) %>%
    tibble::rownames_to_column('Feature') %>%
    tidyr::pivot_longer(cols = -'Feature', names_to = 'Model', values_to = 'Pick') %>%
    dplyr::filter(Pick != 0) %>%
    dplyr::pull(Feature) %>%
    unique()
  numPickedFeats <- c(numPickedFeats, length(topImpoFeats))
  topImpoFeatList[[which(cutoffs == cuto)]] <- topImpoFeats
}
numPickedFeatTab <- data.frame(CutoffWindow = paste0(cutoffs+0.1, ' >= AUC > ', cutoffs),
                               NumPickedFeats = numPickedFeats) %>%
  dplyr::mutate(CutoffWindow = factor(CutoffWindow, levels = CutoffWindow))

ggplot(numPickedFeatTab, aes(x=CutoffWindow, y=NumPickedFeats)) +
  geom_bar(stat = 'identity', position = position_dodge(), alpha = 0.9) +
  labs(x = 'AUC-ROC window',
       y = 'Number of unique selected features',
       title = 'Number of features selected from certain subsets of trained models') +
  th

# Show overlaps of selected features from different subsets of trained models
ggvenn(list(`1 >= AUC > 0.9` = topImpoFeatList[[1]], `0.9 >= AUC > 0.8` = topImpoFeatList[[2]],
            `0.8 >= AUC > 0.7` = topImpoFeatList[[3]]),
       fill_color = c('firebrick1', 'dodgerblue1', 'lightgreen'), fill_alpha = 0.6,
       set_name_color = c('firebrick1', 'dodgerblue1', 'lightgreen'), set_name_size = 8,
       text_size = 6, stroke_size = 1.5) +
  labs(title = 'Overlap of features selected from certain subsets of trained models')
ggvenn(list(`1 >= AUC > 0.9` = topImpoFeatList[[1]], `0.7 >= AUC > 0.6` = topImpoFeatList[[4]],
            `0.6 >= AUC > 0.5` = topImpoFeatList[[5]]),
       fill_color = c('firebrick1', 'dodgerblue1', 'lightgreen'), fill_alpha = 0.6,
       set_name_color = c('firebrick1', 'dodgerblue1', 'lightgreen'), set_name_size = 8,
       text_size = 6, stroke_size = 1.5) +
  labs(title = 'Overlap of features selected from certain subsets of trained models')




# Train models with top important features
cutoffs <- c(0.9, 0.8, 0.7, 0.6, 0.5)
# for (cuto in cutoffs) {
#   models <- which(lrRes$lrRes$auc_roc > cuto & lrRes$lrRes$auc_roc <= cuto+0.1)
#   coefMat <- lrRes$lrRes$coefficient[, models]
#   topImpoFeatTab <- as.data.frame(coefMat) %>%
#     dplyr::mutate(across(everything(), ~ case_when(.x != 0 ~ 1,
#                                                    .x == 0 ~ 0))) %>%
#     tibble::rownames_to_column('Feature') %>%
#     tidyr::pivot_longer(cols = -'Feature', names_to = 'Model', values_to = 'Pick') %>%
#     dplyr::group_by(Feature) %>%
#     dplyr::summarise(Frequency = sum(Pick),
#                      PickRate = Frequency/length(models)) %>%
#     dplyr::filter(Frequency != 0) %>%
#     dplyr::arrange(desc(Frequency))
#   topImpoFeats <- topImpoFeatTab$Feature
#   
#   # Train lasso logistic regression model
#   x <- t(lrRes$featClusters$reducedData[topImpoFeats,])
#   y <- colData(impuAdjProNormal_Klin)$Recurrence
#   lrResSub <- runLogisR(x, y, targetClass = 'Yes', iter = 100, regularized_method = 'lasso',
#                         cvFold = 5, cvMeasure = 'auc', used_lambda = 'lambda.min',
#                         trainSet_ratio = 0.8, split_method = 'random split',
#                         plot_ROC = F, save_model = T)
#   saveRDS(lrResSub, paste0('./data/Discovery/logisR/others/AUC', cuto, '_', cuto+0.1,
#                            '_lrResSOA_impuAdjProNormal_randSplit_100_5fold_auc_lmin_Klin.rds'))
# }

# Display performance of reduced models
meanAUC <- c()
lowerAUC <- c()
upperAUC <- c()
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  auc_roc <- lrRes$lrRes$auc_roc
}
meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
ci <- calcCI(auc_roc, bootstrap = T)
lowerAUC <- c(lowerAUC, ci[1])
upperAUC <- c(upperAUC, ci[2])
for (cuto in cutoffs) {
  lrResSub <- readRDS(paste0('./data/Discovery/logisR/others/AUC', cuto, '_', cuto+0.1,
                             '_lrResSOA_impuAdjProNormal_randSplit_100_5fold_auc_lmin_Klin.rds'))
  uselessModels <- which(lrResSub$nNonZero == 0)
  if (length(uselessModels) != 0) {
    auc_roc <- lrResSub$auc_roc[-uselessModels]
  } else {
    auc_roc <- lrResSub$auc_roc
  }
  meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
  ci <- calcCI(auc_roc, bootstrap = T)
  lowerAUC <- c(lowerAUC, ci[1])
  upperAUC <- c(upperAUC, ci[2])
}
aucStatTab <- data.frame(FeatSpace = c('Complete', paste0(cutoffs+0.1, ' >= AUC > ', cutoffs)),
                         MeanAUC = meanAUC, UpperAUC = upperAUC, LowerAUC = lowerAUC) %>%
  dplyr::mutate(FeatSpace = factor(FeatSpace, levels = FeatSpace))

ggplot(aucStatTab, aes(x=FeatSpace, y=MeanAUC)) +
  geom_bar(stat = 'identity', position = position_dodge(), alpha = 0.9) +
  geom_errorbar(aes(ymin=LowerAUC, ymax=UpperAUC), width = 0.4) +
  labs(x = 'Feature space used to train 100 models', y = 'Mean AUC-ROC',
       title = 'Reduced models trained on certain subsets of features') +
  th

# => Models from different AUC windows can actually capture similar feature set, which
# implies that factor affecting performance may not be variability of feature sets
# selected by models. Instead, composition of test data may be factor, meaning that
# some test sets are probably just easy/hard to predict.
```

## RF

<font size='5'> **Stability selection** </font>

**Performance statistics of 1000 models**
```{r}
# Load imputed adjusted data
impuAdjProNormal_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProNormalVsn.rds')
# Load SOA results for retrieving significant feature list for initial feature selection
proNormalRes_Klin <- readRDS('./data/Discovery/AG_Klingmueller/soaRes/proNormalRes_Stage.rds')

# Train models iteratively
# Prepare significant feature list
sigFeatList <- proNormalRes_Klin$sig.feat.tab$Var1
# rfRes <- iterRF(impuAdjProNormal_Klin, doImputation = F, doInitFeatSelection = T,
#                 sigFeatList = sigFeatList, doFeatClustering = T, iter = 1000)
# saveRDS(rfRes, './data/Discovery/rf/rfResSOA_Stage_impuAdjProNormal_0.8r_randSplit_1000_Klin.rds')
rfRes <- readRDS('./data/Discovery/rf/rfResSOA_Stage_impuAdjProNormal_0.8r_randSplit_1000_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- rfRes$rfRes$y_pred
truth <- rfRes$rfRes$y_truth
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Top important features with highest median ranks**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Klin <- readRDS('./data/Discovery/AG_Klingmueller/proTissueVsn.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')
topImpoFeatViz <- vizTopImpoFeatsRF(rfRes, featAnno = featAnno, num_p1TopFeats = 30)
topImpoFeatViz$rank + theme(axis.title = element_text(size = 28),
                            axis.text = element_text(size = 16))
# ggsave('./output/Discovery/group_meeting/rf_topImpo_combined_proNormal_Klin.png',
#        device = 'png', dpi = 400, height = 8, width = 10)
```

**Full feature importance table**
```{r}
DT::datatable(topImpoFeatViz$fullImpoFeatTab)
```

<font size='5'> **Systematic training and evaluation** </font>

**Performance of models trained with different numbers of top important features**
```{r}
# Systematically train models with different numbers of top important features
# sysTrainModels <- doSysTrainRF(rfRes, impuAdjProNormal_Klin, max_numTopFeats = 100)
# saveRDS(sysTrainModels, './data/Discovery/rf/sysTrain_rfResSOA_Stage_impuAdjProNormal_randSplit_100_Klin.rds')
sysTrainModels <- readRDS('./data/Discovery/rf/sysTrain_rfResSOA_Stage_impuAdjProNormal_randSplit_100_Klin.rds')

# Manually list output from old function to fit function 'vizSysTrainModelPerf'
sysTrainModels <- list(summPerformanceTab = sysTrainModels)
# Visualize systematic training
vizSysTrainModelPerf(sysTrainModels, numTopFeats = 40)
```
=> Top 24, resulting in model with AUC of 0.937 [0.85,1]

**Noninformative models that demonstrate effects of top important features**
```{r}
# Train models without top important features, aka noninformative models
numTopImpoFeats <- c(10, 50, 100, 200, 300, 400, 500)
# for (num in numTopImpoFeats) {
#   topImpoFeats <- topImpoFeatViz$fullImpoFeatTab$Feature[1:num]
#   # Train lasso logistic regression model
#   reducedData <- rfRes$featClusters$reducedData
#   x <- t(reducedData[!rownames(reducedData) %in% topImpoFeats,])
#   y <- colData(impuAdjProNormal_Klin)$Recurrence
#   rfResNonInfo <- runRF(x, y, targetClass = 'Yes', iter = 100, split_method = 'random split',
#                         trainSet_ratio = 0.8, ntree = 10000, plot_ROC = F, save_model = T)
#   saveRDS(rfResNonInfo, paste0('./data/Discovery/rf/NonInfo_rmTop', num, '_rfResSOA_',
#                                'impuAdjProNormal_randSplit_100_Klin.rds'))
# }

# Display performance of noninformative models
meanAUC <- c()
lowerAUC <- c()
upperAUC <- c()
auc_roc <- rfRes$rfRes$auc_roc
meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
ci <- calcCI(auc_roc, bootstrap = T)
lowerAUC <- c(lowerAUC, ci[1])
upperAUC <- c(upperAUC, ci[2])
for (num in numTopImpoFeats) {
  lrResNonInfo <- readRDS(paste0('./data/Discovery/rf/NonInfo_rmTop', num, '_rfResSOA_',
                                 'impuAdjProNormal_randSplit_100_Klin.rds'))
  
  auc_roc <- lrResNonInfo$auc_roc
  meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
  ci <- calcCI(auc_roc, bootstrap = T)
  lowerAUC <- c(lowerAUC, ci[1])
  upperAUC <- c(upperAUC, ci[2])
}
aucStatTab <- data.frame(FeatSpace = c('Complete', paste0('-Top ', numTopImpoFeats)),
                         MeanAUC = meanAUC, UpperAUC = upperAUC, LowerAUC = lowerAUC) %>%
  dplyr::mutate(FeatSpace = factor(FeatSpace, levels = FeatSpace))

ggplot(aucStatTab, aes(x=FeatSpace, y=MeanAUC)) +
  geom_bar(stat = 'identity', position = position_dodge(), alpha = 0.9) +
  geom_errorbar(aes(ymin=LowerAUC, ymax=UpperAUC), width = 0.4) +
  labs(x = 'Feature space used to train 100 models', y = 'Mean AUC-ROC',
       title = 'Noninformative models') +
  th
```

## XGBoost

<font size='5'> **Linear booster** </font>

**Models trained with core features selected by lasso logistic regression**
```{r}
###############
# Change here #
################################################################################
# Load imputed adjusted data
se <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProNormalVsn.rds')
# Load trained models
lrRes <- readRDS('./data/Discovery/logisR/lrResSOA_Stage_impuAdjProNormal_0.8r_randSplit_1000_5fold_auc_lmin_Klin.rds')
# Specify number of core features selected by lasso logistic regression
numTopImpoFeats <- 16
################################################################################

# Retrieve core feature list
coreFeats <- vizTopImpoFeatsLR(lrRes)$fullImpoFeatTab$Feature[1:numTopImpoFeats]
# Subset core features from data
coreSE <- se[rownames(se) %in% coreFeats,]

# Train models iteratively
# linearBoostRes <- iterXGBoost(coreSE, booster = 'gblinear', iter = 100, nrounds = 1000)
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbRes_Stage_coreImpuAdjProNormal_randSplit_rmse_nR1000_iter100_Klin.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbRes_Stage_coreImpuAdjProNormal_randSplit_rmse_nR1000_iter100_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Models trained with grouped recurrence-related features**
```{r}
###############
# Change here #
################################################################################
# Load imputed adjusted data
se <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProNormalVsn.rds')
# Load SOA results for retrieving significant feature list for initial feature selection
soaRes <- readRDS('./data/Discovery/AG_Klingmueller/soaRes/proNormalRes_Stage.rds')
################################################################################

# Train models iteratively
# Prepare significant feature list
sigFeatList <- soaRes$sig.feat.tab$Var1
# linearBoostRes <- iterXGBoost(se, doImputation = F, doInitFeatSelection = T,
#                               sigFeatList = sigFeatList, doFeatClustering = T,
#                               booster = 'gblinear', iter = 100, nrounds = 1000)
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbRes_Stage_impuAdjProNormal_randSplit_rmse_nR1000_iter100_Klin.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbRes_Stage_impuAdjProNormal_randSplit_rmse_nR1000_iter100_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

<font size='5'> **Tree booster** </font>

**Models trained with core features selected by random forest**
```{r}
###############
# Change here #
################################################################################
# Load imputed adjusted data
se <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProNormalVsn.rds')
# Load trained models
rfRes <- readRDS('./data/Discovery/rf/rfResSOA_Stage_impuAdjProNormal_0.8r_randSplit_1000_Klin.rds')
# Specify number of core features selected by random forest
numTopImpoFeats <- 24
################################################################################

# Retrieve core feature list
coreFeats <- vizTopImpoFeatsRF(rfRes)$fullImpoFeatTab$Feature[1:numTopImpoFeats]
# Subset core features from data
coreSE <- se[rownames(se) %in% coreFeats,]

# Train models iteratively
# treeBoostRes <- iterXGBoost(coreSE, booster = 'gbtree', iter = 100, nrounds = 1000)
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbRes_Stage_coreImpuAdjProNormal_randSplit_auc_nR1000_iter100_Klin.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbRes_Stage_coreImpuAdjProNormal_randSplit_auc_nR1000_iter100_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Models trained with grouped recurrence-related features**
```{r}
###############
# Change here #
################################################################################
# Load imputed adjusted data
se <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProNormalVsn.rds')
# Load SOA results for retrieving significant feature list for initial feature selection
soaRes <- readRDS('./data/Discovery/AG_Klingmueller/soaRes/proNormalRes_Stage.rds')
################################################################################

# Train models iteratively
# Prepare significant feature list
sigFeatList <- soaRes$sig.feat.tab$Var1
# treeBoostRes <- iterXGBoost(se, doImputation = F, doInitFeatSelection = T,
#                             sigFeatList = sigFeatList, doFeatClustering = T,
#                             booster = 'gbtree', iter = 100, nrounds = 1000)
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbRes_Stage_impuAdjProNormal_randSplit_logloss_nR1000_iter100_Klin.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbRes_Stage_impuAdjProNormal_randSplit_logloss_nR1000_iter100_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

# TTP (AG Klin.)
Tumor Tissue DIA Proteomics from AG Klingmüller

## Lasso logistic regression

<font size='5'> **Stability selection** </font>

**Performance statistics of 1000 models**
```{r warning=T}
# **ADJUSTED DATA**

# Load preprocessed data
proTissue_Klin <- readRDS('./data/Discovery/AG_Klingmueller/proTissueVsn.rds')
proTumor_Klin <- proTissue_Klin[, colData(proTissue_Klin)$Condition %in% 'Tumor']
# Load SOA results
proTumorRes_Klin <- readRDS('./data/Discovery/AG_Klingmueller/soaRes/proTumorRes_SVs.rds')

# Prepare adjusted data
adjProTumor_Klin <- proTumor_Klin
assay(adjProTumor_Klin) <- proTumorRes_Klin$SOA.res$dataCorrect

# Train models iteratively
# Prepare significant feature list
sigFeatList <- proTumorRes_Klin$sig.feat.tab$Var1
# lrRes <- iterLogisR(adjProTumor_Klin, doImputation = T, doInitFeatSelection = T, sigFeatList = sigFeatList,
#                     doFeatClustering = T, iter = 1000, cvFold = 5, cvMeasure = 'auc')
# saveRDS(lrRes, './data/Discovery/logisR/lrResSOA_SVs_impuAdjProTumor_0.8r_randSplit_1000_5fold_auc_lmin_Klin.rds')
# saveRDS(lrRes$impuSE, './data/Discovery/AG_Klingmueller/impuAdjProTumorVsn.rds')
lrRes <- readRDS('./data/Discovery/logisR/lrResSOA_SVs_impuAdjProTumor_0.8r_randSplit_1000_5fold_auc_lmin_Klin.rds')
impuAdjProTumor_Klin <- lrRes$impuSE

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  pred <- lrRes$lrRes$y_pred[-uselessModels]
  truth <- lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- lrRes$lrRes$y_pred
  truth <- lrRes$lrRes$y_truth
  auc_roc <- lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc))
```

```{r eval=F}
# **UNADJUSTED DATA**

tmp_lrRes <- readRDS('./data/Discovery/logisR/lrResSOA_SVs_impuProTumor_0.8r_randSplit_1000_5fold_auc_lmin_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
uselessModels <- which(tmp_lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  pred <- tmp_lrRes$lrRes$y_pred[-uselessModels]
  truth <- tmp_lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- tmp_lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- tmp_lrRes$lrRes$y_pred
  truth <- tmp_lrRes$lrRes$y_truth
  auc_roc <- tmp_lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc))
```

**Top important features that are most frequently selected**
```{r}
# Visualize top important features
# Prepare feature annotation table
featAnno <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')
topImpoFeatViz <- vizTopImpoFeatsLR(lrRes, fullData = proTissue_Klin, trainData_smpType = 'Tumor',
                                    featAnno = featAnno, num_p1TopFeats = 30)
topImpoFeatViz$pick
# topImpoFeatViz$abun
```

**Full feature importance table**
```{r}
DT::datatable(topImpoFeatViz$fullImpoFeatTab)
```

<font size='5'> **Systematic training and evaluation** </font>

**Performance of models trained with different numbers of top important features**
```{r}
# Systematically train models with different numbers of top important features
# sysTrainModels <- doSysTrainLogisR(lrRes, impuAdjProTumor_Klin, max_numTopFeats = 30)
# saveRDS(sysTrainModels, './data/Discovery/logisR/sysTrain_lrResSOA_SVs_impuAdjProTumor_randSplit_100_5fold_auc_lmin_Klin.rds')
sysTrainModels <- readRDS('./data/Discovery/logisR/sysTrain_lrResSOA_SVs_impuAdjProTumor_randSplit_100_5fold_auc_lmin_Klin.rds')

# Visualize systematic training
vizSysTrainModelPerf(sysTrainModels, numTopFeats = 30)
# ggsave('./output/Junyan/stabSelec_Stats_proTumor.png', device = 'png', dpi = 400, height = 8, width = 10)
```
=> Top 6 important features are selected, resulting in model with AUC of 0.998 [0.97,1].

**Noninformative models that demonstrate effects of top important features**
```{r}
# Train models without top important features, aka noninformative models
numTopImpoFeats <- c(10, 20, 30)
# for (num in numTopImpoFeats) {
#   topImpoFeats <- topImpoFeatViz$fullImpoFeatTab$Feature[1:num]
#   # Train lasso logistic regression model
#   reducedData <- lrRes$featClusters$reducedData
#   x <- t(reducedData[!rownames(reducedData) %in% topImpoFeats,])
#   y <- colData(se)$Recurrence
#   lrResNonInfo <- runLogisR(x, y, targetClass = 'Yes', iter = 100, regularized_method = 'lasso',
#                             cvFold = 5, cvMeasure = 'auc', used_lambda = 'lambda.min',
#                             trainSet_ratio = 0.8, split_method = 'random split',
#                             plot_ROC = F, save_model = T)
#   saveRDS(lrResNonInfo, paste0('./data/Discovery/logisR/NonInfo_rmTop', num, '_lrResSOA_',
#                                'impuAdjProTumor_randSplit_100_5fold_auc_lmin_Klin.rds'))
# }

# Display performance of noninformative models
meanAUC <- c()
lowerAUC <- c()
upperAUC <- c()
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  auc_roc <- lrRes$lrRes$auc_roc
}
meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
ci <- calcCI(auc_roc, bootstrap = T)
lowerAUC <- c(lowerAUC, ci[1])
upperAUC <- c(upperAUC, ci[2])
for (num in numTopImpoFeats) {
  lrResNonInfo <- readRDS(paste0('./data/Discovery/logisR/NonInfo_rmTop', num, '_lrResSOA_',
                                 'impuAdjProTumor_randSplit_100_5fold_auc_lmin_Klin.rds'))
  uselessModels <- which(lrResNonInfo$nNonZero == 0)
  if (length(uselessModels) != 0) {
    auc_roc <- lrResNonInfo$auc_roc[-uselessModels]
  } else {
    auc_roc <- lrResNonInfo$auc_roc
  }
  meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
  ci <- calcCI(auc_roc, bootstrap = T)
  lowerAUC <- c(lowerAUC, ci[1])
  upperAUC <- c(upperAUC, ci[2])
}
aucStatTab <- data.frame(FeatSpace = c('Complete', paste0('-Top ', numTopImpoFeats)),
                         MeanAUC = meanAUC, UpperAUC = upperAUC, LowerAUC = lowerAUC) %>%
  dplyr::mutate(FeatSpace = factor(FeatSpace, levels = FeatSpace))

ggplot(aucStatTab, aes(x=FeatSpace, y=MeanAUC)) +
  geom_bar(stat = 'identity', position = position_dodge(), alpha = 0.9) +
  geom_errorbar(aes(ymin=LowerAUC, ymax=UpperAUC), width = 0.4) +
  labs(x = 'Feature space used to train 100 models', y = 'Mean AUC-ROC',
       title = 'Noninformative models') +
  th
```

<font size='5'> **Investigation of core features** </font>

<font size='3'> Imputed data: </font>\
**Heatmap where samples are ordered by linear regression scores**\
Note that Sample 'M02YH0JJ_TG' from Recurrence patient group is removed from visualization
because its TGFBR3 abundance is extremely low compared to the others, making coloring driven by that data point
```{r}
coreFeatPlotsImpu <- vizCoreFeats(lrRes, sysTrainModels, impuAdjProTumor_Klin,
                                  heatmap_numCoreFeats = 6, colFeatAnno = 'Gene',
                                  scatter_twoCoreFeats = c('TGFBR3', 'RELL2'),
                                  rmUnwantedSmp = 'M02YH0JJ_TG',
                                  fontsize = 10, fontsize_col = 7, fontsize_row = 11,
                                  cellwidth = 6, cellheight = 18)
coreFeatPlotsImpu$heatmap
# ggsave('./output/Junyan/stabSelec_heatmap_proNormal_impu.png', device = 'png', dpi = 400, height = 8, width = 10)
```

**Scatterplot of two core features**
```{r}
coreFeatPlotsImpu$scatterplot
# ggsave('./output/Junyan/stabSelec_top1&3_proTumor_impu.png', device = 'png', dpi = 400, height = 8, width = 10)
```

<font size='3'> Original data: </font>\
**Heatmap**
```{r}
coreFeatPlots <- vizCoreFeats(lrRes, sysTrainModels, adjProTumor_Klin,
                              heatmap_numCoreFeats = 6, colFeatAnno = 'Gene',
                              scatter_twoCoreFeats = c('TGFBR3', 'RELL2'),
                              rmUnwantedSmp = 'M02YH0JJ_TG',
                              fontsize = 10, fontsize_col = 7, fontsize_row = 11,
                              cellwidth = 6, cellheight = 18)
coreFeatPlots$heatmap
# ggsave('./output/Junyan/stabSelec_heatmap_proTumor_ori.png', plot = a, device = 'png', dpi = 400, height = 8, width = 10)
```

**Missingness and availability of core features**
```{r message=F}
numTopImpoFeats <- 6
# Prepare top important feature list
topImpoFeats <- topImpoFeatViz$fullImpoFeatTab$Feature[1:numTopImpoFeats] %>%
  stringr::str_remove(';.+')
topImpoFeatAnnos <- topImpoFeatViz$fullImpoFeatTab$Annotation[1:numTopImpoFeats] %>%
  stringr::str_remove(';.+')

# Show data missingness
proTumor_Klin <- proTissue_Klin[, colData(proTissue_Klin)$Condition %in% 'Tumor']
featAnnoTab <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')
featAvailTab <- summExp2df(proTumor_Klin, row_id = 'Feature', col_id = 'Sample') %>%
  dplyr::select(Feature, Value, Recurrence) %>%
  dplyr::left_join(featAnnoTab, by = 'Feature') %>%
  dplyr::mutate(Value = dplyr::case_when(!is.na(Value) ~ 'Observed',
                                         is.na(Value) ~ 'Missing'),
                Feature = stringr::str_remove(Feature, ';.+'),
                Gene = stringr::str_remove(Gene, ';.+'),
                Recurrence = dplyr::case_when(Recurrence %in% 'Yes' ~ 'Recurrence',
                                              Recurrence %in% 'No' ~ 'Non-Recurrence')) %>%
  dplyr::filter(Feature %in% topImpoFeats) %>%
  dplyr::group_by(Recurrence, Gene, Feature, Value) %>%
  dplyr::summarise(Count = dplyr::n()) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Gene = factor(Gene, levels = topImpoFeatAnnos),
                Recurrence = factor(Recurrence, levels = c('Recurrence', 'Non-Recurrence')),
                Value = factor(Value, levels = c('Missing', 'Observed')))

ggplot(featAvailTab, aes(x=Gene, y=Count, fill=Value)) +
  geom_col(position = 'stack') +
  facet_wrap(vars(Recurrence), scales = 'free') +
  scale_fill_manual(values = c(Missing = 'grey', Observed = 'black')) +
  labs(title = 'Normal Tissue Proteomics') +
  theme_bw() +
  theme(axis.text.x = element_text(size = 18, face = 'bold', angle = 90, hjust = 1, vjust = 0.5),
        axis.text.y = element_text(size = 12, face = 'bold'),
        axis.title = element_text(size = 20, face = 'bold'),
        legend.title = element_blank(), legend.text = element_text(size = 18),
        strip.text = element_text(size = 18, face = 'bold'),
        plot.title = element_text(size = 22, face = 'bold', hjust = 0.5, vjust = 1.5))


# Show availability of top important features in other datasets
# Prepare feature space of other datasets
# Klingmüller Preprocessed Combined dataset
old_proTissue_Combined_Klin <- readRDS('./data/MethodDev/AG_Klingmueller/proTissueVsn.rds')
featSpace_old_Prepro_Combined_Klin <- rownames(old_proTissue_Combined_Klin) %>%
  stringr::str_remove(';.+')
# Klingmüller Original Combined dataset
featSpace_old_Ori_Combined_Klin <- readr::read_tsv(paste0('./data/MethodDev/AG_Klingmueller/',
                                                          '20230309_103228_SmartCare_TumorFree_Tumor_Yang001_Report.tsv')) %>%
  dplyr::pull(PG.ProteinGroups) %>%
  stringr::str_remove(';.+')
# Krijgsveld Preprocessed Combined dataset
proTissue_Combined_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/combined_proTissueVsnBC.rds')
featSpace_Prepro_Combined_Krij <- rownames(proTissue_Combined_Krij) %>%
  stringr::str_remove(';.+')
# Krijgsveld Original Discovery dataset
featSpace_Ori_Discovery_Krij <- readr::read_tsv(paste0('./data/Discovery/AG_Krijgsveld/',
                                                       '20230815_MarcS_Discovery_Tissue.pg_matrix.tsv')) %>%
  dplyr::pull(Protein.Group) %>%
  stringr::str_remove(';.+')
# Krijgsveld Original Method Development dataset
featSpace_Ori_MethodDev_Krij <- readr::read_delim(paste0('./data/MethodDev/AG_Krijgsveld/',
                                                         '20230726_Thorax_Method_Est_tissue.txt')) %>%
  dplyr::pull(Protein.Group) %>%
  stringr::str_remove(';.+')
# Collect all feature spaces into a list
featSpaceList <- list(Ori_Old_Klin = featSpace_old_Ori_Combined_Klin, Prepro_Old_Klin = featSpace_old_Prepro_Combined_Klin,
                      Ori_MDev_Krij = featSpace_Ori_MethodDev_Krij, Ori_Dis_Krij = featSpace_Ori_Discovery_Krij,
                      Prepro_Comb_Krij = featSpace_Prepro_Combined_Krij)
# Store feature availability in a matrix
featAvailMat <- matrix(nrow = 5, ncol = numTopImpoFeats,
                       dimnames = list(c('Ori_Old_Klin', 'Prepro_Old_Klin', 'Ori_MDev_Krij',
                                         'Ori_Dis_Krij', 'Prepro_Comb_Krij'), topImpoFeats))
for (i in seq_len(nrow(featAvailMat))) {
  for (j in seq_len(ncol(featAvailMat))) {
    if (colnames(featAvailMat)[j] %in% featSpaceList[[rownames(featAvailMat)[i]]]) {
      featAvailMat[i, j] <- 'Yes'
    } else {
      featAvailMat[i, j] <- 'No'
    }
  }
}
# Convert matrix to long data for visualization
featAvailMat <- tibble::as_tibble(featAvailMat, rownames = 'Dataset') %>%
  tidyr::pivot_longer(cols = -'Dataset', names_to = 'Feature', values_to = 'Captured') %>%
  dplyr::mutate(Dataset = factor(Dataset, levels = rev(names(featSpaceList))),
                Captured = factor(Captured, levels = c('Yes', 'No')),
                Feature = plyr::mapvalues(Feature, from = topImpoFeats, to = topImpoFeatAnnos),
                Feature = factor(Feature, levels = topImpoFeatAnnos))

ggplot(featAvailMat, aes(x=Feature, y=Dataset, fill=Captured)) +
  geom_tile() +
  scale_fill_manual(values = c('black', 'grey80')) +
  labs(title = 'Tumor Tissue Proteomics') +
  theme(axis.ticks = element_blank(), panel.grid = element_blank(), panel.background = element_blank(),
        axis.text.x = element_text(size = 18, face = 'bold', angle = 45, hjust = 1, vjust = 1),
        axis.text.y = element_text(size = 18, face = 'bold'),
        axis.title = element_text(size = 20, face = 'bold'),
        legend.title = element_text(size = 20), legend.text = element_text(size = 18),
        plot.title = element_text(size = 28, face = 'bold', hjust = 0.5, vjust = 1.5))
```

## RF

<font size='5'> **Stability selection** </font>

**Performance statistics of 1000 models**
```{r}
# Load imputed adjusted data
impuAdjProTumor_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProTumorVsn.rds')
# Load SOA results for retrieving significant feature list for initial feature selection
proTumorRes_Klin <- readRDS('./data/Discovery/AG_Klingmueller/soaRes/proTumorRes_SVs.rds')

# Train models iteratively
# Prepare significant feature list
sigFeatList <- proTumorRes_Klin$sig.feat.tab$Var1
# rfRes <- iterRF(impuAdjProTumor_Klin, doImputation = F, doInitFeatSelection = T,
#                 sigFeatList = sigFeatList, doFeatClustering = T, iter = 1000)
# saveRDS(rfRes, './data/Discovery/rf/rfResSOA_SVs_impuAdjProTumor_0.8r_randSplit_1000_Klin.rds')
rfRes <- readRDS('./data/Discovery/rf/rfResSOA_SVs_impuAdjProTumor_0.8r_randSplit_1000_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- rfRes$rfRes$y_pred
truth <- rfRes$rfRes$y_truth
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Top important features with highest median ranks**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Klin <- readRDS('./data/Discovery/AG_Klingmueller/proTissueVsn.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')
topImpoFeatViz <- vizTopImpoFeatsRF(rfRes, fullData = proTissue_Klin, trainData_smpType = 'Tumor',
                                    featAnno = featAnno, num_p1TopFeats = 30)
topImpoFeatViz$rank
```

**Full feature importance table**
```{r}
DT::datatable(topImpoFeatViz$fullImpoFeatTab)
```

<font size='5'> **Systematic training and evaluation** </font>

**Performance of models trained with different numbers of top important features**
```{r}
# Systematically train models with different numbers of top important features
# sysTrainModels <- doSysTrainRF(rfRes, impuAdjProTumor_Klin, max_numTopFeats = 100)
# saveRDS(sysTrainModels, './data/Discovery/rf/sysTrain_rfResSOA_SVs_impuAdjProTumor_randSplit_100_Klin.rds')
sysTrainModels <- readRDS('./data/Discovery/rf/sysTrain_rfResSOA_SVs_impuAdjProTumor_randSplit_100_Klin.rds')

# Visualize systematic training
vizSysTrainModelPerf(sysTrainModels, numTopFeats = 40)
```
=> Top 34, resulting in model with AUC of 1 [1,1]

## XGBoost

<font size='5'> **Linear booster** </font>

**Models trained with core features selected by lasso logistic regression**
```{r}
###############
# Change here #
################################################################################
# Load imputed adjusted data
se <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProTumorVsn.rds')
# Load trained models
lrRes <- readRDS('./data/Discovery/logisR/lrResSOA_SVs_impuAdjProTumor_0.8r_randSplit_1000_5fold_auc_lmin_Klin.rds')
# Specify number of core features selected by lasso logistic regression
numTopImpoFeats <- 6
################################################################################

# Retrieve core feature list
coreFeats <- vizTopImpoFeatsLR(lrRes)$fullImpoFeatTab$Feature[1:numTopImpoFeats]
# Subset core features from data
coreSE <- se[rownames(se) %in% coreFeats,]

# Train models iteratively
# linearBoostRes <- iterXGBoost(coreSE, booster = 'gblinear', iter = 100, nrounds = 1000)
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbRes_SVs_coreImpuAdjProTumor_randSplit_rmse_nR1000_iter100_Klin.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbRes_SVs_coreImpuAdjProTumor_randSplit_rmse_nR1000_iter100_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Models trained with grouped recurrence-related features**
```{r}
###############
# Change here #
################################################################################
# Load imputed adjusted data
se <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProTumorVsn.rds')
# Load SOA results for retrieving significant feature list for initial feature selection
soaRes <- readRDS('./data/Discovery/AG_Klingmueller/soaRes/proTumorRes_SVs.rds')
################################################################################

# Train models iteratively
# Prepare significant feature list
sigFeatList <- soaRes$sig.feat.tab$Var1
# linearBoostRes <- iterXGBoost(se, doImputation = F, doInitFeatSelection = T,
#                               sigFeatList = sigFeatList, doFeatClustering = T,
#                               booster = 'gblinear', iter = 100, nrounds = 1000)
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbRes_SVs_impuAdjProTumor_randSplit_rmse_nR1000_iter100_Klin.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbRes_SVs_impuAdjProTumor_randSplit_rmse_nR1000_iter100_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

<font size='5'> **Tree booster** </font>

**Models trained with core features selected by random forest**
```{r}
###############
# Change here #
################################################################################
# Load imputed adjusted data
se <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProTumorVsn.rds')
# Load trained models
rfRes <- readRDS('./data/Discovery/rf/rfResSOA_SVs_impuAdjProTumor_0.8r_randSplit_1000_Klin.rds')
# Specify number of core features selected by random forest
numTopImpoFeats <- 34
################################################################################

# Retrieve core feature list
coreFeats <- vizTopImpoFeatsRF(rfRes)$fullImpoFeatTab$Feature[1:numTopImpoFeats]
# Subset core features from data
coreSE <- se[rownames(se) %in% coreFeats,]

# Train models iteratively
# treeBoostRes <- iterXGBoost(coreSE, booster = 'gbtree', iter = 100, nrounds = 1000)
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbRes_SVs_coreImpuAdjProTumor_randSplit_auc_nR1000_iter100_Klin.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbRes_SVs_coreImpuAdjProTumor_randSplit_auc_nR1000_iter100_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Models trained with grouped recurrence-related features**
```{r}
###############
# Change here #
################################################################################
# Load imputed adjusted data
se <- readRDS('./data/Discovery/AG_Klingmueller/impuAdjProTumorVsn.rds')
# Load SOA results for retrieving significant feature list for initial feature selection
soaRes <- readRDS('./data/Discovery/AG_Klingmueller/soaRes/proTumorRes_SVs.rds')
################################################################################

# Train models iteratively
# Prepare significant feature list
sigFeatList <- soaRes$sig.feat.tab$Var1
# treeBoostRes <- iterXGBoost(se, doImputation = F, doInitFeatSelection = T,
#                             sigFeatList = sigFeatList, doFeatClustering = T,
#                             booster = 'gbtree', iter = 100, nrounds = 1000)
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbRes_SVs_impuAdjProTumor_randSplit_auc_nR1000_iter100_Klin.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbRes_SVs_impuAdjProTumor_randSplit_auc_nR1000_iter100_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

# NTP (AG Krij.)
Normal Tissue DIA Proteomics from AG Krijgsveld

## RF

```{r message=F, eval=F, include=F}
# Prepare input data, which includes imputation, initial feature selection, correlated
# feature removal, and RF training. Take Normal Tissue DIA Proteomics as example

# Load preprocessed data
proTissue_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/combined_proTissueVsnBC.rds')
proTissue <- proTissue_Krij
# Subset data
proNormal <- proTissue[, colData(proTissue)$Condition == 'Normal']
proTumor <- proTissue[, colData(proTissue)$Condition == 'Tumor']

# Normal tissues
# Impute missing values using missForest
# dat <- t(assay(proNormal))
# impuDat <- missForest(dat, maxiter = 10, verbose = T)$ximp %>%
#   t()
# assay(proNormal) <- impuDat
# saveRDS(proNormal, './data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')

# Load imputed data
proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
proNormal <- proNormal_Krij

# Prepare input data for RF
# Retrieve data matrix from SE object
datMat <- t(assay(proNormal)) %>%
  tibble::as_tibble(rownames = 'Sample')
# Retrieve patient recurrence annotations
recurAnno <- tibble::as_tibble(colData(proNormal), rownames = 'Sample') %>%
  dplyr::select(Sample, Recurrence)
# Include recurrence information into data matrix
allFeats <- dplyr::left_join(recurAnno, datMat, by = 'Sample') %>%
  tibble::column_to_rownames('Sample')
# Do initial feature selection
# Identify recurrence-related statistically significant features
soaRes <- doSOA(proNormal, meta_var = 'Recurrence', use_limma = T)
sigFeats <- dplyr::select(allFeats, c(Recurrence, soaRes$featSigAssoRes$Var1))
# Cluster highly correlated features and keep only one representative of each cluster
sigFeatClusters <- rmCorrFeats(t(sigFeats[, -1]), cutoff = 0.8)
uncorrSigFeats <- dplyr::select(sigFeats, c(Recurrence, rownames(sigFeatClusters$reducedData)))

# Run RF
# Set random seed for reproducible outcomes
set.seed(42)
x <- as.matrix(uncorrSigFeats[, -1])
y <- uncorrSigFeats[, 1]
spsUtil::quiet(
  rfResSig <- runRF(x, y, targetClass = 'Yes', iter = 1, split_method = 'random split', save_RF = T)
)

# Overview trained RF
# print(rfResSig$rfRes[[1]])
# Play around with thresholds
cutoff <- 0.5
expectedVals <- rfResSig$y_test[[1]]
predictedVals <- as.numeric(rfResSig$rfRes[[1]]$test$votes[, '1'] > cutoff) %>%
  factor()
caret::confusionMatrix(data = predictedVals, reference = expectedVals, positive = '1')
```

**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/rfResSig_proNormal_randSplit_1000_Krij.rds')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_test
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Top important features with highest median ranks**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/combined_proTissueVsnBC.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Krij), rownames = 'Feature') %>%
  dplyr::select(Feature, Genes)

topImpoFeatPlots <- vizTopImpoFeatsRF(rfRes, fullData = proTissue_Krij, trainData_smpType = 'Normal',
                                      featAnno = featAnno, num_p1TopFeats = 15)
topImpoFeatPlots$rank
# ggsave('./output/Discovery/group_meeting/combined_rf_featImpo_proNormal_Krij.png',
#        device = 'png', dpi = 400, height = 8, width = 10)
```

## XGBoost

```{r message=F, eval=F, include=F}
## NTP (AG Krij.)
# Normal Tissue DIA Proteomics from AG Krijgsveld

# XGBoost supports missing values by default. Branch directions for missing values
# are learned during training. Note that 'gblinear' booster treats missing values
# as zeros.

# Load imputed data
proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
proNormal <- proNormal_Krij
# Do initial feature selection
# Identify recurrence-related statistically significant features
soaRes <- doSOA(proNormal, meta_var = 'Recurrence', use_limma = T)
x <- t(assay(proNormal))
x <- x[, colnames(x) %in% soaRes$featSigAssoRes$Var1]
# Cluster highly correlated features and keep only one representative of each cluster
featClusters <- rmCorrFeats(t(x), cutoff = 0.8)
x <- t(featClusters$reducedData)
y <- colData(proNormal)$Recurrence
y <- ifelse(test = y == 'Yes', yes = 1, no = 0)

# Determine best number of iteration using cross-validation
# allDat <- xgb.DMatrix(data = x, label = y)
# bestIter <- xgb.cv(data = allDat, params = paramsTree, nrounds = 20, nfold = 5, verbose = T)
# ggplot(bestIter$evaluation_log, aes(x=iter, y=train_logloss_mean)) +
#   geom_line(linewidth = 1) +
#   geom_line(aes(y=test_logloss_mean), color = 'firebrick', linewidth = 1) +
#   labs(x = 'Iteration', y = 'Loss') +
#   th
#### => Learning curves look weird...

# Split data into training, validation, and test sets
# Set random seed for reproducible outcomes
set.seed(42)
# trainIdx <- subsetTrainData(x, y, split_method = 'bootstrap', trainSet_ratio = 0.8)
trainIdx <- caret::createDataPartition(y, times = 1, p = 0.6, list = T)
x_train <- x[trainIdx[[1]],, drop = F]
y_train <- y[trainIdx[[1]]]
restIdx <- seq_along(y)[!seq_along(y) %in% trainIdx[[1]]]
ySub <- y[restIdx]
validIdx <- caret::createDataPartition(ySub, times = 1, p = 0.5, list = T)
x_valid <- x[restIdx[validIdx[[1]]],, drop = F]
y_valid <- y[restIdx[validIdx[[1]]]]
x_test <- x[restIdx[-validIdx[[1]]],, drop = F]
y_test <- y[restIdx[-validIdx[[1]]]]
# Collect split data into xgb.DMatrix objects
trainDat <- xgb.DMatrix(data = x_train, label = y_train)
validDat <- xgb.DMatrix(data = x_valid, label = y_valid)
testDat <- xgb.DMatrix(data = x_test, label = y_test)

# Train XGBoost with tree booster
# Prepare parameters for training XGBoost
paramsTree <- list(booster = 'gbtree',
                   objective = 'binary:logistic',
                   eval_metric = 'error',
                   eval_metric = 'logloss',
                   max_depth = 6,
                   eta = 0.3)
# Determine best number of iteration
watchlist <- list(train = trainDat, valid = validDat)
treeBoost <- xgb.train(data = trainDat, params = paramsTree, nrounds = 50,
                       watchlist = watchlist, verbose = 1, early_stopping_rounds = 4)
ggplot(treeBoost$evaluation_log, aes(x=iter, y=train_logloss)) +
  geom_line(linewidth = 1) +
  geom_line(aes(y=valid_logloss), color = 'firebrick', linewidth = 1) +
  labs(x = 'Iteration', y = 'Loss') +
  th
# Retrain XGBoost with combined data including training and validation
# combinedTrainIdx <- c(trainIdx[[1]], restIdx[validIdx[[1]]])
# combinedTrainDat <- xgb.DMatrix(data = x[combinedTrainIdx,, drop = F],
#                                 label = y[combinedTrainIdx])
# treeBoost <- xgb.train(data = combinedTrainDat, params = paramsTree, nrounds = 3, verbose = 1)

# Predict unseen data using trained XGBoost
# Play around with thresholds
cutoff <- 0.5
truth <- getinfo(testDat, 'label') %>%
  factor()
pred <- as.numeric(predict(treeBoost, testDat) > cutoff) %>%
  factor()
caret::confusionMatrix(data = pred, reference = truth, positive = '1')

# Visualize results of trained XGBoost
# Structure of trees
# xgb.plot.tree(model = treeBoost)
# Feature importance
impoTab <- xgb.importance(model = treeBoost)
xgb.ggplot.importance(importance_matrix = impoTab) +
  th
# ggsave('./output/Discovery/group_meeting/combined_xgboost_featImpo_proNormal_Krij.png',
#        device = 'png', dpi = 400, height = 8, width = 10)
```

**Tree booster**
```{r}
# Load imputed data
# proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
# treeBoostRes <- iterXGBoost(proNormal_Krij, booster = 'gbtree')
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbResSig_proNormal_randSplit_logloss_1000_Krij.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbResSig_proNormal_randSplit_logloss_1000_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Linear booster**
```{r}
# Load imputed data
# proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
# linearBoostRes <- iterXGBoost(proNormal_Krij, booster = 'gblinear')
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbResSig_proNormal_randSplit_error_1000_Krij.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbResSig_proNormal_randSplit_error_1000_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

## Lasso logistic regression

**Models with no any non-zero beta are removed.**
```{r warning=T}
# Load imputed data
# proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
# lrRes <- iterLogisR(proNormal_Krij, iter = 1000, cvFold = 5, cvMeasure = 'auc')
# saveRDS(lrRes, './data/Discovery/logisR/lrResSig_proNormal_randSplit_1000_5fold_auc_lmin_Krij.rds')
lrRes <- readRDS('./data/Discovery/logisR/lrResSig_proNormal_randSplit_1000_5fold_auc_lmin_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  pred <- lrRes$lrRes$y_pred[-uselessModels]
  truth <- lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- lrRes$lrRes$y_pred
  truth <- lrRes$lrRes$y_truth
  auc_roc <- lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc))
```

# TTP (AG Krij.)
Tumor Tissue DIA Proteomics from AG Krijgsveld

## RF

**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/rfResSig_proTumor_randSplit_1000_Krij.rds')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_test
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Top important features with highest median ranks**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/combined_proTissueVsnBC.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Krij), rownames = 'Feature') %>%
  dplyr::select(Feature, Genes)

topImpoFeatPlots <- vizTopImpoFeatsRF(rfRes, fullData = proTissue_Krij, trainData_smpType = 'Tumor',
                                      featAnno = featAnno, num_p1TopFeats = 15)
topImpoFeatPlots$rank
```

## XGBoost

**Tree booster**
```{r}
# Load imputed data
# proTumor_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proTumorVsnImpu.rds')
# treeBoostRes <- iterXGBoost(proTumor_Krij, booster = 'gbtree')
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbResSig_proTumor_randSplit_logloss_1000_Krij.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbResSig_proTumor_randSplit_logloss_1000_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Linear booster**
```{r}
# Load imputed data
# proTumor_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proTumorVsnImpu.rds')
# linearBoostRes <- iterXGBoost(proTumor_Krij, booster = 'gblinear')
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbResSig_proTumor_randSplit_error_1000_Krij.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbResSig_proTumor_randSplit_error_1000_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

## Lasso logistic regression

**Models with no any non-zero beta are removed.**
```{r warning=T}
# Load imputed data
# proTumor_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proTumorVsnImpu.rds')
# lrRes <- iterLogisR(proTumor_Krij, iter = 1000, cvFold = 5, cvMeasure = 'auc')
# saveRDS(lrRes, './data/Discovery/logisR/lrResSig_proTumor_randSplit_1000_5fold_auc_lmin_Krij.rds')
lrRes <- readRDS('./data/Discovery/logisR/lrResSig_proTumor_randSplit_1000_5fold_auc_lmin_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  pred <- lrRes$lrRes$y_pred[-uselessModels]
  truth <- lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- lrRes$lrRes$y_pred
  truth <- lrRes$lrRes$y_truth
  auc_roc <- lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc))
```




# Unt. Lipid.
Untargeted Lipidomics

## RF

```{r}
# NTL
# Load preprocessed data
# Discovery
# dis_lipTissue_Hopf <- readRDS('./data/Discovery/AG_Hopf/lipTissueVsn_WBC25.rds')
# Method development
mDev_lipTissue_Hopf <- readRDS('./data/MethodDev/AG_Hopf/lipTissueVsn.rds')
lipTissue <- mDev_lipTissue_Hopf
# Subset data
lipNormal <- lipTissue[, colData(lipTissue)$Condition == 'Normal']
# Remove features observed in less than 67% of samples
rmFeats <- apply(assay(lipNormal), 1, function(featVec) {
  obProp <- sum(!is.na(featVec)) / length(featVec)
  obProp <= 0.67
}) %>%
  which()
if (length(rmFeats) != 0) {
  lipNormal <- lipNormal[-rmFeats,]
}
# Impute missing values using missForest
dat <- t(assay(lipNormal))
impuDat <- missForest(dat, maxiter = 10, verbose = T)$ximp %>%
  t()
assay(lipNormal) <- impuDat
# saveRDS(lipNormal, './data/MethodDev/AG_Hopf/impuByMF//lipNormalVsnImpu.rds')

# BPL
# Load preprocessed data
# Discovery
# dis_lipBase_Hopf <- readRDS('./data/Discovery/AG_Hopf/lipBaseVsn_B1WBC25.rds')
# Method development
# Subset data
mDev_lipPlasma_Hopf <- readRDS('./data/MethodDev/AG_Hopf/lipPlasmaVsn.rds')
lipPlasma <- mDev_lipPlasma_Hopf
lipBase <- lipPlasma[, colData(lipPlasma)$TimePoint == 'Baseline']
# Remove features observed in less than 67% of samples
rmFeats <- apply(assay(lipBase), 1, function(featVec) {
  obProp <- sum(!is.na(featVec)) / length(featVec)
  obProp <= 0.67
}) %>%
  which()
if (length(rmFeats) != 0) {
  lipBase <- lipBase[-rmFeats,]
}
# Impute missing values using missForest
dat <- t(assay(lipBase))
impuDat <- missForest(dat, maxiter = 10, verbose = T)$ximp %>%
  t()
assay(lipBase) <- impuDat
# saveRDS(lipBase, './data/MethodDev/AG_Hopf/impuByMF/lipBaseVsnImpu.rds')


# Train RF
# rfRes <- iterRF(lipBase)
# saveRDS(rfRes, './data/Discovery/rf/untLip/rfResSig_mDev_untLipBase_randSplit_1000')
```

### Dis. NTL
**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/untLip/rfResSig_dis_untLipNormal_randSplit_1000')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_truth
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

### Dis. BPL
**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/untLip/rfResSig_dis_untLipBase_randSplit_1000')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_truth
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

### MDev. NTL
**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/untLip/rfResSig_mDev_untLipNormal_randSplit_1000')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_truth
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

### MDev. BPL
**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/untLip/rfResSig_mDev_untLipBase_randSplit_1000')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_truth
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```
