---
title: 'Feature selection: Machine learning models'
author: "Qian-Wu Liao"
output:
  workflowr::wflow_html:
    toc: true
    toc_float: true
    code_folding: hide
---

<font size='4'> Description: Do feature selection using machine learning models
(e.g., random forest) trained on combined data of cohorts to identify potential
biomarkers for predicting lung cancer recurrence. </font>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.height = 8, fig.width = 10, warning = F)
knitr::opts_knit$set(root.dir = '/Users/qianwu/Desktop/SMART-CARE_LungCancer')
```

Load libraries
```{r library loading, message = F}
library('spsUtil')
library('randomForest')
library('missForest')
library(xgboost)
library('caret')
library('glmnet')
library('SummarizedExperiment')
library('tidyverse')
# Load user-defined functions
source('./code/misc.R')
source('./code/ml_funcs.R')

# Set plot theme
th <- theme_bw(base_size = 15) +
  theme(axis.title = element_text(face = 'bold'),
        axis.text = element_text(face = 'bold'),
        axis.ticks = element_line(linewidth = 0.8),
        legend.text = element_text(size = 15))
```

# NTP (AG Klin.)
Normal Tissue DIA Proteomics from AG Klingmüller

## RF

**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/rfResSig_proNormal_randSplit_1000_Klin.rds')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_test
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Top important features with highest median ranks**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Klin <- readRDS('./data/MethodDev/AG_Klingmueller/proTissueVsnBC.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')

topImpoFeatPlots <- vizTopImpoFeatsRF(rfRes, fullData = proTissue_Klin, trainData_smpType = 'Normal',
                                      featAnno = featAnno, num_p1TopFeats = 15)
topImpoFeatPlots$topFeatTab
topImpoFeatPlots$rank + theme(axis.title = element_text(size = 28),
                              axis.text = element_text(size = 16))
# ggsave('./output/Discovery/group_meeting/rf_topImpo_combined_proNormal_Klin.png',
#        device = 'png', dpi = 400, height = 8, width = 10)

topImpoFeatPlots$abun
```

## XGBoost

**Tree booster**
```{r}
# Load imputed data
# proNormal_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuByMF/proNormalVsnImpu.rds')
# treeBoostRes <- iterXGBoost(proNormal_Klin, booster = 'gbtree')
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbResSig_proNormal_randSplit_logloss_1000_Klin.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbResSig_proNormal_randSplit_logloss_1000_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)

# Take only models with good performance?
bestModels <- which(treeBoostRes$xgbRes$auc_roc == 1)
```

```{r}
# treeBoostRes$xgbRes$auc_roc
```

**Linear booster**
```{r}
# Load imputed data
# proNormal_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuByMF/proNormalVsnImpu.rds')
# linearBoostRes <- iterXGBoost(proNormal_Klin, booster = 'gblinear')
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbResSig_proNormal_randSplit_logloss_1000_Klin.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbResSig_proNormal_randSplit_error_1000_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)

# impoTab <- xgb.importance(model = linearBoost$modelRes[[1]])
# xgb.ggplot.importance(importance_matrix = impoTab,  top_n = 20) +
#   th
```

## Lasso logistic regression

**Models with no any non-zero beta are removed.**
```{r warning=T}
# Load imputed data. Use 'deviance' as CV metric due to too few (< 10) observations per fold for 'auc'
# proNormal_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuByMF/proNormalVsnImpu.rds')
# lrRes <- iterLogisR(proNormal_Klin, iter = 1000, cvFold = 5, cvMeasure = 'deviance')
# saveRDS(lrRes, './data/Discovery/logisR/lrResSig_proNormal_randSplit_1000_5fold_deviance_lmin_Klin.rds')
lrRes <- readRDS('./data/Discovery/logisR/lrResSig_proNormal_randSplit_1000_5fold_deviance_lmin_Klin.rds')

# Pinpoint useless models that will be removed
uselessModels <- which(lrRes$lrRes$nNonZero == 0) #higher lambda results in simpler model
# for (i in uselessModels) {
#   pred <- lrRes$lrRes$y_pred[[i]]
#   truth <- lrRes$lrRes$y_truth[[i]]
#   scores <- caret::confusionMatrix(data = pred, reference = truth, positive = '1')
#   cat(scores$overall[['Accuracy']], '\n')
# } # Models that got only intercept make random predictions, 0.5 accuracy and AUC-ROC

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
if (length(uselessModels) != 0) {
  pred <- lrRes$lrRes$y_pred[-uselessModels]
  truth <- lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- lrRes$lrRes$y_pred
  truth <- lrRes$lrRes$y_truth
  auc_roc <- lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc)) #warning due to sometimes only pos or neg predictions
```

**Total number of unique selected features by top models (depending on AUC-ROC)**
```{r}
# Show number of features with non-zero coefficients, i.e., selected features
cutoffs <- c(1, 0.9, 0.8, 0.7, 0.6, 0.5)
numPickedFeats <- c()
for (cuto in cutoffs) {
  models <- which(lrRes$lrRes$auc_roc >= cuto)
  coefMat <- lrRes$lrRes$coefficient[, models]
  topImpoFeats <- as.data.frame(coefMat) %>%
    dplyr::mutate(across(everything(), ~ case_when(.x != 0 ~ 1,
                                                   .x == 0 ~ 0))) %>%
    tibble::rownames_to_column('Feature') %>%
    tidyr::pivot_longer(cols = -'Feature', names_to = 'Model', values_to = 'Pick') %>%
    dplyr::filter(Pick != 0) %>%
    dplyr::pull(Feature) %>%
    unique()
  numPickedFeats <- c(numPickedFeats, length(topImpoFeats))
}
numPickedFeatTab <- data.frame(Cutoff = cutoffs, NumPickedFeats = numPickedFeats)

ggplot(numPickedFeatTab, aes(x=Cutoff, y=NumPickedFeats)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2.5) +
  labs(x = 'Cutoff of AUC-ROC for model selection',
       y = 'Total number of unique selected features') +
  th
```

**Top important features that are most frequently selected**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Klin <- readRDS('./data/MethodDev/AG_Klingmueller/proTissueVsnBC.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')

topImpoFeatPlots <- vizTopImpoFeatsLR(lrRes, fullData = proTissue_Klin, trainData_smpType = 'Normal',
                                      featAnno = featAnno, num_p1TopFeats = 15)
topImpoFeatPlots$topFeatTab
topImpoFeatPlots$pick
topImpoFeatPlots$abun
```

```{r}
# Train models with top important features
cutoffs <- c(1, 0.9, 0.8, 0.7, 0.6, 0.5)
# proNormal_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuByMF/proNormalVsnImpu.rds')
# for (cuto in cutoffs) {
#   models <- which(lrRes$lrRes$auc_roc >= cuto)
#   coefMat <- lrRes$lrRes$coefficient[, models]
#   topImpoFeatTab <- as.data.frame(coefMat) %>%
#     dplyr::mutate(across(everything(), ~ case_when(.x != 0 ~ 1,
#                                                    .x == 0 ~ 0))) %>%
#     tibble::rownames_to_column('Feature') %>%
#     tidyr::pivot_longer(cols = -'Feature', names_to = 'Model', values_to = 'Pick') %>%
#     dplyr::group_by(Feature) %>%
#     dplyr::summarise(Frequency = sum(Pick),
#                      PickRate = Frequency/length(models)) %>%
#     dplyr::filter(Frequency != 0) %>%
#     dplyr::arrange(desc(Frequency))
#   topImpoFeats <- topImpoFeatTab$Feature
# 
#   # Train lasso logistic regression model
#   x <- t(lrRes$featClusters$reducedData[topImpoFeats,])
#   y <- colData(proNormal_Klin)$Recurrence
#   # set.seed(42)
#   lrResStab <- runLogisR(x, y, targetClass = 'Yes', iter = 1000, regularized_method = 'lasso',
#                          cvFold = 5, cvMeasure = 'deviance', used_lambda = 'lambda.min',
#                          trainSet_ratio = 0.8, split_method = 'random split',
#                          plot_ROC = F, save_model = T)
#   saveRDS(lrResStab, paste0('./data/Discovery/logisR/AUC', cuto,
#                             '_lrResSig_proNormal_randSplit_1000_5fold_deviance_lmin_Klin.rds'))
# }

# Display performance of reduced models
meanAUC <- c()
lowerAUC <- c()
upperAUC <- c()
lrRes <- readRDS('./data/Discovery/logisR/lrResSig_proNormal_randSplit_1000_5fold_deviance_lmin_Klin.rds')
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
ci <- calcCI(auc_roc, bootstrap = T)
lowerAUC <- c(lowerAUC, ci[1])
upperAUC <- c(upperAUC, ci[2])
for (cuto in cutoffs) {
  lrResStab <- readRDS(paste0('./data/Discovery/logisR/others/AUC', cuto,
                              '_lrResSig_proNormal_randSplit_1000_5fold_deviance_lmin_Klin.rds'))
  auc_roc <- lrResStab$auc_roc
  meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
  ci <- calcCI(auc_roc, bootstrap = T)
  lowerAUC <- c(lowerAUC, ci[1])
  upperAUC <- c(upperAUC, ci[2])
}
aucStatTab <- data.frame(FeatSpace = c('Ori.', paste0('AUC >= ', cutoffs)),
                         MeanAUC = meanAUC, UpperAUC = upperAUC, LowerAUC = lowerAUC)

ggplot(aucStatTab, aes(x=FeatSpace, y=MeanAUC)) +
  geom_bar(stat = 'identity', position = position_dodge(), alpha = 0.9) +
  geom_errorbar(aes(ymin=LowerAUC, ymax=UpperAUC), width = 0.4) +
  labs(x = 'Feature space used to train 1000 models', y = 'Mean AUC-ROC',
       title = 'Reduced models') +
  th


# Train models without top important features, aka noninformative models
# proNormal_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuByMF/proNormalVsnImpu.rds')
# cutoffs <- c(1, 0.9, 0.8, 0.7, 0.6, 0.5)
# for (cuto in cutoffs) {
#   models <- which(lrRes$lrRes$auc_roc >= cuto)
#   coefMat <- lrRes$lrRes$coefficient[, models]
#   topImpoFeats <- as.data.frame(coefMat) %>%
#     dplyr::mutate(across(everything(), ~ case_when(.x != 0 ~ 1,
#                                                    .x == 0 ~ 0))) %>%
#     tibble::rownames_to_column('Feature') %>%
#     tidyr::pivot_longer(cols = -'Feature', names_to = 'Model', values_to = 'Pick') %>%
#     dplyr::filter(Pick != 0) %>%
#     dplyr::pull(Feature) %>%
#     unique()
# 
#   # Train lasso logistic regression model
#   reducedData <- lrRes$featClusters$reducedData
#   x <- t(reducedData[!rownames(reducedData) %in% topImpoFeats,])
#   y <- colData(proNormal_Klin)$Recurrence
#   # set.seed(42)
#   lrResNonInfo <- runLogisR(x, y, targetClass = 'Yes', iter = 1000, regularized_method = 'lasso',
#                             cvFold = 5, cvMeasure = 'deviance', used_lambda = 'lambda.min',
#                             trainSet_ratio = 0.8, split_method = 'random split',
#                             plot_ROC = F, save_model = T)
#   saveRDS(lrResNonInfo, paste0('./data/Discovery/logisR/NonInfo_AUC', cuto,
#                                '_lrResSig_proNormal_randSplit_1000_5fold_deviance_lmin_Klin.rds'))
# }

# Display performance of noninformative models
meanAUC <- c()
lowerAUC <- c()
upperAUC <- c()
lrRes <- readRDS('./data/Discovery/logisR/lrResSig_proNormal_randSplit_1000_5fold_deviance_lmin_Klin.rds')
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
ci <- calcCI(auc_roc, bootstrap = T)
lowerAUC <- c(lowerAUC, ci[1])
upperAUC <- c(upperAUC, ci[2])
for (cuto in cutoffs) {
  lrResNonInfo <- readRDS(paste0('./data/Discovery/logisR/others/NonInfo_AUC', cuto,
                                 '_lrResSig_proNormal_randSplit_1000_5fold_deviance_lmin_Klin.rds'))
  auc_roc <- lrResNonInfo$auc_roc
  meanAUC <- c(meanAUC, round(mean(auc_roc), 3))
  ci <- calcCI(auc_roc, bootstrap = T)
  lowerAUC <- c(lowerAUC, ci[1])
  upperAUC <- c(upperAUC, ci[2])
}
aucStatTab <- data.frame(FeatSpace = c('Ori.', paste0('AUC >= ', cutoffs)),
                         MeanAUC = meanAUC, UpperAUC = upperAUC, LowerAUC = lowerAUC)

ggplot(aucStatTab, aes(x=FeatSpace, y=MeanAUC)) +
  geom_bar(stat = 'identity', position = position_dodge(), alpha = 0.9) +
  geom_errorbar(aes(ymin=LowerAUC, ymax=UpperAUC), width = 0.4) +
  labs(x = 'Feature space removed to train 1000 models', y = 'Mean AUC-ROC',
       title = 'Noninformative models') +
  th
```

# TTP (AG Klin.)
Tumor Tissue DIA Proteomics from AG Klingmüller

## RF

**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/rfResSig_proTumor_randSplit_1000_Klin.rds')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_test
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Top important features with highest median ranks**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Klin <- readRDS('./data/MethodDev/AG_Klingmueller/proTissueVsnBC.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Klin), rownames = 'Feature')

topImpoFeatPlots <- vizTopImpoFeatsRF(rfRes, fullData = proTissue_Klin, trainData_smpType = 'Tumor',
                                      featAnno = featAnno, num_p1TopFeats = 15)
topImpoFeatPlots$rank
```

## XGBoost

**Tree booster**
```{r}
# Load imputed data
# proTumor_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuByMF/proTumorVsnImpu.rds')
# treeBoostRes <- iterXGBoost(proTumor_Klin, booster = 'gbtree')
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbResSig_proTumor_randSplit_logloss_1000_Klin.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbResSig_proTumor_randSplit_logloss_1000_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Linear booster**
```{r}
# Load imputed data
# proTumor_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuByMF/proTumorVsnImpu.rds')
# linearBoostRes <- iterXGBoost(proTumor_Klin, booster = 'gblinear')
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbResSig_proTumor_randSplit_error_1000_Klin.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbResSig_proTumor_randSplit_error_1000_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

## Lasso logistic regression

**Models with no any non-zero beta are removed.**
```{r warning=T}
# Load imputed data
# proTumor_Klin <- readRDS('./data/Discovery/AG_Klingmueller/impuByMF/proTumorVsnImpu.rds')
# lrRes <- iterLogisR(proTumor_Klin, iter = 1000, cvFold = 5, cvMeasure = 'deviance')
# saveRDS(lrRes, './data/Discovery/logisR/lrResSig_proTumor_randSplit_1000_5fold_deviance_lmin_Klin.rds')
lrRes <- readRDS('./data/Discovery/logisR/lrResSig_proTumor_randSplit_1000_5fold_deviance_lmin_Klin.rds')

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  pred <- lrRes$lrRes$y_pred[-uselessModels]
  truth <- lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- lrRes$lrRes$y_pred
  truth <- lrRes$lrRes$y_truth
  auc_roc <- lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc))
```

# NTP (AG Krij.)
Normal Tissue DIA Proteomics from AG Krijgsveld

## RF

```{r message=F, eval=F, include=F}
# Prepare input data, which includes imputation, initial feature selection, correlated
# feature removal, and RF training. Take Normal Tissue DIA Proteomics as example

# Load preprocessed data
proTissue_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/combined_proTissueVsnBC.rds')
proTissue <- proTissue_Krij
# Subset data
proNormal <- proTissue[, colData(proTissue)$Condition == 'Normal']
proTumor <- proTissue[, colData(proTissue)$Condition == 'Tumor']

# Normal tissues
# Impute missing values using missForest
# dat <- t(assay(proNormal))
# impuDat <- missForest(dat, maxiter = 10, verbose = T)$ximp %>%
#   t()
# assay(proNormal) <- impuDat
# saveRDS(proNormal, './data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')

# Load imputed data
proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
proNormal <- proNormal_Krij

# Prepare input data for RF
# Retrieve data matrix from SE object
datMat <- t(assay(proNormal)) %>%
  tibble::as_tibble(rownames = 'Sample')
# Retrieve patient recurrence annotations
recurAnno <- tibble::as_tibble(colData(proNormal), rownames = 'Sample') %>%
  dplyr::select(Sample, Recurrence)
# Include recurrence information into data matrix
allFeats <- dplyr::left_join(recurAnno, datMat, by = 'Sample') %>%
  tibble::column_to_rownames('Sample')
# Do initial feature selection
# Identify recurrence-related statistically significant features
soaRes <- doSOA(proNormal, meta_var = 'Recurrence', use_limma = T)
sigFeats <- dplyr::select(allFeats, c(Recurrence, soaRes$featSigAssoRes$Var1))
# Cluster highly correlated features and keep only one representative of each cluster
sigFeatClusters <- rmCorrFeats(t(sigFeats[, -1]), cutoff = 0.8)
uncorrSigFeats <- dplyr::select(sigFeats, c(Recurrence, rownames(sigFeatClusters$reducedData)))

# Run RF
# Set random seed for reproducible outcomes
set.seed(42)
x <- as.matrix(uncorrSigFeats[, -1])
y <- uncorrSigFeats[, 1]
spsUtil::quiet(
  rfResSig <- runRF(x, y, targetClass = 'Yes', iter = 1, split_method = 'random split', save_RF = T)
)

# Overview trained RF
# print(rfResSig$rfRes[[1]])
# Play around with thresholds
cutoff <- 0.5
expectedVals <- rfResSig$y_test[[1]]
predictedVals <- as.numeric(rfResSig$rfRes[[1]]$test$votes[, '1'] > cutoff) %>%
  factor()
caret::confusionMatrix(data = predictedVals, reference = expectedVals, positive = '1')
```

**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/rfResSig_proNormal_randSplit_1000_Krij.rds')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_test
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Top important features with highest median ranks**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/combined_proTissueVsnBC.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Krij), rownames = 'Feature') %>%
  dplyr::select(Feature, Genes)

topImpoFeatPlots <- vizTopImpoFeatsRF(rfRes, fullData = proTissue_Krij, trainData_smpType = 'Normal',
                                      featAnno = featAnno, num_p1TopFeats = 15)
topImpoFeatPlots$rank
# ggsave('./output/Discovery/group_meeting/combined_rf_featImpo_proNormal_Krij.png',
#        device = 'png', dpi = 400, height = 8, width = 10)
```

## XGBoost

```{r message=F, eval=F, include=F}
## NTP (AG Krij.)
# Normal Tissue DIA Proteomics from AG Krijgsveld

# XGBoost supports missing values by default. Branch directions for missing values
# are learned during training. Note that 'gblinear' booster treats missing values
# as zeros.

# Load imputed data
proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
proNormal <- proNormal_Krij
# Do initial feature selection
# Identify recurrence-related statistically significant features
soaRes <- doSOA(proNormal, meta_var = 'Recurrence', use_limma = T)
x <- t(assay(proNormal))
x <- x[, colnames(x) %in% soaRes$featSigAssoRes$Var1]
# Cluster highly correlated features and keep only one representative of each cluster
featClusters <- rmCorrFeats(t(x), cutoff = 0.8)
x <- t(featClusters$reducedData)
y <- colData(proNormal)$Recurrence
y <- ifelse(test = y == 'Yes', yes = 1, no = 0)

# Determine best number of iteration using cross-validation
# allDat <- xgb.DMatrix(data = x, label = y)
# bestIter <- xgb.cv(data = allDat, params = paramsTree, nrounds = 20, nfold = 5, verbose = T)
# ggplot(bestIter$evaluation_log, aes(x=iter, y=train_logloss_mean)) +
#   geom_line(linewidth = 1) +
#   geom_line(aes(y=test_logloss_mean), color = 'firebrick', linewidth = 1) +
#   labs(x = 'Iteration', y = 'Loss') +
#   th
#### => Learning curves look weird...

# Split data into training, validation, and test sets
# Set random seed for reproducible outcomes
set.seed(42)
# trainIdx <- subsetTrainData(x, y, split_method = 'bootstrap', trainSet_ratio = 0.8)
trainIdx <- caret::createDataPartition(y, times = 1, p = 0.6, list = T)
x_train <- x[trainIdx[[1]],, drop = F]
y_train <- y[trainIdx[[1]]]
restIdx <- seq_along(y)[!seq_along(y) %in% trainIdx[[1]]]
ySub <- y[restIdx]
validIdx <- caret::createDataPartition(ySub, times = 1, p = 0.5, list = T)
x_valid <- x[restIdx[validIdx[[1]]],, drop = F]
y_valid <- y[restIdx[validIdx[[1]]]]
x_test <- x[restIdx[-validIdx[[1]]],, drop = F]
y_test <- y[restIdx[-validIdx[[1]]]]
# Collect split data into xgb.DMatrix objects
trainDat <- xgb.DMatrix(data = x_train, label = y_train)
validDat <- xgb.DMatrix(data = x_valid, label = y_valid)
testDat <- xgb.DMatrix(data = x_test, label = y_test)

# Train XGBoost with tree booster
# Prepare parameters for training XGBoost
paramsTree <- list(booster = 'gbtree',
                   objective = 'binary:logistic',
                   eval_metric = 'error',
                   eval_metric = 'logloss',
                   max_depth = 6,
                   eta = 0.3)
# Determine best number of iteration
watchlist <- list(train = trainDat, valid = validDat)
treeBoost <- xgb.train(data = trainDat, params = paramsTree, nrounds = 50,
                       watchlist = watchlist, verbose = 1, early_stopping_rounds = 4)
ggplot(treeBoost$evaluation_log, aes(x=iter, y=train_logloss)) +
  geom_line(linewidth = 1) +
  geom_line(aes(y=valid_logloss), color = 'firebrick', linewidth = 1) +
  labs(x = 'Iteration', y = 'Loss') +
  th
# Retrain XGBoost with combined data including training and validation
# combinedTrainIdx <- c(trainIdx[[1]], restIdx[validIdx[[1]]])
# combinedTrainDat <- xgb.DMatrix(data = x[combinedTrainIdx,, drop = F],
#                                 label = y[combinedTrainIdx])
# treeBoost <- xgb.train(data = combinedTrainDat, params = paramsTree, nrounds = 3, verbose = 1)

# Predict unseen data using trained XGBoost
# Play around with thresholds
cutoff <- 0.5
truth <- getinfo(testDat, 'label') %>%
  factor()
pred <- as.numeric(predict(treeBoost, testDat) > cutoff) %>%
  factor()
caret::confusionMatrix(data = pred, reference = truth, positive = '1')

# Visualize results of trained XGBoost
# Structure of trees
# xgb.plot.tree(model = treeBoost)
# Feature importance
impoTab <- xgb.importance(model = treeBoost)
xgb.ggplot.importance(importance_matrix = impoTab) +
  th
# ggsave('./output/Discovery/group_meeting/combined_xgboost_featImpo_proNormal_Krij.png',
#        device = 'png', dpi = 400, height = 8, width = 10)
```

**Tree booster**
```{r}
# Load imputed data
# proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
# treeBoostRes <- iterXGBoost(proNormal_Krij, booster = 'gbtree')
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbResSig_proNormal_randSplit_logloss_1000_Krij.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbResSig_proNormal_randSplit_logloss_1000_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Linear booster**
```{r}
# Load imputed data
# proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
# linearBoostRes <- iterXGBoost(proNormal_Krij, booster = 'gblinear')
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbResSig_proNormal_randSplit_error_1000_Krij.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbResSig_proNormal_randSplit_error_1000_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

## Lasso logistic regression

**Models with no any non-zero beta are removed.**
```{r warning=T}
# Load imputed data
# proNormal_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proNormalVsnImpu.rds')
# lrRes <- iterLogisR(proNormal_Krij, iter = 1000, cvFold = 5, cvMeasure = 'auc')
# saveRDS(lrRes, './data/Discovery/logisR/lrResSig_proNormal_randSplit_1000_5fold_auc_lmin_Krij.rds')
lrRes <- readRDS('./data/Discovery/logisR/lrResSig_proNormal_randSplit_1000_5fold_auc_lmin_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  pred <- lrRes$lrRes$y_pred[-uselessModels]
  truth <- lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- lrRes$lrRes$y_pred
  truth <- lrRes$lrRes$y_truth
  auc_roc <- lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc))
```

# TTP (AG Krij.)
Tumor Tissue DIA Proteomics from AG Krijgsveld

## RF

**Average model performance (Uncorrelated significant features, iter = 1000)**
```{r}
# Load RF training results
rfRes <- readRDS('./data/Discovery/rf/rfResSig_proTumor_randSplit_1000_Krij.rds')

# Report summarized scores
trainedModels <- rfRes$rfRes$rfRes
# Prepare predictions and ground truths
pred <- as.list(rep(NA, length(trainedModels)))
for (i in seq_len(length(trainedModels))) {
  pred[[i]] <- trainedModels[[i]]$test$predicted
}
truth <- rfRes$rfRes$y_test
auc_roc <- rfRes$rfRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Top important features with highest median ranks**
```{r}
# Visualize top important features
# Prepare feature annotation table
proTissue_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/combined_proTissueVsnBC.rds')
featAnno <- tibble::as_tibble(rowData(proTissue_Krij), rownames = 'Feature') %>%
  dplyr::select(Feature, Genes)

topImpoFeatPlots <- vizTopImpoFeatsRF(rfRes, fullData = proTissue_Krij, trainData_smpType = 'Tumor',
                                      featAnno = featAnno, num_p1TopFeats = 15)
topImpoFeatPlots$rank
```

## XGBoost

**Tree booster**
```{r}
# Load imputed data
# proTumor_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proTumorVsnImpu.rds')
# treeBoostRes <- iterXGBoost(proTumor_Krij, booster = 'gbtree')
# saveRDS(treeBoostRes, './data/Discovery/xgboost/tree_xgbResSig_proTumor_randSplit_logloss_1000_Krij.rds')
treeBoostRes <- readRDS('./data/Discovery/xgboost/tree_xgbResSig_proTumor_randSplit_logloss_1000_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- treeBoostRes$xgbRes$y_pred
truth <- treeBoostRes$xgbRes$y_truth
auc_roc <- treeBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

**Linear booster**
```{r}
# Load imputed data
# proTumor_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proTumorVsnImpu.rds')
# linearBoostRes <- iterXGBoost(proTumor_Krij, booster = 'gblinear')
# saveRDS(linearBoostRes, './data/Discovery/xgboost/linear_xgbResSig_proTumor_randSplit_error_1000_Krij.rds')
linearBoostRes <- readRDS('./data/Discovery/xgboost/linear_xgbResSig_proTumor_randSplit_error_1000_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths
pred <- linearBoostRes$xgbRes$y_pred
truth <- linearBoostRes$xgbRes$y_truth
auc_roc <- linearBoostRes$xgbRes$auc_roc
summarizePredPower(pred, truth, auc_roc)
```

## Lasso logistic regression

**Models with no any non-zero beta are removed.**
```{r warning=T}
# Load imputed data
# proTumor_Krij <- readRDS('./data/Discovery/AG_Krijgsveld/impuByMF/combined_proTumorVsnImpu.rds')
# lrRes <- iterLogisR(proTumor_Krij, iter = 1000, cvFold = 5, cvMeasure = 'auc')
# saveRDS(lrRes, './data/Discovery/logisR/lrResSig_proTumor_randSplit_1000_5fold_auc_lmin_Krij.rds')
lrRes <- readRDS('./data/Discovery/logisR/lrResSig_proTumor_randSplit_1000_5fold_auc_lmin_Krij.rds')

# Report summarized scores
# Prepare predictions and ground truths where results from useless models are removed
uselessModels <- which(lrRes$lrRes$nNonZero == 0)
if (length(uselessModels) != 0) {
  pred <- lrRes$lrRes$y_pred[-uselessModels]
  truth <- lrRes$lrRes$y_truth[-uselessModels]
  auc_roc <- lrRes$lrRes$auc_roc[-uselessModels]
} else {
  pred <- lrRes$lrRes$y_pred
  truth <- lrRes$lrRes$y_truth
  auc_roc <- lrRes$lrRes$auc_roc
}
suppressWarnings(summarizePredPower(pred, truth, auc_roc))
```

```{r}
sessionInfo()
```
